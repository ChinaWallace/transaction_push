# -*- coding: utf-8 -*-
"""
WebSocketè¿æ¥ä¼˜åŒ–å™¨
WebSocket Connection Optimizer - ä¼˜åŒ–WebSocketè¿æ¥æ€§èƒ½å’Œç¨³å®šæ€§
"""

import asyncio
import time
from typing import Dict, Any, List, Optional, Callable
from datetime import datetime
from dataclasses import dataclass, field
from enum import Enum
from collections import deque

from app.core.logging import get_logger
from app.utils.exceptions import TradingToolError

logger = get_logger(__name__)


class ConnectionState(Enum):
    """è¿æ¥çŠ¶æ€æšä¸¾"""
    DISCONNECTED = "disconnected"
    CONNECTING = "connecting"
    CONNECTED = "connected"
    RECONNECTING = "reconnecting"
    ERROR = "error"


@dataclass
class ConnectionMetrics:
    """è¿æ¥æŒ‡æ ‡"""
    connect_time: float = 0.0
    disconnect_time: float = 0.0
    total_messages: int = 0
    error_count: int = 0
    reconnect_count: int = 0
    last_message_time: float = 0.0
    average_latency: float = 0.0
    latency_samples: deque = field(default_factory=lambda: deque(maxlen=100))


@dataclass
class OptimizationConfig:
    """ä¼˜åŒ–é…ç½®"""
    # è¿æ¥æ± é…ç½®
    max_connections_per_host: int = 5
    connection_timeout: float = 10.0
    read_timeout: float = 30.0
    
    # é‡è¿é…ç½®
    initial_reconnect_delay: float = 1.0
    max_reconnect_delay: float = 60.0
    reconnect_backoff_factor: float = 1.5
    max_reconnect_attempts: int = 10
    
    # å¿ƒè·³é…ç½®
    ping_interval: float = 20.0
    pong_timeout: float = 10.0
    health_check_interval: float = 30.0
    
    # æ¶ˆæ¯å¤„ç†é…ç½®
    message_queue_size: int = 1000
    batch_processing_size: int = 10
    batch_processing_timeout: float = 0.1
    
    # æ€§èƒ½ä¼˜åŒ–é…ç½®
    enable_compression: bool = True
    enable_message_batching: bool = True
    enable_connection_pooling: bool = True
    enable_adaptive_reconnect: bool = True


class WebSocketOptimizer:
    """WebSocketè¿æ¥ä¼˜åŒ–å™¨"""
    
    def __init__(self, config: OptimizationConfig = None):
        self.config = config or OptimizationConfig()
        
        # è¿æ¥ç®¡ç†
        self.connections: Dict[str, Any] = {}
        self.connection_states: Dict[str, ConnectionState] = {}
        self.connection_metrics: Dict[str, ConnectionMetrics] = {}
        
        # è¿æ¥æ± 
        self.connection_pool: Dict[str, List[Any]] = {}
        self.pool_lock = asyncio.Lock()
        
        # æ¶ˆæ¯å¤„ç†
        self.message_queues: Dict[str, asyncio.Queue] = {}
        self.message_processors: Dict[str, asyncio.Task] = {}
        
        # ç›‘æ§å’Œç»Ÿè®¡
        self.global_metrics = {
            'total_connections': 0,
            'active_connections': 0,
            'total_messages': 0,
            'total_errors': 0,
            'total_reconnects': 0,
            'start_time': time.time()
        }
        
        # ä¼˜åŒ–ä»»åŠ¡
        self.optimization_tasks: List[asyncio.Task] = []
        self.is_running = False
        
        logger.info("ğŸ”§ WebSocketä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def start(self):
        """å¯åŠ¨ä¼˜åŒ–å™¨"""
        if self.is_running:
            return
        
        self.is_running = True
        logger.info("ğŸš€ å¯åŠ¨WebSocketä¼˜åŒ–å™¨")
        
        # å¯åŠ¨ä¼˜åŒ–ä»»åŠ¡
        self.optimization_tasks = [
            asyncio.create_task(self._health_monitor_task()),
            asyncio.create_task(self._connection_pool_manager_task()),
            asyncio.create_task(self._metrics_collector_task()),
            asyncio.create_task(self._adaptive_reconnect_task())
        ]
        
        logger.info("âœ… WebSocketä¼˜åŒ–å™¨å¯åŠ¨å®Œæˆ")
    
    async def stop(self):
        """åœæ­¢ä¼˜åŒ–å™¨"""
        if not self.is_running:
            return
        
        logger.info("ğŸ›‘ åœæ­¢WebSocketä¼˜åŒ–å™¨")
        self.is_running = False
        
        # å–æ¶ˆä¼˜åŒ–ä»»åŠ¡
        for task in self.optimization_tasks:
            if not task.done():
                task.cancel()
        
        # ç­‰å¾…ä»»åŠ¡å®Œæˆ
        if self.optimization_tasks:
            await asyncio.gather(*self.optimization_tasks, return_exceptions=True)
        
        # æ¸…ç†è¿æ¥
        await self._cleanup_all_connections()
        
        logger.info("âœ… WebSocketä¼˜åŒ–å™¨å·²åœæ­¢")
    
    async def optimize_connection(self, connection_id: str, websocket, 
                                callback: Optional[Callable] = None) -> bool:
        """ä¼˜åŒ–WebSocketè¿æ¥"""
        try:
            logger.info(f"ğŸ”§ å¼€å§‹ä¼˜åŒ–è¿æ¥: {connection_id}")
            
            # åˆå§‹åŒ–è¿æ¥çŠ¶æ€
            self.connection_states[connection_id] = ConnectionState.CONNECTED
            self.connection_metrics[connection_id] = ConnectionMetrics(
                connect_time=time.time()
            )
            self.connections[connection_id] = websocket
            
            # åˆ›å»ºæ¶ˆæ¯é˜Ÿåˆ—
            if self.config.enable_message_batching:
                self.message_queues[connection_id] = asyncio.Queue(
                    maxsize=self.config.message_queue_size
                )
                
                # å¯åŠ¨æ¶ˆæ¯å¤„ç†å™¨
                processor_task = asyncio.create_task(
                    self._message_processor(connection_id, callback)
                )
                self.message_processors[connection_id] = processor_task
            
            # æ›´æ–°å…¨å±€æŒ‡æ ‡
            self.global_metrics['total_connections'] += 1
            self.global_metrics['active_connections'] += 1
            
            logger.info(f"âœ… è¿æ¥ä¼˜åŒ–å®Œæˆ: {connection_id}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ è¿æ¥ä¼˜åŒ–å¤±è´¥: {connection_id} - {e}")
            return False
    
    async def handle_message(self, connection_id: str, message: Any) -> bool:
        """å¤„ç†æ¶ˆæ¯ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        try:
            metrics = self.connection_metrics.get(connection_id)
            if metrics:
                metrics.total_messages += 1
                metrics.last_message_time = time.time()
                
                # è®¡ç®—å»¶è¿Ÿï¼ˆå¦‚æœæ¶ˆæ¯åŒ…å«æ—¶é—´æˆ³ï¼‰
                if isinstance(message, dict) and 'timestamp' in message:
                    try:
                        msg_time = float(message['timestamp']) / 1000  # å‡è®¾æ˜¯æ¯«ç§’æ—¶é—´æˆ³
                        latency = time.time() - msg_time
                        metrics.latency_samples.append(latency)
                        
                        # æ›´æ–°å¹³å‡å»¶è¿Ÿ
                        if metrics.latency_samples:
                            metrics.average_latency = sum(metrics.latency_samples) / len(metrics.latency_samples)
                    except (ValueError, TypeError):
                        pass
            
            # æ›´æ–°å…¨å±€æŒ‡æ ‡
            self.global_metrics['total_messages'] += 1
            
            # å¦‚æœå¯ç”¨äº†æ¶ˆæ¯æ‰¹å¤„ç†ï¼Œå°†æ¶ˆæ¯æ”¾å…¥é˜Ÿåˆ—
            if self.config.enable_message_batching and connection_id in self.message_queues:
                try:
                    self.message_queues[connection_id].put_nowait(message)
                    return True
                except asyncio.QueueFull:
                    logger.warning(f"âš ï¸ æ¶ˆæ¯é˜Ÿåˆ—å·²æ»¡: {connection_id}")
                    return False
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†æ¶ˆæ¯å¼‚å¸¸: {connection_id} - {e}")
            await self._record_error(connection_id, e)
            return False
    
    async def handle_connection_error(self, connection_id: str, error: Exception) -> bool:
        """å¤„ç†è¿æ¥é”™è¯¯"""
        try:
            logger.warning(f"âš ï¸ è¿æ¥é”™è¯¯: {connection_id} - {error}")
            
            await self._record_error(connection_id, error)
            
            # æ›´æ–°è¿æ¥çŠ¶æ€
            self.connection_states[connection_id] = ConnectionState.ERROR
            
            # å¦‚æœå¯ç”¨è‡ªé€‚åº”é‡è¿ï¼Œè§¦å‘é‡è¿
            if self.config.enable_adaptive_reconnect:
                await self._schedule_reconnect(connection_id)
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†è¿æ¥é”™è¯¯å¼‚å¸¸: {connection_id} - {e}")
            return False
    
    async def handle_connection_close(self, connection_id: str) -> bool:
        """å¤„ç†è¿æ¥å…³é—­"""
        try:
            logger.info(f"ğŸ”Œ è¿æ¥å…³é—­: {connection_id}")
            
            # æ›´æ–°è¿æ¥çŠ¶æ€
            self.connection_states[connection_id] = ConnectionState.DISCONNECTED
            
            # æ›´æ–°æŒ‡æ ‡
            metrics = self.connection_metrics.get(connection_id)
            if metrics:
                metrics.disconnect_time = time.time()
            
            # æ¸…ç†è¿æ¥èµ„æº
            await self._cleanup_connection(connection_id)
            
            # æ›´æ–°å…¨å±€æŒ‡æ ‡
            if self.global_metrics['active_connections'] > 0:
                self.global_metrics['active_connections'] -= 1
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†è¿æ¥å…³é—­å¼‚å¸¸: {connection_id} - {e}")
            return False
    
    async def _message_processor(self, connection_id: str, callback: Optional[Callable]):
        """æ¶ˆæ¯æ‰¹å¤„ç†å™¨"""
        try:
            queue = self.message_queues[connection_id]
            batch = []
            last_process_time = time.time()
            
            while self.is_running and connection_id in self.message_queues:
                try:
                    # ç­‰å¾…æ¶ˆæ¯æˆ–è¶…æ—¶
                    message = await asyncio.wait_for(
                        queue.get(),
                        timeout=self.config.batch_processing_timeout
                    )
                    
                    batch.append(message)
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦å¤„ç†æ‰¹æ¬¡
                    current_time = time.time()
                    should_process = (
                        len(batch) >= self.config.batch_processing_size or
                        current_time - last_process_time >= self.config.batch_processing_timeout
                    )
                    
                    if should_process and batch:
                        # å¤„ç†æ‰¹æ¬¡
                        if callback:
                            try:
                                if len(batch) == 1:
                                    await self._safe_callback(callback, batch[0])
                                else:
                                    await self._safe_callback(callback, batch)
                            except Exception as e:
                                logger.error(f"âŒ æ‰¹å¤„ç†å›è°ƒå¼‚å¸¸: {e}")
                        
                        batch.clear()
                        last_process_time = current_time
                
                except asyncio.TimeoutError:
                    # è¶…æ—¶ï¼Œå¤„ç†å½“å‰æ‰¹æ¬¡
                    if batch and callback:
                        try:
                            if len(batch) == 1:
                                await self._safe_callback(callback, batch[0])
                            else:
                                await self._safe_callback(callback, batch)
                        except Exception as e:
                            logger.error(f"âŒ è¶…æ—¶æ‰¹å¤„ç†å›è°ƒå¼‚å¸¸: {e}")
                        
                        batch.clear()
                        last_process_time = time.time()
                
                except Exception as e:
                    logger.error(f"âŒ æ¶ˆæ¯å¤„ç†å™¨å¼‚å¸¸: {connection_id} - {e}")
                    await asyncio.sleep(1)
        
        except Exception as e:
            logger.error(f"âŒ æ¶ˆæ¯å¤„ç†å™¨å¯åŠ¨å¼‚å¸¸: {connection_id} - {e}")
        finally:
            logger.debug(f"ğŸ”„ æ¶ˆæ¯å¤„ç†å™¨é€€å‡º: {connection_id}")
    
    async def _safe_callback(self, callback: Callable, data: Any):
        """å®‰å…¨çš„å›è°ƒæ‰§è¡Œ"""
        try:
            if asyncio.iscoroutinefunction(callback):
                await callback(data)
            else:
                callback(data)
        except Exception as e:
            logger.error(f"âŒ å›è°ƒæ‰§è¡Œå¼‚å¸¸: {e}")
    
    async def _record_error(self, connection_id: str, error: Exception):
        """è®°å½•é”™è¯¯"""
        metrics = self.connection_metrics.get(connection_id)
        if metrics:
            metrics.error_count += 1
        
        self.global_metrics['total_errors'] += 1
        
        logger.debug(f"ğŸ“Š è®°å½•é”™è¯¯: {connection_id} - {error}")
    
    async def _schedule_reconnect(self, connection_id: str):
        """è°ƒåº¦é‡è¿"""
        try:
            metrics = self.connection_metrics.get(connection_id)
            if not metrics:
                return
            
            # è®¡ç®—é‡è¿å»¶è¿Ÿï¼ˆæŒ‡æ•°é€€é¿ï¼‰
            delay = min(
                self.config.initial_reconnect_delay * (
                    self.config.reconnect_backoff_factor ** metrics.reconnect_count
                ),
                self.config.max_reconnect_delay
            )
            
            logger.info(f"ğŸ”„ è°ƒåº¦é‡è¿: {connection_id}, å»¶è¿Ÿ {delay:.1f}ç§’")
            
            # æ›´æ–°çŠ¶æ€
            self.connection_states[connection_id] = ConnectionState.RECONNECTING
            metrics.reconnect_count += 1
            self.global_metrics['total_reconnects'] += 1
            
            # å»¶è¿Ÿåè§¦å‘é‡è¿ï¼ˆè¿™é‡Œåªæ˜¯ç¤ºä¾‹ï¼Œå®é™…é‡è¿é€»è¾‘éœ€è¦ç”±è°ƒç”¨æ–¹å®ç°ï¼‰
            await asyncio.sleep(delay)
            
        except Exception as e:
            logger.error(f"âŒ è°ƒåº¦é‡è¿å¼‚å¸¸: {connection_id} - {e}")
    
    async def _cleanup_connection(self, connection_id: str):
        """æ¸…ç†è¿æ¥èµ„æº"""
        try:
            # åœæ­¢æ¶ˆæ¯å¤„ç†å™¨
            if connection_id in self.message_processors:
                task = self.message_processors[connection_id]
                if not task.done():
                    task.cancel()
                del self.message_processors[connection_id]
            
            # æ¸…ç†æ¶ˆæ¯é˜Ÿåˆ—
            if connection_id in self.message_queues:
                del self.message_queues[connection_id]
            
            # æ¸…ç†è¿æ¥å¼•ç”¨
            self.connections.pop(connection_id, None)
            
            logger.debug(f"ğŸ§¹ è¿æ¥èµ„æºæ¸…ç†å®Œæˆ: {connection_id}")
            
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†è¿æ¥èµ„æºå¼‚å¸¸: {connection_id} - {e}")
    
    async def _cleanup_all_connections(self):
        """æ¸…ç†æ‰€æœ‰è¿æ¥"""
        try:
            logger.info("ğŸ§¹ æ¸…ç†æ‰€æœ‰è¿æ¥èµ„æº")
            
            # åœæ­¢æ‰€æœ‰æ¶ˆæ¯å¤„ç†å™¨
            for task in self.message_processors.values():
                if not task.done():
                    task.cancel()
            
            # ç­‰å¾…ä»»åŠ¡å®Œæˆ
            if self.message_processors:
                await asyncio.gather(*self.message_processors.values(), return_exceptions=True)
            
            # æ¸…ç†æ‰€æœ‰èµ„æº
            self.connections.clear()
            self.connection_states.clear()
            self.message_queues.clear()
            self.message_processors.clear()
            
            logger.info("âœ… æ‰€æœ‰è¿æ¥èµ„æºæ¸…ç†å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†æ‰€æœ‰è¿æ¥å¼‚å¸¸: {e}")
    
    async def _health_monitor_task(self):
        """å¥åº·ç›‘æ§ä»»åŠ¡"""
        try:
            while self.is_running:
                try:
                    current_time = time.time()
                    
                    # æ£€æŸ¥è¿æ¥å¥åº·çŠ¶æ€
                    for connection_id, metrics in self.connection_metrics.items():
                        # æ£€æŸ¥æ¶ˆæ¯æ¥æ”¶è¶…æ—¶
                        if (metrics.last_message_time > 0 and 
                            current_time - metrics.last_message_time > self.config.read_timeout):
                            
                            logger.warning(f"âš ï¸ è¿æ¥æ¶ˆæ¯æ¥æ”¶è¶…æ—¶: {connection_id}")
                            await self.handle_connection_error(
                                connection_id, 
                                TradingToolError("æ¶ˆæ¯æ¥æ”¶è¶…æ—¶")
                            )
                    
                    await asyncio.sleep(self.config.health_check_interval)
                    
                except Exception as e:
                    logger.error(f"âŒ å¥åº·ç›‘æ§å¼‚å¸¸: {e}")
                    await asyncio.sleep(5)
        
        except asyncio.CancelledError:
            logger.debug("ğŸ”„ å¥åº·ç›‘æ§ä»»åŠ¡è¢«å–æ¶ˆ")
        except Exception as e:
            logger.error(f"âŒ å¥åº·ç›‘æ§ä»»åŠ¡å¼‚å¸¸: {e}")
    
    async def _connection_pool_manager_task(self):
        """è¿æ¥æ± ç®¡ç†ä»»åŠ¡"""
        try:
            while self.is_running:
                try:
                    # è¿æ¥æ± æ¸…ç†å’Œç»´æŠ¤é€»è¾‘
                    # è¿™é‡Œå¯ä»¥å®ç°è¿æ¥æ± çš„æ¸…ç†ã€é¢„çƒ­ç­‰åŠŸèƒ½
                    
                    await asyncio.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
                    
                except Exception as e:
                    logger.error(f"âŒ è¿æ¥æ± ç®¡ç†å¼‚å¸¸: {e}")
                    await asyncio.sleep(10)
        
        except asyncio.CancelledError:
            logger.debug("ğŸ”„ è¿æ¥æ± ç®¡ç†ä»»åŠ¡è¢«å–æ¶ˆ")
        except Exception as e:
            logger.error(f"âŒ è¿æ¥æ± ç®¡ç†ä»»åŠ¡å¼‚å¸¸: {e}")
    
    async def _metrics_collector_task(self):
        """æŒ‡æ ‡æ”¶é›†ä»»åŠ¡"""
        try:
            while self.is_running:
                try:
                    # æ”¶é›†å’Œè®°å½•æ€§èƒ½æŒ‡æ ‡
                    self._log_performance_metrics()
                    
                    await asyncio.sleep(300)  # æ¯5åˆ†é’Ÿè®°å½•ä¸€æ¬¡
                    
                except Exception as e:
                    logger.error(f"âŒ æŒ‡æ ‡æ”¶é›†å¼‚å¸¸: {e}")
                    await asyncio.sleep(30)
        
        except asyncio.CancelledError:
            logger.debug("ğŸ”„ æŒ‡æ ‡æ”¶é›†ä»»åŠ¡è¢«å–æ¶ˆ")
        except Exception as e:
            logger.error(f"âŒ æŒ‡æ ‡æ”¶é›†ä»»åŠ¡å¼‚å¸¸: {e}")
    
    async def _adaptive_reconnect_task(self):
        """è‡ªé€‚åº”é‡è¿ä»»åŠ¡"""
        try:
            while self.is_running:
                try:
                    # æ£€æŸ¥éœ€è¦é‡è¿çš„è¿æ¥
                    for connection_id, state in self.connection_states.items():
                        if state == ConnectionState.ERROR:
                            metrics = self.connection_metrics.get(connection_id)
                            if metrics and metrics.reconnect_count < self.config.max_reconnect_attempts:
                                # è§¦å‘é‡è¿é€»è¾‘ï¼ˆå®é™…å®ç°éœ€è¦è°ƒç”¨æ–¹æä¾›ï¼‰
                                logger.debug(f"ğŸ”„ æ£€æµ‹åˆ°éœ€è¦é‡è¿çš„è¿æ¥: {connection_id}")
                    
                    await asyncio.sleep(10)  # æ¯10ç§’æ£€æŸ¥ä¸€æ¬¡
                    
                except Exception as e:
                    logger.error(f"âŒ è‡ªé€‚åº”é‡è¿å¼‚å¸¸: {e}")
                    await asyncio.sleep(5)
        
        except asyncio.CancelledError:
            logger.debug("ğŸ”„ è‡ªé€‚åº”é‡è¿ä»»åŠ¡è¢«å–æ¶ˆ")
        except Exception as e:
            logger.error(f"âŒ è‡ªé€‚åº”é‡è¿ä»»åŠ¡å¼‚å¸¸: {e}")
    
    def _log_performance_metrics(self):
        """è®°å½•æ€§èƒ½æŒ‡æ ‡"""
        try:
            current_time = time.time()
            uptime = current_time - self.global_metrics['start_time']
            
            # è®¡ç®—å¹³å‡æŒ‡æ ‡
            avg_messages_per_second = self.global_metrics['total_messages'] / uptime if uptime > 0 else 0
            error_rate = self.global_metrics['total_errors'] / self.global_metrics['total_messages'] if self.global_metrics['total_messages'] > 0 else 0
            
            logger.info(f"ğŸ“Š WebSocketæ€§èƒ½æŒ‡æ ‡:")
            logger.info(f"  è¿è¡Œæ—¶é—´: {uptime:.1f}ç§’")
            logger.info(f"  æ€»è¿æ¥æ•°: {self.global_metrics['total_connections']}")
            logger.info(f"  æ´»è·ƒè¿æ¥æ•°: {self.global_metrics['active_connections']}")
            logger.info(f"  æ€»æ¶ˆæ¯æ•°: {self.global_metrics['total_messages']}")
            logger.info(f"  å¹³å‡æ¶ˆæ¯/ç§’: {avg_messages_per_second:.2f}")
            logger.info(f"  é”™è¯¯ç‡: {error_rate:.4f}")
            logger.info(f"  é‡è¿æ¬¡æ•°: {self.global_metrics['total_reconnects']}")
            
            # è®°å½•è¿æ¥çº§åˆ«çš„æŒ‡æ ‡
            for connection_id, metrics in self.connection_metrics.items():
                if metrics.total_messages > 0:
                    logger.debug(f"  è¿æ¥ {connection_id}: {metrics.total_messages} æ¶ˆæ¯, {metrics.error_count} é”™è¯¯, å¹³å‡å»¶è¿Ÿ {metrics.average_latency:.3f}ç§’")
        
        except Exception as e:
            logger.error(f"âŒ è®°å½•æ€§èƒ½æŒ‡æ ‡å¼‚å¸¸: {e}")
    
    def get_optimization_status(self) -> Dict[str, Any]:
        """è·å–ä¼˜åŒ–çŠ¶æ€"""
        return {
            'is_running': self.is_running,
            'config': {
                'max_connections_per_host': self.config.max_connections_per_host,
                'connection_timeout': self.config.connection_timeout,
                'enable_compression': self.config.enable_compression,
                'enable_message_batching': self.config.enable_message_batching,
                'enable_connection_pooling': self.config.enable_connection_pooling,
                'enable_adaptive_reconnect': self.config.enable_adaptive_reconnect
            },
            'global_metrics': self.global_metrics.copy(),
            'active_connections': len(self.connections),
            'connection_states': {k: v.value for k, v in self.connection_states.items()},
            'message_queues': {k: v.qsize() for k, v in self.message_queues.items()},
            'timestamp': datetime.now().isoformat()
        }
    
    def get_connection_metrics(self, connection_id: str) -> Optional[Dict[str, Any]]:
        """è·å–è¿æ¥æŒ‡æ ‡"""
        metrics = self.connection_metrics.get(connection_id)
        if not metrics:
            return None
        
        return {
            'connection_id': connection_id,
            'state': self.connection_states.get(connection_id, ConnectionState.DISCONNECTED).value,
            'connect_time': metrics.connect_time,
            'disconnect_time': metrics.disconnect_time,
            'total_messages': metrics.total_messages,
            'error_count': metrics.error_count,
            'reconnect_count': metrics.reconnect_count,
            'last_message_time': metrics.last_message_time,
            'average_latency': metrics.average_latency,
            'uptime': time.time() - metrics.connect_time if metrics.connect_time > 0 else 0
        }


# å…¨å±€ä¼˜åŒ–å™¨å®ä¾‹
_global_optimizer: Optional[WebSocketOptimizer] = None


async def get_websocket_optimizer(config: OptimizationConfig = None) -> WebSocketOptimizer:
    """è·å–å…¨å±€WebSocketä¼˜åŒ–å™¨å®ä¾‹"""
    global _global_optimizer
    
    if _global_optimizer is None:
        _global_optimizer = WebSocketOptimizer(config)
        await _global_optimizer.start()
    
    return _global_optimizer


async def cleanup_websocket_optimizer():
    """æ¸…ç†å…¨å±€WebSocketä¼˜åŒ–å™¨"""
    global _global_optimizer
    
    if _global_optimizer:
        await _global_optimizer.stop()
        _global_optimizer = None