# -*- coding: utf-8 -*-
"""
å¸å®‰æ•°æ®é€‚é…å™¨
Binance data adapter
"""

from typing import Dict, Any, List, Optional
from datetime import datetime

from app.core.logging import get_logger
from app.models.unified_exchange_data import (
    UnifiedInstrument, UnifiedTicker, UnifiedFundingRate, UnifiedPosition,
    validate_unified_instrument
)
from .base_adapter import ExchangeDataAdapter
from .performance_monitor import log_adapter_performance
from .batch_processor import adapter_batch_processor
from .cache_manager import cache_adapter_result

logger = get_logger(__name__)


class BinanceDataAdapter(ExchangeDataAdapter):
    """
    å¸å®‰æ•°æ®é€‚é…å™¨
    Binance data adapter
    
    å°†å¸å®‰äº¤æ˜“æ‰€çš„åŸå§‹æ•°æ®æ ¼å¼è½¬æ¢ä¸ºç»Ÿä¸€çš„æ•°æ®æ ¼å¼
    """
    
    def __init__(self):
        super().__init__("binance")
        logger.info("ğŸ”§ å¸å®‰æ•°æ®é€‚é…å™¨åˆå§‹åŒ–å®Œæˆ")
    
    @log_adapter_performance("adapt_instruments")
    @cache_adapter_result("binance_instruments", ttl=3600, data_type="instruments")
    def adapt_instruments(self, raw_data: List[Dict[str, Any]]) -> List[UnifiedInstrument]:
        """
        é€‚é…å¸å®‰äº¤æ˜“å¯¹æ•°æ®
        Adapt Binance instruments data
        
        å¸å®‰åŸå§‹æ ¼å¼ç¤ºä¾‹:
        {
            "symbol": "BTCUSDT",
            "status": "TRADING",
            "baseAsset": "BTC",
            "quoteAsset": "USDT",
            "contractType": "PERPETUAL",
            "filters": [
                {"filterType": "PRICE_FILTER", "tickSize": "0.10"},
                {"filterType": "LOT_SIZE", "minQty": "0.001", "stepSize": "0.001"}
            ]
        }
        
        è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼:
        {
            "instId": "BTC-USDT-SWAP",
            "instType": "SWAP",
            "baseCcy": "BTC",
            "quoteCcy": "USDT",
            "state": "live"
        }
        """
        if not raw_data:
            logger.warning("âš ï¸ å¸å®‰äº¤æ˜“å¯¹æ•°æ®ä¸ºç©º")
            return []
        
        unified_instruments = []
        processed_count = 0
        error_count = 0
        
        logger.info(f"ğŸ”„ å¼€å§‹é€‚é…å¸å®‰äº¤æ˜“å¯¹æ•°æ®ï¼Œå…± {len(raw_data)} ä¸ªäº¤æ˜“å¯¹")
        
        for item in raw_data:
            try:
                # éªŒè¯å¿…éœ€å­—æ®µ
                self._validate_required_fields(
                    item, 
                    ["symbol", "status"], 
                    "å¸å®‰äº¤æ˜“å¯¹"
                )
                
                # è·å–åŸºç¡€ä¿¡æ¯
                raw_symbol = self._safe_get(item, "symbol")
                status = self._safe_get(item, "status")
                base_asset = self._safe_get(item, "baseAsset")
                quote_asset = self._safe_get(item, "quoteAsset")
                contract_type = self._safe_get(item, "contractType")
                
                # åªå¤„ç†USDTæ°¸ç»­åˆçº¦
                if not raw_symbol.endswith('USDT') or quote_asset != 'USDT':
                    continue
                
                # åªå¤„ç†æ°¸ç»­åˆçº¦
                if contract_type != 'PERPETUAL':
                    continue
                
                # åªå¤„ç†äº¤æ˜“çŠ¶æ€çš„åˆçº¦
                if status.upper() != 'TRADING':
                    continue
                
                # æå–åŸºç¡€è´§å¸ - ä½¿ç”¨baseAssetå­—æ®µæ›´å‡†ç¡®
                base_currency = base_asset if base_asset else raw_symbol[:-4]
                
                # è¿‡æ»¤æ‰åŸºç¡€è´§å¸åç§°è¿‡é•¿çš„äº¤æ˜“å¯¹ï¼ˆæ•°æ®åº“é™åˆ¶ä¸º10ä¸ªå­—ç¬¦ï¼‰
                if len(base_currency) > 10:
                    logger.debug(f"è·³è¿‡åŸºç¡€è´§å¸åç§°è¿‡é•¿çš„äº¤æ˜“å¯¹: {base_currency} (é•¿åº¦: {len(base_currency)})")
                    continue
                
                unified_symbol = f"{base_currency}-USDT-SWAP"
                
                # æå–è¿‡æ»¤å™¨ä¿¡æ¯ç”¨äºç²¾åº¦è®¾ç½®
                filters = item.get('filters', [])
                min_qty = self._extract_min_qty_from_filters(filters)
                step_size = self._extract_step_size_from_filters(filters)
                tick_size = self._extract_tick_size_from_filters(filters)
                
                # è·å–ä¸Šçº¿æ—¶é—´ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                list_time = self._safe_get_timestamp(item, "onboardDate", "0")
                
                # åˆ›å»ºç»Ÿä¸€äº¤æ˜“å¯¹å¯¹è±¡
                unified_instrument = UnifiedInstrument(
                    instId=unified_symbol,
                    instType='SWAP',
                    baseCcy=base_currency,
                    quoteCcy='USDT',
                    settleCcy='USDT',
                    ctVal='1',  # å¸å®‰æ°¸ç»­åˆçº¦é¢å€¼ä¸º1
                    ctMult='1', # å¸å®‰æ°¸ç»­åˆçº¦ä¹˜æ•°ä¸º1
                    ctValCcy=base_currency,
                    minSz=min_qty,
                    lotSz=step_size,
                    tickSz=tick_size,
                    state=self._normalize_state(status),
                    listTime=list_time,
                    expTime='0',   # æ°¸ç»­åˆçº¦æ— åˆ°æœŸæ—¶é—´ï¼Œä½¿ç”¨0è€Œä¸æ˜¯ç©ºå­—ç¬¦ä¸²
                    source='binance',
                    raw_data=item
                )
                
                # éªŒè¯æ•°æ®å®Œæ•´æ€§
                if validate_unified_instrument(unified_instrument):
                    unified_instruments.append(unified_instrument)
                    processed_count += 1
                    logger.debug(f"âœ… æˆåŠŸé€‚é…äº¤æ˜“å¯¹: {unified_symbol}")
                else:
                    logger.warning(f"âš ï¸ å¸å®‰äº¤æ˜“å¯¹æ•°æ®éªŒè¯å¤±è´¥: {unified_symbol}")
                    error_count += 1
                    
            except Exception as e:
                error_count += 1
                logger.warning(f"âš ï¸ é€‚é…äº¤æ˜“å¯¹å¤±è´¥: {e}")
                self._handle_adaptation_error(e, "å¸å®‰äº¤æ˜“å¯¹", item)
                continue
        
        logger.info(f"âœ… å¸å®‰äº¤æ˜“å¯¹é€‚é…å®Œæˆ: æˆåŠŸ {processed_count} ä¸ªï¼Œå¤±è´¥ {error_count} ä¸ª")
        return unified_instruments
    
    @cache_adapter_result("binance_instruments_batch", ttl=1800, data_type="batch_instruments")
    async def adapt_instruments_batch(self, raw_data: List[Dict[str, Any]]) -> List[UnifiedInstrument]:
        """
        æ‰¹é‡é€‚é…å¸å®‰äº¤æ˜“å¯¹æ•°æ®ï¼ˆå¼‚æ­¥ä¼˜åŒ–ç‰ˆæœ¬ï¼‰
        Batch adapt Binance instruments data (async optimized version)
        """
        if not raw_data:
            logger.warning("âš ï¸ å¸å®‰äº¤æ˜“å¯¹æ•°æ®ä¸ºç©º")
            return []
        
        logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡é€‚é…å¸å®‰äº¤æ˜“å¯¹æ•°æ®ï¼Œå…± {len(raw_data)} ä¸ªäº¤æ˜“å¯¹")
        
        def progress_callback(processed: int, total: int):
            if processed % 100 == 0 or processed == total:
                logger.info(f"ğŸ“Š æ‰¹é‡é€‚é…è¿›åº¦: {processed}/{total} ({processed/total*100:.1f}%)")
        
        try:
            # ä½¿ç”¨æ‰¹å¤„ç†å™¨è¿›è¡Œä¼˜åŒ–å¤„ç†
            results = await adapter_batch_processor.batch_adapt_instruments(
                raw_data, 
                self._adapt_single_instrument,
                progress_callback
            )
            
            logger.info(f"âœ… å¸å®‰äº¤æ˜“å¯¹æ‰¹é‡é€‚é…å®Œæˆ: {len(results)}/{len(raw_data)} ä¸ª")
            return results
            
        except Exception as e:
            logger.error(f"âŒ å¸å®‰äº¤æ˜“å¯¹æ‰¹é‡é€‚é…å¤±è´¥: {e}")
            # å›é€€åˆ°ä¸²è¡Œå¤„ç†
            logger.info("ğŸ”„ å›é€€åˆ°ä¸²è¡Œå¤„ç†æ¨¡å¼")
            return self.adapt_instruments(raw_data)
    
    def _adapt_single_instrument(self, item: Dict[str, Any]) -> Optional[UnifiedInstrument]:
        """é€‚é…å•ä¸ªäº¤æ˜“å¯¹æ•°æ®ï¼ˆç”¨äºæ‰¹å¤„ç†ï¼‰"""
        try:
            # éªŒè¯å¿…éœ€å­—æ®µ
            self._validate_required_fields(
                item, 
                ["symbol", "status"], 
                "å¸å®‰äº¤æ˜“å¯¹"
            )
            
            # è·å–åŸºç¡€ä¿¡æ¯
            raw_symbol = self._safe_get(item, "symbol")
            status = self._safe_get(item, "status")
            base_asset = self._safe_get(item, "baseAsset")
            quote_asset = self._safe_get(item, "quoteAsset")
            contract_type = self._safe_get(item, "contractType")
            
            # åªå¤„ç†USDTæ°¸ç»­åˆçº¦
            if not raw_symbol.endswith('USDT') or quote_asset != 'USDT':
                return None
            
            # åªå¤„ç†æ°¸ç»­åˆçº¦
            if contract_type != 'PERPETUAL':
                return None
            
            # åªå¤„ç†äº¤æ˜“çŠ¶æ€çš„åˆçº¦
            if status.upper() != 'TRADING':
                return None
            
            # æå–åŸºç¡€è´§å¸ - ä½¿ç”¨baseAssetå­—æ®µæ›´å‡†ç¡®
            base_currency = base_asset if base_asset else raw_symbol[:-4]
            
            # è¿‡æ»¤æ‰åŸºç¡€è´§å¸åç§°è¿‡é•¿çš„äº¤æ˜“å¯¹ï¼ˆæ•°æ®åº“é™åˆ¶ä¸º10ä¸ªå­—ç¬¦ï¼‰
            if len(base_currency) > 10:
                return None
            
            unified_symbol = f"{base_currency}-USDT-SWAP"
            
            # æå–è¿‡æ»¤å™¨ä¿¡æ¯ç”¨äºç²¾åº¦è®¾ç½®
            filters = item.get('filters', [])
            min_qty = self._extract_min_qty_from_filters(filters)
            step_size = self._extract_step_size_from_filters(filters)
            tick_size = self._extract_tick_size_from_filters(filters)
            
            # è·å–ä¸Šçº¿æ—¶é—´ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            list_time = self._safe_get_timestamp(item, "onboardDate", "0")
            
            # åˆ›å»ºç»Ÿä¸€äº¤æ˜“å¯¹å¯¹è±¡
            unified_instrument = UnifiedInstrument(
                instId=unified_symbol,
                instType='SWAP',
                baseCcy=base_currency,
                quoteCcy='USDT',
                settleCcy='USDT',
                ctVal='1',  # å¸å®‰æ°¸ç»­åˆçº¦é¢å€¼ä¸º1
                ctMult='1', # å¸å®‰æ°¸ç»­åˆçº¦ä¹˜æ•°ä¸º1
                ctValCcy=base_currency,
                minSz=min_qty,
                lotSz=step_size,
                tickSz=tick_size,
                state=self._normalize_state(status),
                listTime=list_time,
                expTime='0',   # æ°¸ç»­åˆçº¦æ— åˆ°æœŸæ—¶é—´ï¼Œä½¿ç”¨0è€Œä¸æ˜¯ç©ºå­—ç¬¦ä¸²
                source='binance',
                raw_data=item
            )
            
            # éªŒè¯æ•°æ®å®Œæ•´æ€§
            if validate_unified_instrument(unified_instrument):
                return unified_instrument
            else:
                logger.warning(f"âš ï¸ å¸å®‰äº¤æ˜“å¯¹æ•°æ®éªŒè¯å¤±è´¥: {unified_symbol}")
                return None
                
        except Exception as e:
            logger.warning(f"âš ï¸ é€‚é…äº¤æ˜“å¯¹å¤±è´¥: {e}")
            return None
    
    @log_adapter_performance("adapt_ticker")
    @cache_adapter_result("binance_ticker", ttl=30, data_type="ticker")
    def adapt_ticker(self, raw_data: Dict[str, Any]) -> UnifiedTicker:
        """
        é€‚é…å¸å®‰tickeræ•°æ®
        Adapt Binance ticker data
        
        å¸å®‰åŸå§‹æ ¼å¼ç¤ºä¾‹:
        {
            "symbol": "BTCUSDT",
            "lastPrice": "50000.00",
            "bidPrice": "49999.00",
            "askPrice": "50001.00",
            "bidQty": "1.5",
            "askQty": "2.0",
            "openPrice": "49500.00",
            "highPrice": "50500.00",
            "lowPrice": "49000.00",
            "volume": "1000.00",
            "quoteVolume": "50000000.00",
            "closeTime": 1640995200000
        }
        """
        try:
            # éªŒè¯å¿…éœ€å­—æ®µ
            self._validate_required_fields(
                raw_data,
                ["symbol"],
                "å¸å®‰ticker"
            )
            
            # æ ‡å‡†åŒ–äº¤æ˜“å¯¹ç¬¦å·
            raw_symbol = self._safe_get(raw_data, "symbol")
            unified_symbol = self._normalize_symbol(raw_symbol, "binance")
            
            # è·å–æ—¶é—´æˆ³ï¼Œä¼˜å…ˆä½¿ç”¨closeTimeï¼Œå¦åˆ™ä½¿ç”¨å½“å‰æ—¶é—´
            timestamp = self._safe_get_timestamp(
                raw_data, 
                "closeTime", 
                str(int(datetime.now().timestamp() * 1000))
            )
            
            # åˆ›å»ºç»Ÿä¸€tickerå¯¹è±¡
            unified_ticker = UnifiedTicker(
                instId=unified_symbol,
                last=self._safe_get_float(raw_data, "lastPrice", "0"),
                lastSz=self._safe_get_float(raw_data, "count", "0"),  # äº¤æ˜“æ¬¡æ•°ä½œä¸ºæœ€æ–°æˆäº¤é‡
                askPx=self._safe_get_float(raw_data, "askPrice", "0"),
                askSz=self._safe_get_float(raw_data, "askQty", "0"),
                bidPx=self._safe_get_float(raw_data, "bidPrice", "0"),
                bidSz=self._safe_get_float(raw_data, "bidQty", "0"),
                open24h=self._safe_get_float(raw_data, "openPrice", "0"),
                high24h=self._safe_get_float(raw_data, "highPrice", "0"),
                low24h=self._safe_get_float(raw_data, "lowPrice", "0"),
                vol24h=self._safe_get_float(raw_data, "volume", "0"),
                volCcy24h=self._safe_get_float(raw_data, "quoteVolume", "0"),
                ts=timestamp,
                source='binance',
                raw_data=raw_data
            )
            
            logger.debug(f"âœ… æˆåŠŸé€‚é…tickeræ•°æ®: {unified_symbol}")
            return unified_ticker
            
        except Exception as e:
            self._handle_adaptation_error(e, "å¸å®‰ticker", raw_data)
    
    @log_adapter_performance("adapt_tickers")
    @cache_adapter_result("binance_tickers", ttl=60, data_type="batch_tickers")
    def adapt_tickers(self, raw_data: List[Dict[str, Any]]) -> List[UnifiedTicker]:
        """æ‰¹é‡é€‚é…å¸å®‰tickeræ•°æ®"""
        if not raw_data:
            return []
        
        unified_tickers = []
        for item in raw_data:
            try:
                ticker = self.adapt_ticker(item)
                unified_tickers.append(ticker)
            except Exception as e:
                logger.warning(f"âš ï¸ è·³è¿‡æ— æ•ˆçš„tickeræ•°æ®: {e}")
                continue
        
        logger.info(f"âœ… å¸å®‰tickeræ‰¹é‡é€‚é…å®Œæˆ: {len(unified_tickers)}/{len(raw_data)}")
        return unified_tickers
    
    @cache_adapter_result("binance_tickers_batch", ttl=60, data_type="batch_tickers")
    async def adapt_tickers_batch(self, raw_data: List[Dict[str, Any]]) -> List[UnifiedTicker]:
        """æ‰¹é‡é€‚é…å¸å®‰tickeræ•°æ®ï¼ˆå¼‚æ­¥ä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        if not raw_data:
            return []
        
        logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡é€‚é…å¸å®‰tickeræ•°æ®ï¼Œå…± {len(raw_data)} ä¸ª")
        
        try:
            results = await adapter_batch_processor.batch_adapt_tickers(
                raw_data, 
                self.adapt_ticker
            )
            
            logger.info(f"âœ… å¸å®‰tickeræ‰¹é‡é€‚é…å®Œæˆ: {len(results)}/{len(raw_data)}")
            return results
            
        except Exception as e:
            logger.error(f"âŒ å¸å®‰tickeræ‰¹é‡é€‚é…å¤±è´¥: {e}")
            # å›é€€åˆ°ä¸²è¡Œå¤„ç†
            return self.adapt_tickers(raw_data)
    
    @log_adapter_performance("adapt_funding_rate")
    @cache_adapter_result("binance_funding_rate", ttl=300, data_type="funding_rate")
    def adapt_funding_rate(self, raw_data: Dict[str, Any]) -> UnifiedFundingRate:
        """
        é€‚é…å¸å®‰èµ„é‡‘è´¹ç‡æ•°æ®
        Adapt Binance funding rate data
        
        å¸å®‰åŸå§‹æ ¼å¼ç¤ºä¾‹:
        {
            "symbol": "BTCUSDT",
            "lastFundingRate": "0.0001",
            "fundingTime": 1640995200000,
            "nextFundingTime": 1641024000000
        }
        """
        try:
            # éªŒè¯å¿…éœ€å­—æ®µ
            self._validate_required_fields(
                raw_data,
                ["symbol"],
                "å¸å®‰èµ„é‡‘è´¹ç‡"
            )
            
            # æ ‡å‡†åŒ–äº¤æ˜“å¯¹ç¬¦å·
            raw_symbol = self._safe_get(raw_data, "symbol")
            unified_symbol = self._normalize_symbol(raw_symbol, "binance")
            
            # è·å–èµ„é‡‘è´¹ç‡ï¼Œå¸å®‰APIä¸­å¯èƒ½æ˜¯lastFundingRateæˆ–fundingRate
            funding_rate = self._safe_get_float(raw_data, "lastFundingRate", "0")
            if funding_rate == "0":
                funding_rate = self._safe_get_float(raw_data, "fundingRate", "0")
            
            # è·å–æ—¶é—´æˆ³
            next_funding_time = self._safe_get_timestamp(raw_data, "nextFundingTime", "")
            funding_time = self._safe_get_timestamp(raw_data, "fundingTime", "")
            
            # å¦‚æœæ²¡æœ‰fundingTimeï¼Œä½¿ç”¨å½“å‰æ—¶é—´
            if not funding_time:
                funding_time = str(int(datetime.now().timestamp() * 1000))
            
            # åˆ›å»ºç»Ÿä¸€èµ„é‡‘è´¹ç‡å¯¹è±¡
            unified_funding_rate = UnifiedFundingRate(
                instId=unified_symbol,
                fundingRate=funding_rate,
                nextFundingTime=next_funding_time,
                fundingTime=funding_time,
                source='binance',
                raw_data=raw_data
            )
            
            logger.debug(f"âœ… æˆåŠŸé€‚é…èµ„é‡‘è´¹ç‡æ•°æ®: {unified_symbol}, è´¹ç‡: {funding_rate}")
            return unified_funding_rate
            
        except Exception as e:
            self._handle_adaptation_error(e, "å¸å®‰èµ„é‡‘è´¹ç‡", raw_data)
    
    @log_adapter_performance("adapt_funding_rates")
    @cache_adapter_result("binance_funding_rates", ttl=300, data_type="funding_rate")
    def adapt_funding_rates(self, raw_data: List[Dict[str, Any]]) -> List[UnifiedFundingRate]:
        """æ‰¹é‡é€‚é…å¸å®‰èµ„é‡‘è´¹ç‡æ•°æ®"""
        if not raw_data:
            return []
        
        unified_rates = []
        for item in raw_data:
            try:
                rate = self.adapt_funding_rate(item)
                unified_rates.append(rate)
            except Exception as e:
                logger.warning(f"âš ï¸ è·³è¿‡æ— æ•ˆçš„èµ„é‡‘è´¹ç‡æ•°æ®: {e}")
                continue
        
        logger.info(f"âœ… å¸å®‰èµ„é‡‘è´¹ç‡æ‰¹é‡é€‚é…å®Œæˆ: {len(unified_rates)}/{len(raw_data)}")
        return unified_rates
    
    @cache_adapter_result("binance_funding_rates_batch", ttl=300, data_type="funding_rate")
    async def adapt_funding_rates_batch(self, raw_data: List[Dict[str, Any]]) -> List[UnifiedFundingRate]:
        """æ‰¹é‡é€‚é…å¸å®‰èµ„é‡‘è´¹ç‡æ•°æ®ï¼ˆå¼‚æ­¥ä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        if not raw_data:
            return []
        
        logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡é€‚é…å¸å®‰èµ„é‡‘è´¹ç‡æ•°æ®ï¼Œå…± {len(raw_data)} ä¸ª")
        
        try:
            results = await adapter_batch_processor.batch_adapt_funding_rates(
                raw_data, 
                self.adapt_funding_rate
            )
            
            logger.info(f"âœ… å¸å®‰èµ„é‡‘è´¹ç‡æ‰¹é‡é€‚é…å®Œæˆ: {len(results)}/{len(raw_data)}")
            return results
            
        except Exception as e:
            logger.error(f"âŒ å¸å®‰èµ„é‡‘è´¹ç‡æ‰¹é‡é€‚é…å¤±è´¥: {e}")
            # å›é€€åˆ°ä¸²è¡Œå¤„ç†
            return self.adapt_funding_rates(raw_data)
    
    @log_adapter_performance("adapt_position")
    @cache_adapter_result("binance_position", ttl=60, data_type="position")
    def adapt_position(self, raw_data: Dict[str, Any]) -> UnifiedPosition:
        """
        é€‚é…å¸å®‰æŒä»“æ•°æ®
        Adapt Binance position data
        
        å¸å®‰åŸå§‹æ ¼å¼ç¤ºä¾‹:
        {
            "symbol": "BTCUSDT",
            "positionAmt": "0.001",
            "entryPrice": "50000.0",
            "markPrice": "50100.0",
            "unRealizedProfit": "0.1",
            "positionSide": "LONG"
        }
        """
        try:
            # éªŒè¯å¿…éœ€å­—æ®µ
            self._validate_required_fields(
                raw_data,
                ["symbol"],
                "å¸å®‰æŒä»“"
            )
            
            # è°ƒè¯•ï¼šæ£€æŸ¥å®é™…æ”¶åˆ°çš„æ•°æ®å­—æ®µ
            logger.debug(f"ğŸ” å¸å®‰åŸå§‹æŒä»“æ•°æ®å­—æ®µ: {list(raw_data.keys())}")
            
            # æ ‡å‡†åŒ–äº¤æ˜“å¯¹ç¬¦å·
            raw_symbol = self._safe_get(raw_data, "symbol")
            unified_symbol = self._normalize_symbol(raw_symbol, "binance")
            
            # å¤„ç†æŒä»“æ–¹å‘
            position_side = self._safe_get(raw_data, "positionSide", "BOTH").upper()
            if position_side == "LONG":
                pos_side = "long"
            elif position_side == "SHORT":
                pos_side = "short"
            else:
                pos_side = "net"
            
            # è®¡ç®—æŒä»“åä¹‰ä»·å€¼
            position_amt = float(self._safe_get_float(raw_data, "positionAmt", "0"))
            mark_price = float(self._safe_get_float(raw_data, "markPrice", "0"))
            pos_notional = str(abs(position_amt * mark_price))
            
            # åˆ›å»ºç»Ÿä¸€æŒä»“å¯¹è±¡
            unified_position = UnifiedPosition(
                instId=unified_symbol,
                posSide=pos_side,
                pos=self._safe_get_float(raw_data, "positionAmt"),
                posNotional=pos_notional,
                avgPx=self._safe_get_float(raw_data, "entryPrice"),
                upl=self._safe_get_float(raw_data, "unRealizedProfit"),
                uplRatio=self._safe_get_float(raw_data, "percentage"),
                margin=self._safe_get_float(raw_data, "isolatedMargin"),
                source='binance',
                raw_data=raw_data
            )
            
            return unified_position
            
        except Exception as e:
            self._handle_adaptation_error(e, "å¸å®‰æŒä»“", raw_data)
    
    @log_adapter_performance("adapt_positions")
    @cache_adapter_result("binance_positions", ttl=60, data_type="position")
    def adapt_positions(self, raw_data: List[Dict[str, Any]]) -> List[UnifiedPosition]:
        """æ‰¹é‡é€‚é…å¸å®‰æŒä»“æ•°æ®"""
        if not raw_data:
            return []
        
        unified_positions = []
        for item in raw_data:
            try:
                position = self.adapt_position(item)
                # åªè¿”å›æœ‰æŒä»“çš„æ•°æ®
                if position.has_position:
                    unified_positions.append(position)
            except Exception as e:
                logger.warning(f"âš ï¸ è·³è¿‡æ— æ•ˆçš„æŒä»“æ•°æ®: {e}")
                continue
        
        logger.info(f"âœ… å¸å®‰æŒä»“æ‰¹é‡é€‚é…å®Œæˆ: {len(unified_positions)}/{len(raw_data)}")
        return unified_positions
    
    @cache_adapter_result("binance_positions_batch", ttl=60, data_type="position")
    async def adapt_positions_batch(self, raw_data: List[Dict[str, Any]]) -> List[UnifiedPosition]:
        """æ‰¹é‡é€‚é…å¸å®‰æŒä»“æ•°æ®ï¼ˆå¼‚æ­¥ä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        if not raw_data:
            return []
        
        logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡é€‚é…å¸å®‰æŒä»“æ•°æ®ï¼Œå…± {len(raw_data)} ä¸ª")
        
        try:
            results = await adapter_batch_processor.batch_adapt_positions(
                raw_data, 
                self.adapt_position
            )
            
            # åªè¿”å›æœ‰æŒä»“çš„æ•°æ®
            valid_positions = [pos for pos in results if pos.has_position]
            
            logger.info(f"âœ… å¸å®‰æŒä»“æ‰¹é‡é€‚é…å®Œæˆ: {len(valid_positions)}/{len(raw_data)}")
            return valid_positions
            
        except Exception as e:
            logger.error(f"âŒ å¸å®‰æŒä»“æ‰¹é‡é€‚é…å¤±è´¥: {e}")
            # å›é€€åˆ°ä¸²è¡Œå¤„ç†
            return self.adapt_positions(raw_data)
    
    # è¾…åŠ©æ–¹æ³•
    def _extract_min_qty_from_filters(self, filters: List[Dict[str, Any]]) -> str:
        """ä»è¿‡æ»¤å™¨ä¸­æå–æœ€å°ä¸‹å•æ•°é‡"""
        for filter_item in filters:
            if filter_item.get('filterType') == 'LOT_SIZE':
                return self._safe_get_float(filter_item, 'minQty', '0.001')
        return '0.001'
    
    def _extract_step_size_from_filters(self, filters: List[Dict[str, Any]]) -> str:
        """ä»è¿‡æ»¤å™¨ä¸­æå–ä¸‹å•æ•°é‡ç²¾åº¦"""
        for filter_item in filters:
            if filter_item.get('filterType') == 'LOT_SIZE':
                return self._safe_get_float(filter_item, 'stepSize', '0.001')
        return '0.001'
    
    def _extract_tick_size_from_filters(self, filters: List[Dict[str, Any]]) -> str:
        """ä»è¿‡æ»¤å™¨ä¸­æå–ä»·æ ¼ç²¾åº¦"""
        for filter_item in filters:
            if filter_item.get('filterType') == 'PRICE_FILTER':
                return self._safe_get_float(filter_item, 'tickSize', '0.01')
        return '0.01'