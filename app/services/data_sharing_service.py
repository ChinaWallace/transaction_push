# -*- coding: utf-8 -*-
"""
æ•°æ®å…±äº«æœåŠ¡
Data Sharing Service - ä¸ºå…¶ä»–æœåŠ¡æä¾›ä¼˜åŒ–çš„æ•°æ®è®¿é—®æœºåˆ¶
"""

import asyncio
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
import pandas as pd

from app.core.logging import get_logger
from app.core.config import get_settings
from app.services.unified_data_service import (
    get_unified_data_service, 
    DataRequest, 
    DataSource,
    get_shared_market_data
)

logger = get_logger(__name__)
settings = get_settings()


class DataSharingService:
    """
    æ•°æ®å…±äº«æœåŠ¡
    
    ä¸ºå…¶ä»–æœåŠ¡æä¾›é«˜æ•ˆçš„æ•°æ®è®¿é—®ï¼Œé¿å…é‡å¤è·å–ç›¸åŒæ•°æ®
    """
    
    def __init__(self):
        self.logger = get_logger(self.__class__.__name__)
        self._unified_service = None
        
        # å¸¸ç”¨æ•°æ®çš„å¿«é€Ÿè®¿é—®ç¼“å­˜
        self._hot_data_cache = {}
        self._cache_lock = asyncio.Lock()
        
        # è®¢é˜…è€…ç®¡ç†
        self._subscribers = {}
        
    async def _get_unified_service(self):
        """è·å–ç»Ÿä¸€æ•°æ®æœåŠ¡"""
        if self._unified_service is None:
            self._unified_service = await get_unified_data_service()
        return self._unified_service
    
    async def get_market_data_for_analysis(self, symbol: str, 
                                         timeframes: List[str] = None) -> Dict[str, pd.DataFrame]:
        """
        ä¸ºåˆ†ææœåŠ¡è·å–å¸‚åœºæ•°æ®
        ä¼˜å…ˆä½¿ç”¨å…±äº«æ•°æ®ï¼Œå‡å°‘é‡å¤è¯·æ±‚
        """
        if timeframes is None:
            timeframes = ['1h', '4h', '1d']
        
        try:
            market_data = {}
            
            # é¦–å…ˆå°è¯•è·å–å…±äº«æ•°æ®
            for timeframe in timeframes:
                shared_data = await get_shared_market_data(symbol, timeframe)
                if shared_data is not None:
                    market_data[timeframe] = shared_data
                    self.logger.debug(f"ğŸ“ˆ ä½¿ç”¨å…±äº«æ•°æ®: {symbol} {timeframe}")
            
            # è·å–ç¼ºå¤±çš„æ•°æ®
            missing_timeframes = [tf for tf in timeframes if tf not in market_data]
            if missing_timeframes:
                unified_service = await self._get_unified_service()
                
                # æ‰¹é‡è¯·æ±‚ç¼ºå¤±çš„æ•°æ®
                requests = []
                for timeframe in missing_timeframes:
                    request = DataRequest(
                        symbol=symbol,
                        timeframe=timeframe,
                        limit=200,  # åˆ†æé€šå¸¸ä¸éœ€è¦å¤ªå¤šå†å²æ•°æ®
                        source=DataSource.AUTO,
                        use_cache=True
                    )
                    requests.append(request)
                
                results = await unified_service.batch_get_kline_data(requests)
                
                for result in results:
                    market_data[result.timeframe] = result.data
                    self.logger.debug(f"ğŸ“Š è·å–æ–°æ•°æ®: {symbol} {result.timeframe}")
            
            self.logger.info(f"âœ… ä¸ºåˆ†ææœåŠ¡æä¾› {symbol} æ•°æ®: {len(market_data)} ä¸ªå‘¨æœŸ")
            return market_data
            
        except Exception as e:
            self.logger.error(f"âŒ è·å–åˆ†ææ•°æ®å¤±è´¥: {symbol} - {e}")
            return {}
    
    async def get_funding_rates_batch(self, symbols: List[str]) -> Dict[str, Any]:
        """
        æ‰¹é‡è·å–èµ„é‡‘è´¹ç‡ï¼Œæ”¯æŒæ•°æ®å…±äº«
        """
        try:
            async with self._cache_lock:
                cache_key = "funding_rates_batch"
                
                # æ£€æŸ¥ç¼“å­˜ï¼ˆ5åˆ†é’Ÿå†…çš„æ•°æ®ï¼‰
                if (cache_key in self._hot_data_cache and 
                    datetime.now() - self._hot_data_cache[cache_key]['timestamp'] < timedelta(minutes=5)):
                    
                    cached_rates = self._hot_data_cache[cache_key]['data']
                    
                    # è¿”å›è¯·æ±‚çš„å¸ç§æ•°æ®
                    result = {symbol: cached_rates.get(symbol) for symbol in symbols if symbol in cached_rates}
                    self.logger.debug(f"ğŸ“ˆ ä½¿ç”¨ç¼“å­˜è´¹ç‡æ•°æ®: {len(result)} ä¸ªå¸ç§")
                    return result
            
            # è·å–æ–°æ•°æ®
            unified_service = await self._get_unified_service()
            all_rates = await unified_service.get_funding_rates(symbols)
            
            # æ›´æ–°ç¼“å­˜
            async with self._cache_lock:
                self._hot_data_cache[cache_key] = {
                    'data': all_rates,
                    'timestamp': datetime.now()
                }
            
            self.logger.info(f"âœ… æ‰¹é‡è·å–è´¹ç‡æ•°æ®: {len(all_rates)} ä¸ªå¸ç§")
            return all_rates
            
        except Exception as e:
            self.logger.error(f"âŒ æ‰¹é‡è·å–è´¹ç‡æ•°æ®å¤±è´¥: {e}")
            return {}
    
    async def get_top_symbols_data(self, count: int = 20) -> Dict[str, Dict[str, pd.DataFrame]]:
        """
        è·å–çƒ­é—¨å¸ç§çš„æ•°æ®ï¼Œå¤šæœåŠ¡å…±äº«
        """
        try:
            # è·å–çƒ­é—¨å¸ç§åˆ—è¡¨ï¼ˆè¿™é‡Œç®€åŒ–ä¸ºä½¿ç”¨é…ç½®ä¸­çš„å¸ç§ï¼‰
            hot_symbols = settings.monitored_symbols + settings.funding_rate_only_symbols[:count-len(settings.monitored_symbols)]
            hot_symbols = hot_symbols[:count]
            
            result = {}
            
            # å¹¶å‘è·å–å¤šä¸ªå¸ç§çš„å¤šå‘¨æœŸæ•°æ®
            tasks = []
            for symbol in hot_symbols:
                task = self.get_market_data_for_analysis(symbol, ['1h', '4h'])
                tasks.append((symbol, task))
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            for symbol, task in tasks:
                try:
                    data = await task
                    if data:
                        result[symbol] = data
                except Exception as e:
                    self.logger.warning(f"è·å– {symbol} æ•°æ®å¤±è´¥: {e}")
            
            self.logger.info(f"âœ… è·å–çƒ­é—¨å¸ç§æ•°æ®: {len(result)} ä¸ªå¸ç§")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ è·å–çƒ­é—¨å¸ç§æ•°æ®å¤±è´¥: {e}")
            return {}
    
    async def subscribe_to_data_updates(self, service_name: str, symbols: List[str], 
                                      callback) -> bool:
        """
        è®¢é˜…æ•°æ®æ›´æ–°ï¼ˆä¸ºæœªæ¥æ‰©å±•é¢„ç•™ï¼‰
        """
        try:
            if service_name not in self._subscribers:
                self._subscribers[service_name] = {
                    'symbols': set(),
                    'callback': callback,
                    'last_update': datetime.now()
                }
            
            self._subscribers[service_name]['symbols'].update(symbols)
            self.logger.info(f"âœ… æœåŠ¡ {service_name} è®¢é˜…æ•°æ®æ›´æ–°: {len(symbols)} ä¸ªå¸ç§")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ è®¢é˜…æ•°æ®æ›´æ–°å¤±è´¥: {e}")
            return False
    
    async def get_shared_indicators(self, symbol: str, timeframe: str = "1h") -> Dict[str, Any]:
        """
        è·å–å…±äº«çš„æŠ€æœ¯æŒ‡æ ‡æ•°æ®
        é¿å…å¤šä¸ªæœåŠ¡é‡å¤è®¡ç®—ç›¸åŒæŒ‡æ ‡
        """
        try:
            cache_key = f"indicators_{symbol}_{timeframe}"
            
            async with self._cache_lock:
                # æ£€æŸ¥ç¼“å­˜ï¼ˆ2åˆ†é’Ÿå†…çš„æŒ‡æ ‡ï¼‰
                if (cache_key in self._hot_data_cache and 
                    datetime.now() - self._hot_data_cache[cache_key]['timestamp'] < timedelta(minutes=2)):
                    
                    self.logger.debug(f"ğŸ“ˆ ä½¿ç”¨ç¼“å­˜æŒ‡æ ‡: {symbol} {timeframe}")
                    return self._hot_data_cache[cache_key]['data']
            
            # è·å–å¸‚åœºæ•°æ®
            market_data = await self.get_market_data_for_analysis(symbol, [timeframe])
            if timeframe not in market_data or market_data[timeframe].empty:
                return {}
            
            df = market_data[timeframe]
            
            # è®¡ç®—å¸¸ç”¨æŠ€æœ¯æŒ‡æ ‡
            indicators = {}
            
            if len(df) >= 20:
                # ç§»åŠ¨å¹³å‡çº¿
                indicators['ma_20'] = df['close'].rolling(20).mean().iloc[-1]
                indicators['ma_50'] = df['close'].rolling(50).mean().iloc[-1] if len(df) >= 50 else None
                
                # ä»·æ ¼å˜åŒ–
                indicators['price_change_24h'] = ((df['close'].iloc[-1] - df['close'].iloc[-25]) / df['close'].iloc[-25] * 100) if len(df) >= 25 else None
                
                # æˆäº¤é‡æŒ‡æ ‡
                indicators['volume_avg_20'] = df['volume'].rolling(20).mean().iloc[-1]
                indicators['volume_ratio'] = df['volume'].iloc[-1] / indicators['volume_avg_20']
                
                # æ³¢åŠ¨ç‡
                indicators['volatility'] = df['close'].pct_change().rolling(20).std().iloc[-1] * 100
                
                # å½“å‰ä»·æ ¼ä¿¡æ¯
                indicators['current_price'] = df['close'].iloc[-1]
                indicators['high_24h'] = df['high'].tail(24).max() if len(df) >= 24 else df['high'].max()
                indicators['low_24h'] = df['low'].tail(24).min() if len(df) >= 24 else df['low'].min()
            
            # ç¼“å­˜æŒ‡æ ‡
            async with self._cache_lock:
                self._hot_data_cache[cache_key] = {
                    'data': indicators,
                    'timestamp': datetime.now()
                }
            
            self.logger.debug(f"ğŸ“Š è®¡ç®—æŠ€æœ¯æŒ‡æ ‡: {symbol} {timeframe}")
            return indicators
            
        except Exception as e:
            self.logger.error(f"âŒ è·å–æŠ€æœ¯æŒ‡æ ‡å¤±è´¥: {symbol} {timeframe} - {e}")
            return {}
    
    async def get_service_stats(self) -> Dict[str, Any]:
        """è·å–æ•°æ®å…±äº«æœåŠ¡ç»Ÿè®¡"""
        try:
            unified_service = await self._get_unified_service()
            unified_stats = unified_service.get_stats()
            
            return {
                "data_sharing": {
                    "hot_cache_size": len(self._hot_data_cache),
                    "subscribers_count": len(self._subscribers),
                    "subscribers": list(self._subscribers.keys())
                },
                "unified_service": unified_stats
            }
            
        except Exception as e:
            self.logger.error(f"è·å–æœåŠ¡ç»Ÿè®¡å¤±è´¥: {e}")
            return {}
    
    async def cleanup_cache(self):
        """æ¸…ç†è¿‡æœŸç¼“å­˜"""
        try:
            current_time = datetime.now()
            expired_keys = []
            
            async with self._cache_lock:
                for key, cache_entry in self._hot_data_cache.items():
                    # æ¸…ç†è¶…è¿‡10åˆ†é’Ÿçš„ç¼“å­˜
                    if current_time - cache_entry['timestamp'] > timedelta(minutes=10):
                        expired_keys.append(key)
                
                for key in expired_keys:
                    del self._hot_data_cache[key]
            
            if expired_keys:
                self.logger.info(f"ğŸ§¹ æ¸…ç†è¿‡æœŸç¼“å­˜: {len(expired_keys)} ä¸ªæ¡ç›®")
                
        except Exception as e:
            self.logger.error(f"æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")


# å…¨å±€æ•°æ®å…±äº«æœåŠ¡å®ä¾‹
_data_sharing_service = None


async def get_data_sharing_service() -> DataSharingService:
    """è·å–æ•°æ®å…±äº«æœåŠ¡å®ä¾‹"""
    global _data_sharing_service
    if _data_sharing_service is None:
        _data_sharing_service = DataSharingService()
    return _data_sharing_service


# ä¾¿æ·å‡½æ•°
async def get_analysis_data(symbol: str, timeframes: List[str] = None) -> Dict[str, pd.DataFrame]:
    """ä¾¿æ·å‡½æ•°ï¼šè·å–åˆ†ææ•°æ®"""
    service = await get_data_sharing_service()
    return await service.get_market_data_for_analysis(symbol, timeframes)


async def get_batch_funding_rates(symbols: List[str]) -> Dict[str, Any]:
    """ä¾¿æ·å‡½æ•°ï¼šæ‰¹é‡è·å–è´¹ç‡æ•°æ®"""
    service = await get_data_sharing_service()
    return await service.get_funding_rates_batch(symbols)


async def get_technical_indicators(symbol: str, timeframe: str = "1h") -> Dict[str, Any]:
    """ä¾¿æ·å‡½æ•°ï¼šè·å–æŠ€æœ¯æŒ‡æ ‡"""
    service = await get_data_sharing_service()
    return await service.get_shared_indicators(symbol, timeframe)
