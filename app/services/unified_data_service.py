# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€æ•°æ®æœåŠ¡
Unified Data Service - æä¾›ç»Ÿä¸€çš„æ•°æ®è·å–ã€ç¼“å­˜å’Œå…±äº«æœºåˆ¶
"""

import asyncio
import time
from typing import Dict, List, Any, Optional, Union
from datetime import datetime, timedelta
from dataclasses import dataclass
from enum import Enum
import pandas as pd

from app.core.logging import get_logger
from app.core.config import get_settings
from app.data.data_cache import DataCache
from app.services.binance_service import BinanceService
from app.services.okx_service import OKXService
from app.utils.exceptions import DataNotFoundError, ServiceUnavailableError

logger = get_logger(__name__)
settings = get_settings()


class DataSource(Enum):
    """æ•°æ®æºæšä¸¾"""
    BINANCE = "binance"
    OKX = "okx"
    AUTO = "auto"  # è‡ªåŠ¨é€‰æ‹©æœ€ä½³æ•°æ®æº


@dataclass
class DataRequest:
    """æ•°æ®è¯·æ±‚é…ç½®"""
    symbol: str
    timeframe: str = "1h"
    limit: int = 500
    source: DataSource = DataSource.AUTO
    use_cache: bool = True
    cache_ttl_minutes: int = 2


@dataclass
class MarketDataResult:
    """å¸‚åœºæ•°æ®ç»“æœ"""
    data: pd.DataFrame
    source: str
    timestamp: datetime
    cached: bool
    symbol: str
    timeframe: str


class UnifiedDataService:
    """
    ç»Ÿä¸€æ•°æ®æœåŠ¡
    
    åŠŸèƒ½ç‰¹æ€§ï¼š
    1. ç»Ÿä¸€çš„æ•°æ®è·å–æ¥å£
    2. æ™ºèƒ½ç¼“å­˜ç®¡ç†
    3. å¤šæ•°æ®æºæ”¯æŒ
    4. è‡ªåŠ¨æ•…éšœè½¬ç§»
    5. æ•°æ®å…±äº«æœºåˆ¶
    """
    
    def __init__(self):
        self.logger = get_logger(self.__class__.__name__)
        self.cache = DataCache()
        
        # æ•°æ®æºä¼˜å…ˆçº§é…ç½®
        self.source_priority = [DataSource.BINANCE, DataSource.OKX]
        
        # æœåŠ¡å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
        self._binance_service = None
        self._okx_service = None
        
        # æ•°æ®æºå¥åº·çŠ¶æ€
        self._source_health = {
            DataSource.BINANCE: {"healthy": True, "last_check": None, "error_count": 0},
            DataSource.OKX: {"healthy": True, "last_check": None, "error_count": 0}
        }
        
        # è¯·æ±‚ç»Ÿè®¡
        self._stats = {
            "total_requests": 0,
            "cache_hits": 0,
            "cache_misses": 0,
            "source_requests": {source.value: 0 for source in DataSource if source != DataSource.AUTO},
            "errors": {"total": 0, "by_source": {source.value: 0 for source in DataSource if source != DataSource.AUTO}}
        }
        
        # æ•°æ®å…±äº«å­˜å‚¨ï¼ˆä¾›å¤šæœåŠ¡å…±äº«çš„çƒ­ç‚¹æ•°æ®ï¼‰
        self._shared_data = {}
        self._shared_data_lock = asyncio.Lock()
    
    async def _get_binance_service(self) -> BinanceService:
        """è·å–å¸å®‰æœåŠ¡å®ä¾‹"""
        if self._binance_service is None:
            self._binance_service = BinanceService()
        return self._binance_service
    
    async def _get_okx_service(self) -> OKXService:
        """è·å–OKXæœåŠ¡å®ä¾‹"""
        if self._okx_service is None:
            self._okx_service = OKXService()
        return self._okx_service
    
    async def get_kline_data(self, request: DataRequest) -> MarketDataResult:
        """
        è·å–Kçº¿æ•°æ® - ç»Ÿä¸€å…¥å£
        
        Args:
            request: æ•°æ®è¯·æ±‚é…ç½®
            
        Returns:
            å¸‚åœºæ•°æ®ç»“æœ
        """
        self._stats["total_requests"] += 1
        start_time = time.time()
        
        try:
            # æ£€æŸ¥ç¼“å­˜
            if request.use_cache:
                cached_data = await self._get_cached_data(request)
                if cached_data is not None:
                    self._stats["cache_hits"] += 1
                    self.logger.debug(f"âœ… ç¼“å­˜å‘½ä¸­: {request.symbol} {request.timeframe}")
                    return MarketDataResult(
                        data=cached_data,
                        source="cache",
                        timestamp=datetime.now(),
                        cached=True,
                        symbol=request.symbol,
                        timeframe=request.timeframe
                    )
            
            self._stats["cache_misses"] += 1
            
            # ç¡®å®šæ•°æ®æº
            data_source = await self._determine_data_source(request.source)
            
            # è·å–æ•°æ®
            data = await self._fetch_from_source(data_source, request)
            
            # ç¼“å­˜æ•°æ®
            if request.use_cache and not data.empty:
                await self._cache_data(request, data)
            
            # æ›´æ–°å…±äº«æ•°æ®ï¼ˆçƒ­ç‚¹æ•°æ®ï¼‰
            await self._update_shared_data(request, data)
            
            elapsed_time = time.time() - start_time
            self.logger.info(f"ğŸ¯ æ•°æ®è·å–å®Œæˆ: {request.symbol} {request.timeframe} "
                           f"from {data_source.value} ({elapsed_time:.2f}s)")
            
            return MarketDataResult(
                data=data,
                source=data_source.value,
                timestamp=datetime.now(),
                cached=False,
                symbol=request.symbol,
                timeframe=request.timeframe
            )
            
        except Exception as e:
            self._stats["errors"]["total"] += 1
            self.logger.error(f"âŒ æ•°æ®è·å–å¤±è´¥: {request.symbol} {request.timeframe} - {e}")
            raise DataNotFoundError(f"è·å– {request.symbol} æ•°æ®å¤±è´¥: {e}")
    
    async def _get_cached_data(self, request: DataRequest) -> Optional[pd.DataFrame]:
        """è·å–ç¼“å­˜æ•°æ®"""
        try:
            # æ„å»ºç¼“å­˜é”®
            cache_key = f"{request.symbol}_{request.timeframe}_{request.limit}"
            
            # æ£€æŸ¥å†…å­˜ç¼“å­˜
            if cache_key in self.cache.memory_cache:
                cache_entry = self.cache.memory_cache[cache_key]
                if self.cache._is_cache_valid(cache_entry):
                    return cache_entry['data']
            
            # æ£€æŸ¥ç£ç›˜ç¼“å­˜
            cached_data = await self.cache.get_ohlcv(
                symbol=request.symbol,
                timeframe=request.timeframe,
                exchange="unified",  # ä½¿ç”¨ç»Ÿä¸€æ ‡è¯†
                limit=request.limit
            )
            
            return cached_data
            
        except Exception as e:
            self.logger.warning(f"è·å–ç¼“å­˜æ•°æ®å¤±è´¥: {e}")
            return None
    
    async def _cache_data(self, request: DataRequest, data: pd.DataFrame):
        """ç¼“å­˜æ•°æ®"""
        try:
            await self.cache.set_ohlcv(
                symbol=request.symbol,
                timeframe=request.timeframe,
                exchange="unified",
                data=data,
                limit=request.limit
            )
            self.logger.debug(f"ğŸ’¾ æ•°æ®å·²ç¼“å­˜: {request.symbol} {request.timeframe}")
            
        except Exception as e:
            self.logger.warning(f"ç¼“å­˜æ•°æ®å¤±è´¥: {e}")
    
    async def _determine_data_source(self, preferred_source: DataSource) -> DataSource:
        """ç¡®å®šæœ€ä½³æ•°æ®æº"""
        if preferred_source != DataSource.AUTO:
            # æ£€æŸ¥æŒ‡å®šæ•°æ®æºçš„å¥åº·çŠ¶æ€
            if self._source_health[preferred_source]["healthy"]:
                return preferred_source
            else:
                self.logger.warning(f"æŒ‡å®šæ•°æ®æº {preferred_source.value} ä¸å¥åº·ï¼Œä½¿ç”¨å¤‡ç”¨æ•°æ®æº")
        
        # æŒ‰ä¼˜å…ˆçº§é€‰æ‹©å¥åº·çš„æ•°æ®æº
        for source in self.source_priority:
            if self._source_health[source]["healthy"]:
                return source
        
        # å¦‚æœæ‰€æœ‰æ•°æ®æºéƒ½ä¸å¥åº·ï¼Œé€‰æ‹©é”™è¯¯æœ€å°‘çš„
        best_source = min(
            self.source_priority,
            key=lambda s: self._source_health[s]["error_count"]
        )
        
        self.logger.warning(f"æ‰€æœ‰æ•°æ®æºéƒ½æœ‰é—®é¢˜ï¼Œé€‰æ‹©é”™è¯¯æœ€å°‘çš„: {best_source.value}")
        return best_source
    
    async def _fetch_from_source(self, source: DataSource, request: DataRequest) -> pd.DataFrame:
        """ä»æŒ‡å®šæ•°æ®æºè·å–æ•°æ®"""
        self._stats["source_requests"][source.value] += 1
        
        try:
            if source == DataSource.BINANCE:
                service = await self._get_binance_service()
                klines = await service.get_kline_data(
                    symbol=request.symbol.replace('-SWAP', '').replace('-', ''),  # å¸å®‰æ ¼å¼è½¬æ¢
                    interval=request.timeframe,
                    limit=request.limit
                )
                
                # è½¬æ¢ä¸ºDataFrameï¼ˆè¿™é‡Œéœ€è¦æ ¹æ®å®é™…æ•°æ®æ ¼å¼è°ƒæ•´ï¼‰
                if klines:
                    data = pd.DataFrame([{
                        'timestamp': k['open_time'],
                        'open': float(k['open_price']),
                        'high': float(k['high_price']),
                        'low': float(k['low_price']),
                        'close': float(k['close_price']),
                        'volume': float(k['volume'])
                    } for k in klines])
                    data.set_index('timestamp', inplace=True)
                    self._mark_source_healthy(source)
                    return data
                
            elif source == DataSource.OKX:
                async with await self._get_okx_service() as service:
                    klines = await service.get_kline_data(
                        symbol=request.symbol,
                        timeframe=request.timeframe,
                        limit=request.limit
                    )
                    
                    if klines:
                        data = pd.DataFrame([{
                            'timestamp': pd.to_datetime(k['timestamp'], unit='ms'),
                            'open': k['open'],
                            'high': k['high'],
                            'low': k['low'],
                            'close': k['close'],
                            'volume': k['volume']
                        } for k in klines])
                        data.set_index('timestamp', inplace=True)
                        self._mark_source_healthy(source)
                        return data
            
            # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œæ ‡è®°ä¸ºè½»å¾®é”™è¯¯
            self._mark_source_error(source, is_critical=False)
            return pd.DataFrame()
            
        except Exception as e:
            self._mark_source_error(source, is_critical=True)
            self._stats["errors"]["by_source"][source.value] += 1
            self.logger.error(f"ä» {source.value} è·å–æ•°æ®å¤±è´¥: {e}")
            raise
    
    def _mark_source_healthy(self, source: DataSource):
        """æ ‡è®°æ•°æ®æºä¸ºå¥åº·"""
        health = self._source_health[source]
        health["healthy"] = True
        health["last_check"] = datetime.now()
        health["error_count"] = max(0, health["error_count"] - 1)  # é€æ¸æ¢å¤
    
    def _mark_source_error(self, source: DataSource, is_critical: bool = True):
        """æ ‡è®°æ•°æ®æºé”™è¯¯"""
        health = self._source_health[source]
        health["error_count"] += 1 if is_critical else 0.5
        health["last_check"] = datetime.now()
        
        # é”™è¯¯è¶…è¿‡é˜ˆå€¼æ—¶æ ‡è®°ä¸ºä¸å¥åº·
        if health["error_count"] >= 3:
            health["healthy"] = False
            self.logger.warning(f"æ•°æ®æº {source.value} æ ‡è®°ä¸ºä¸å¥åº·")
    
    async def _update_shared_data(self, request: DataRequest, data: pd.DataFrame):
        """æ›´æ–°å…±äº«æ•°æ®å­˜å‚¨"""
        try:
            # åªç¼“å­˜çƒ­ç‚¹æ•°æ®ï¼ˆä¸»è¦ç›‘æ§å¸ç§çš„1å°æ—¶æ•°æ®ï¼‰
            if (request.symbol in settings.monitored_symbols and 
                request.timeframe in ['1h', '4h'] and 
                not data.empty):
                
                async with self._shared_data_lock:
                    key = f"{request.symbol}_{request.timeframe}"
                    self._shared_data[key] = {
                        'data': data.copy(),
                        'timestamp': datetime.now(),
                        'symbol': request.symbol,
                        'timeframe': request.timeframe
                    }
                    
                    self.logger.debug(f"ğŸ“Š å…±äº«æ•°æ®å·²æ›´æ–°: {key}")
        
        except Exception as e:
            self.logger.warning(f"æ›´æ–°å…±äº«æ•°æ®å¤±è´¥: {e}")
    
    async def get_shared_data(self, symbol: str, timeframe: str) -> Optional[pd.DataFrame]:
        """è·å–å…±äº«æ•°æ®"""
        try:
            async with self._shared_data_lock:
                key = f"{symbol}_{timeframe}"
                if key in self._shared_data:
                    shared_entry = self._shared_data[key]
                    
                    # æ£€æŸ¥æ•°æ®æ˜¯å¦è¿˜æ–°é²œï¼ˆ5åˆ†é’Ÿå†…ï¼‰
                    age = datetime.now() - shared_entry['timestamp']
                    if age < timedelta(minutes=5):
                        self.logger.debug(f"ğŸ“ˆ å…±äº«æ•°æ®å‘½ä¸­: {key}")
                        return shared_entry['data'].copy()
                    else:
                        # åˆ é™¤è¿‡æœŸæ•°æ®
                        del self._shared_data[key]
                        
            return None
            
        except Exception as e:
            self.logger.warning(f"è·å–å…±äº«æ•°æ®å¤±è´¥: {e}")
            return None
    
    async def batch_get_kline_data(self, requests: List[DataRequest]) -> List[MarketDataResult]:
        """æ‰¹é‡è·å–Kçº¿æ•°æ®"""
        self.logger.info(f"ğŸš€ å¼€å§‹æ‰¹é‡è·å–æ•°æ®ï¼Œæ€»è®¡ {len(requests)} ä¸ªè¯·æ±‚")
        
        # å¹¶å‘è·å–æ•°æ®
        tasks = [self.get_kline_data(request) for request in requests]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†ç»“æœ
        successful_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                self.logger.error(f"æ‰¹é‡è¯·æ±‚å¤±è´¥: {requests[i].symbol} - {result}")
            else:
                successful_results.append(result)
        
        self.logger.debug(f"âœ… æ‰¹é‡è·å–å®Œæˆ: {len(successful_results)}/{len(requests)} æˆåŠŸ")
        return successful_results
    
    async def get_funding_rates(self, symbols: List[str]) -> Dict[str, Any]:
        """è·å–èµ„é‡‘è´¹ç‡æ•°æ®ï¼ˆç»Ÿä¸€æ¥å£ï¼‰"""
        try:
            # ä¼˜å…ˆä½¿ç”¨OKXï¼ˆæ”¯æŒæ›´å¤šå¸ç§ï¼‰
            async with await self._get_okx_service() as okx_service:
                rates = await okx_service.get_batch_funding_rates(symbols)
                
                # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
                result = {}
                for rate in rates:
                    if rate and 'symbol' in rate:
                        result[rate['symbol']] = {
                            'funding_rate': rate['funding_rate'],
                            'next_funding_time': rate.get('next_funding_time'),
                            'source': 'okx',
                            'timestamp': datetime.now()
                        }
                
                self.logger.info(f"ğŸ“Š è·å–è´¹ç‡æ•°æ®: {len(result)} ä¸ªå¸ç§")
                return result
                
        except Exception as e:
            self.logger.error(f"è·å–è´¹ç‡æ•°æ®å¤±è´¥: {e}")
            return {}
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–æœåŠ¡ç»Ÿè®¡ä¿¡æ¯"""
        cache_hit_rate = 0
        if self._stats["total_requests"] > 0:
            cache_hit_rate = self._stats["cache_hits"] / self._stats["total_requests"]
        
        return {
            "requests": self._stats,
            "cache_hit_rate": f"{cache_hit_rate:.2%}",
            "source_health": self._source_health,
            "shared_data_count": len(self._shared_data),
            "cache_stats": self.cache.get_cache_stats()
        }
    
    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        health_status = {"overall": "healthy", "sources": {}}
        
        try:
            # æ£€æŸ¥å¸å®‰æœåŠ¡
            binance_service = await self._get_binance_service()
            binance_healthy = await binance_service.health_check()
            health_status["sources"]["binance"] = "healthy" if binance_healthy else "unhealthy"
            
            # æ£€æŸ¥OKXæœåŠ¡
            async with await self._get_okx_service() as okx_service:
                okx_healthy = await okx_service.health_check()
                health_status["sources"]["okx"] = "healthy" if okx_healthy else "unhealthy"
            
            # æ›´æ–°å¥åº·çŠ¶æ€
            self._source_health[DataSource.BINANCE]["healthy"] = binance_healthy
            self._source_health[DataSource.OKX]["healthy"] = okx_healthy
            
            # åˆ¤æ–­æ•´ä½“å¥åº·çŠ¶æ€
            if not binance_healthy and not okx_healthy:
                health_status["overall"] = "critical"
            elif not binance_healthy or not okx_healthy:
                health_status["overall"] = "degraded"
            
        except Exception as e:
            self.logger.error(f"å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            health_status["overall"] = "error"
            health_status["error"] = str(e)
        
        return health_status
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            # æ¸…ç†å…±äº«æ•°æ®
            async with self._shared_data_lock:
                self._shared_data.clear()
            
            # æ¸…ç†ç¼“å­˜
            await self.cache.invalidate()
            
            self.logger.info("ğŸ§¹ ç»Ÿä¸€æ•°æ®æœåŠ¡èµ„æºå·²æ¸…ç†")
            
        except Exception as e:
            self.logger.error(f"æ¸…ç†èµ„æºå¤±è´¥: {e}")


# å…¨å±€ç»Ÿä¸€æ•°æ®æœåŠ¡å®ä¾‹
_unified_data_service = None


async def get_unified_data_service() -> UnifiedDataService:
    """è·å–ç»Ÿä¸€æ•°æ®æœåŠ¡å®ä¾‹"""
    global _unified_data_service
    if _unified_data_service is None:
        _unified_data_service = UnifiedDataService()
    return _unified_data_service


# ä¾¿æ·å‡½æ•°
async def get_market_data(symbol: str, timeframe: str = "1h", 
                         limit: int = 500, source: DataSource = DataSource.AUTO) -> MarketDataResult:
    """ä¾¿æ·å‡½æ•°ï¼šè·å–å¸‚åœºæ•°æ®"""
    service = await get_unified_data_service()
    request = DataRequest(symbol=symbol, timeframe=timeframe, limit=limit, source=source)
    return await service.get_kline_data(request)


async def get_shared_market_data(symbol: str, timeframe: str = "1h") -> Optional[pd.DataFrame]:
    """ä¾¿æ·å‡½æ•°ï¼šè·å–å…±äº«å¸‚åœºæ•°æ®"""
    service = await get_unified_data_service()
    return await service.get_shared_data(symbol, timeframe)
