# -*- coding: utf-8 -*-
"""
å®Œæ•´å›æµ‹æœåŠ¡
Complete Backtesting Service - é«˜çº§å›æµ‹åŠŸèƒ½å’Œç­–ç•¥ä¼˜åŒ–
"""

from typing import Dict, Any, List, Optional, Tuple, Union, Callable
from datetime import datetime, timedelta
from enum import Enum
from dataclasses import dataclass, field
import asyncio
import numpy as np
import pandas as pd
from decimal import Decimal, ROUND_HALF_UP
import json
import itertools
from concurrent.futures import ThreadPoolExecutor
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import pickle

from app.core.logging import get_logger, trading_logger
from app.core.config import get_settings
from app.services.backtest_service import BacktestService, BacktestEngine, BacktestMetrics, BacktestTrade
from app.services.trend_analysis_service import TrendAnalysisService
from app.services.ml_enhanced_service import MLEnhancedService
from app.utils.indicators import SuperTrendIndicator, calculate_support_resistance
from app.utils.exceptions import TradingToolError, BacktestError

logger = get_logger(__name__)
settings = get_settings()


class OptimizationMethod(Enum):
    """ä¼˜åŒ–æ–¹æ³•"""
    GRID_SEARCH = "grid_search"
    RANDOM_SEARCH = "random_search"
    GENETIC_ALGORITHM = "genetic_algorithm"
    BAYESIAN_OPTIMIZATION = "bayesian_optimization"


class RiskMetric(Enum):
    """é£é™©æŒ‡æ ‡ç±»å‹"""
    MAX_DRAWDOWN = "max_drawdown"
    SHARPE_RATIO = "sharpe_ratio"
    SORTINO_RATIO = "sortino_ratio"
    VAR_95 = "var_95"
    CALMAR_RATIO = "calmar_ratio"


@dataclass
class StrategyParameter:
    """ç­–ç•¥å‚æ•°å®šä¹‰"""
    name: str
    min_value: Union[int, float]
    max_value: Union[int, float]
    step: Union[int, float]
    param_type: type = float
    description: str = ""


@dataclass
class OptimizationResult:
    """ä¼˜åŒ–ç»“æœ"""
    best_params: Dict[str, Any]
    best_score: float
    optimization_metric: str
    all_results: List[Dict[str, Any]]
    optimization_time: float
    total_combinations: int


@dataclass
class RiskManagementConfig:
    """é£é™©ç®¡ç†é…ç½®"""
    max_position_size: float = 0.1  # æœ€å¤§ä»“ä½æ¯”ä¾‹
    max_daily_drawdown: float = 0.05  # æœ€å¤§æ—¥å›æ’¤
    max_total_drawdown: float = 0.20  # æœ€å¤§æ€»å›æ’¤
    position_size_method: str = "fixed"  # fixed, kelly, volatility
    stop_loss_method: str = "technical"  # fixed, technical, volatility
    take_profit_method: str = "technical"  # fixed, technical, risk_reward
    risk_reward_ratio: float = 2.0  # é£é™©æ”¶ç›Šæ¯”
    enable_position_sizing: bool = True
    enable_dynamic_stops: bool = True


@dataclass
class PortfolioConfig:
    """æŠ•èµ„ç»„åˆé…ç½®"""
    symbols: List[str]
    weights: Optional[Dict[str, float]] = None  # æƒé‡åˆ†é…
    rebalance_frequency: str = "weekly"  # daily, weekly, monthly
    max_correlation: float = 0.8  # æœ€å¤§ç›¸å…³æ€§
    min_symbols: int = 3  # æœ€å°‘äº¤æ˜“å¯¹æ•°é‡
    max_symbols: int = 10  # æœ€å¤šäº¤æ˜“å¯¹æ•°é‡


class AdvancedBacktestEngine(BacktestEngine):
    """é«˜çº§å›æµ‹å¼•æ“"""
    
    def __init__(self, risk_config: RiskManagementConfig = None):
        super().__init__()
        self.risk_config = risk_config or RiskManagementConfig()
        self.portfolio_history: List[Dict[str, Any]] = []
        self.risk_events: List[Dict[str, Any]] = []
        self.performance_attribution: Dict[str, Any] = {}
        
    async def run_portfolio_backtest(
        self,
        portfolio_config: PortfolioConfig,
        start_date: datetime,
        end_date: datetime,
        initial_balance: float = 100000.0,
        interval: str = "1h",
        strategy_configs: Dict[str, Any] = None,
        rebalance_threshold: float = 0.05
    ) -> Dict[str, Any]:
        """è¿è¡ŒæŠ•èµ„ç»„åˆå›æµ‹"""
        try:
            logger.info(f"ğŸš€ å¼€å§‹æŠ•èµ„ç»„åˆå›æµ‹: {portfolio_config.symbols}")
            
            # åˆå§‹åŒ–å›æµ‹
            await self.initialize_backtest(start_date, end_date, initial_balance, portfolio_config.symbols)
            
            # è·å–æ‰€æœ‰äº¤æ˜“å¯¹æ•°æ®
            symbol_data = {}
            for symbol in portfolio_config.symbols:
                try:
                    data = await self.get_market_data(symbol, start_date, end_date, interval)
                    if not data.empty:
                        symbol_data[symbol] = data
                        logger.info(f"ğŸ“Š å·²åŠ è½½ {symbol} æ•°æ®: {len(data)} æ¡è®°å½•")
                except Exception as e:
                    logger.error(f"âŒ è·å– {symbol} æ•°æ®å¤±è´¥: {e}")
                    continue
            
            if len(symbol_data) < portfolio_config.min_symbols:
                raise BacktestError(f"å¯ç”¨äº¤æ˜“å¯¹ä¸è¶³ï¼Œéœ€è¦è‡³å°‘ {portfolio_config.min_symbols} ä¸ª")
            
            # è®¡ç®—åˆå§‹æƒé‡
            weights = self._calculate_portfolio_weights(portfolio_config, symbol_data)
            
            # è·å–é‡æ–°å¹³è¡¡æ—¶é—´ç‚¹
            rebalance_dates = self._get_rebalance_dates(
                start_date, end_date, portfolio_config.rebalance_frequency
            )
            
            # æŒ‰æ—¶é—´é¡ºåºæ‰§è¡Œå›æµ‹
            all_timestamps = self._get_all_timestamps(symbol_data)
            next_rebalance = 0
            
            for i, timestamp in enumerate(all_timestamps):
                self.current_time = timestamp
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°å¹³è¡¡
                if (next_rebalance < len(rebalance_dates) and 
                    timestamp >= rebalance_dates[next_rebalance]):
                    
                    # æ‰§è¡ŒæŠ•èµ„ç»„åˆé‡æ–°å¹³è¡¡
                    await self._rebalance_portfolio(
                        symbol_data, weights, timestamp, rebalance_threshold
                    )
                    next_rebalance += 1
                
                # ä¸ºæ¯ä¸ªäº¤æ˜“å¯¹æ‰§è¡Œç­–ç•¥
                portfolio_value = await self._execute_portfolio_strategy(
                    symbol_data, weights, timestamp, strategy_configs
                )
                
                # è®°å½•æŠ•èµ„ç»„åˆå†å²
                self.portfolio_history.append({
                    'timestamp': timestamp,
                    'total_value': portfolio_value,
                    'positions': dict(self.positions),
                    'weights': weights.copy()
                })
                
                # é£é™©æ£€æŸ¥
                await self._check_portfolio_risk(portfolio_value)
                
                if i % 100 == 0:
                    logger.info(f"ğŸ“ˆ å·²å¤„ç† {i}/{len(all_timestamps)} ä¸ªæ—¶é—´ç‚¹")
            
            # è®¡ç®—æŠ•èµ„ç»„åˆæŒ‡æ ‡
            portfolio_metrics = await self._calculate_portfolio_metrics()
            
            # ç”ŸæˆæŠ•èµ„ç»„åˆæŠ¥å‘Š
            portfolio_report = await self._generate_portfolio_report(
                portfolio_metrics, symbol_data, portfolio_config
            )
            
            logger.info(f"âœ… æŠ•èµ„ç»„åˆå›æµ‹å®Œæˆ")
            
            return {
                "status": "success",
                "portfolio_metrics": portfolio_metrics,
                "individual_metrics": self.calculate_metrics(),
                "portfolio_history": self.portfolio_history,
                "risk_events": self.risk_events,
                "performance_attribution": self.performance_attribution,
                "trades": [self._trade_to_dict(trade) for trade in self.trades],
                "report": portfolio_report,
                "config": {
                    "portfolio_config": portfolio_config.__dict__,
                    "risk_config": self.risk_config.__dict__,
                    "start_date": start_date.isoformat(),
                    "end_date": end_date.isoformat(),
                    "initial_balance": initial_balance
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ æŠ•èµ„ç»„åˆå›æµ‹å¤±è´¥: {e}")
            raise BacktestError(f"æŠ•èµ„ç»„åˆå›æµ‹å¤±è´¥: {str(e)}")
    
    def _calculate_portfolio_weights(
        self,
        portfolio_config: PortfolioConfig,
        symbol_data: Dict[str, pd.DataFrame]
    ) -> Dict[str, float]:
        """è®¡ç®—æŠ•èµ„ç»„åˆæƒé‡"""
        try:
            if portfolio_config.weights:
                # ä½¿ç”¨æŒ‡å®šæƒé‡
                return portfolio_config.weights
            
            # ç­‰æƒé‡åˆ†é…
            num_symbols = len(symbol_data)
            equal_weight = 1.0 / num_symbols
            
            weights = {}
            for symbol in symbol_data.keys():
                weights[symbol] = equal_weight
            
            return weights
            
        except Exception as e:
            logger.error(f"âŒ è®¡ç®—æŠ•èµ„ç»„åˆæƒé‡å¤±è´¥: {e}")
            # è¿”å›ç­‰æƒé‡
            num_symbols = len(symbol_data)
            return {symbol: 1.0/num_symbols for symbol in symbol_data.keys()}
    
    def _get_rebalance_dates(
        self,
        start_date: datetime,
        end_date: datetime,
        frequency: str
    ) -> List[datetime]:
        """è·å–é‡æ–°å¹³è¡¡æ—¥æœŸ"""
        rebalance_dates = []
        current = start_date
        
        if frequency == "daily":
            delta = timedelta(days=1)
        elif frequency == "weekly":
            delta = timedelta(weeks=1)
        elif frequency == "monthly":
            delta = timedelta(days=30)
        else:
            delta = timedelta(weeks=1)  # é»˜è®¤å‘¨é¢‘ç‡
        
        while current <= end_date:
            rebalance_dates.append(current)
            current += delta
        
        return rebalance_dates
    
    def _get_all_timestamps(self, symbol_data: Dict[str, pd.DataFrame]) -> List[datetime]:
        """è·å–æ‰€æœ‰æ—¶é—´æˆ³å¹¶æ’åº"""
        all_timestamps = set()
        for data in symbol_data.values():
            all_timestamps.update(data.index)
        return sorted(all_timestamps)
    
    async def _rebalance_portfolio(
        self,
        symbol_data: Dict[str, pd.DataFrame],
        weights: Dict[str, float],
        timestamp: datetime,
        threshold: float
    ):
        """é‡æ–°å¹³è¡¡æŠ•èµ„ç»„åˆ"""
        try:
            # è®¡ç®—å½“å‰æŠ•èµ„ç»„åˆä»·å€¼
            total_value = self.balance
            for symbol, position in self.positions.items():
                if timestamp in symbol_data[symbol].index:
                    current_price = float(symbol_data[symbol].loc[timestamp, 'close'])
                    position_value = position.size * current_price
                    total_value += position_value
            
            # è®¡ç®—ç›®æ ‡ä»“ä½
            target_positions = {}
            for symbol, weight in weights.items():
                if timestamp in symbol_data[symbol].index:
                    current_price = float(symbol_data[symbol].loc[timestamp, 'close'])
                    target_value = total_value * weight
                    target_size = target_value / current_price
                    target_positions[symbol] = target_size
            
            # æ‰§è¡Œé‡æ–°å¹³è¡¡
            for symbol, target_size in target_positions.items():
                current_position = self.positions.get(symbol)
                current_size = current_position.size if current_position else 0.0
                
                # è®¡ç®—å·®é¢
                size_diff = target_size - current_size
                
                # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é‡æ–°å¹³è¡¡é˜ˆå€¼
                if abs(size_diff) / target_size > threshold:
                    if size_diff > 0:
                        # éœ€è¦ä¹°å…¥
                        await self._create_market_order(
                            symbol=symbol,
                            side="buy",
                            quantity=size_diff,
                            price=float(symbol_data[symbol].loc[timestamp, 'close'])
                        )
                    else:
                        # éœ€è¦å–å‡º
                        await self._create_market_order(
                            symbol=symbol,
                            side="sell",
                            quantity=abs(size_diff),
                            price=float(symbol_data[symbol].loc[timestamp, 'close'])
                        )
            
            logger.info(f"ğŸ”„ æŠ•èµ„ç»„åˆé‡æ–°å¹³è¡¡å®Œæˆ: {timestamp}")
            
        except Exception as e:
            logger.error(f"âŒ é‡æ–°å¹³è¡¡å¤±è´¥: {e}")
    
    async def _execute_portfolio_strategy(
        self,
        symbol_data: Dict[str, pd.DataFrame],
        weights: Dict[str, float],
        timestamp: datetime,
        strategy_configs: Dict[str, Any]
    ) -> float:
        """æ‰§è¡ŒæŠ•èµ„ç»„åˆç­–ç•¥"""
        try:
            total_value = self.balance
            
            for symbol in symbol_data.keys():
                if timestamp not in symbol_data[symbol].index:
                    continue
                
                try:
                    # è·å–å†å²æ•°æ®çª—å£
                    current_idx = symbol_data[symbol].index.get_loc(timestamp)
                    if current_idx < 50:
                        continue
                    
                    window_data = symbol_data[symbol].iloc[:current_idx + 1]
                    current_price = float(symbol_data[symbol].loc[timestamp, 'close'])
                    
                    # æ‰§è¡Œç­–ç•¥åˆ†æ
                    signal_data = await self._analyze_with_strategy(
                        symbol, window_data, strategy_configs
                    )
                    
                    # è°ƒæ•´ä¿¡å·å¼ºåº¦ï¼ˆåŸºäºæŠ•èµ„ç»„åˆæƒé‡ï¼‰
                    if signal_data:
                        symbol_weight = weights.get(symbol, 0.0)
                        signal_data['confidence'] *= symbol_weight
                        
                        # æ‰§è¡Œç­–ç•¥ä¿¡å·
                        await self.execute_strategy_signal(
                            symbol, signal_data, window_data, current_price
                        )
                    
                    # æ›´æ–°æŒä»“æ­¢æŸæ­¢ç›ˆ
                    await self._update_position_stops(symbol, window_data, current_price)
                    
                    # ç´¯è®¡æŠ•èµ„ç»„åˆä»·å€¼
                    position = self.positions.get(symbol)
                    if position:
                        total_value += position.size * current_price
                    
                except Exception as e:
                    logger.error(f"âŒ å¤„ç† {symbol} ç­–ç•¥å¤±è´¥: {e}")
                    continue
            
            return total_value
            
        except Exception as e:
            logger.error(f"âŒ æ‰§è¡ŒæŠ•èµ„ç»„åˆç­–ç•¥å¤±è´¥: {e}")
            return self.balance
    
    async def _check_portfolio_risk(self, portfolio_value: float):
        """æ£€æŸ¥æŠ•èµ„ç»„åˆé£é™©"""
        try:
            # è®¡ç®—å½“å‰å›æ’¤
            if self.portfolio_history:
                peak_value = max(h['total_value'] for h in self.portfolio_history)
                current_drawdown = (peak_value - portfolio_value) / peak_value
                
                # æ£€æŸ¥æœ€å¤§å›æ’¤é™åˆ¶
                if current_drawdown > self.risk_config.max_total_drawdown:
                    # è§¦å‘é£é™©æ§åˆ¶ï¼Œå¼ºåˆ¶å¹³ä»“
                    await self._emergency_liquidation("max_drawdown_exceeded")
                    
                    self.risk_events.append({
                        'timestamp': self.current_time,
                        'event_type': 'max_drawdown_exceeded',
                        'drawdown': current_drawdown,
                        'action': 'emergency_liquidation'
                    })
                    
                    logger.warning(f"âš ï¸ è§¦å‘æœ€å¤§å›æ’¤é£æ§: {current_drawdown:.2%}")
            
            # æ£€æŸ¥æ—¥å›æ’¤
            if len(self.portfolio_history) >= 24:  # 24å°æ—¶æ•°æ®
                daily_start_value = self.portfolio_history[-24]['total_value']
                daily_drawdown = (daily_start_value - portfolio_value) / daily_start_value
                
                if daily_drawdown > self.risk_config.max_daily_drawdown:
                    # æš‚åœäº¤æ˜“
                    self.risk_events.append({
                        'timestamp': self.current_time,
                        'event_type': 'daily_drawdown_exceeded',
                        'drawdown': daily_drawdown,
                        'action': 'trading_suspended'
                    })
                    
                    logger.warning(f"âš ï¸ è§¦å‘æ—¥å›æ’¤é£æ§: {daily_drawdown:.2%}")
            
        except Exception as e:
            logger.error(f"âŒ é£é™©æ£€æŸ¥å¤±è´¥: {e}")
    
    async def _emergency_liquidation(self, reason: str):
        """ç´§æ€¥æ¸…ä»“"""
        try:
            logger.warning(f"ğŸš¨ æ‰§è¡Œç´§æ€¥æ¸…ä»“: {reason}")
            
            for symbol in list(self.positions.keys()):
                await self._close_position(symbol, f"emergency_{reason}")
            
        except Exception as e:
            logger.error(f"âŒ ç´§æ€¥æ¸…ä»“å¤±è´¥: {e}")
    
    async def _calculate_portfolio_metrics(self) -> Dict[str, Any]:
        """è®¡ç®—æŠ•èµ„ç»„åˆæŒ‡æ ‡"""
        try:
            if not self.portfolio_history:
                return {}
            
            # æå–æŠ•èµ„ç»„åˆä»·å€¼åºåˆ—
            values = [h['total_value'] for h in self.portfolio_history]
            timestamps = [h['timestamp'] for h in self.portfolio_history]
            
            # è®¡ç®—æ”¶ç›Šç‡åºåˆ—
            returns = []
            for i in range(1, len(values)):
                ret = (values[i] - values[i-1]) / values[i-1]
                returns.append(ret)
            
            returns_array = np.array(returns)
            
            # åŸºç¡€æŒ‡æ ‡
            total_return = (values[-1] - values[0]) / values[0]
            annualized_return = (1 + total_return) ** (252 / len(values)) - 1
            
            # æ³¢åŠ¨ç‡
            volatility = np.std(returns_array) * np.sqrt(252)
            
            # æœ€å¤§å›æ’¤
            max_drawdown = 0
            peak = values[0]
            for value in values:
                if value > peak:
                    peak = value
                drawdown = (peak - value) / peak
                if drawdown > max_drawdown:
                    max_drawdown = drawdown
            
            # å¤æ™®æ¯”ç‡
            sharpe_ratio = (np.mean(returns_array) * 252) / (np.std(returns_array) * np.sqrt(252)) if np.std(returns_array) > 0 else 0
            
            # Sortinoæ¯”ç‡
            negative_returns = returns_array[returns_array < 0]
            downside_deviation = np.std(negative_returns) * np.sqrt(252) if len(negative_returns) > 0 else 0
            sortino_ratio = (np.mean(returns_array) * 252) / downside_deviation if downside_deviation > 0 else 0
            
            # Calmaræ¯”ç‡
            calmar_ratio = annualized_return / max_drawdown if max_drawdown > 0 else 0
            
            # VaRå’ŒCVaR
            var_95 = np.percentile(returns_array, 5)
            cvar_95 = np.mean(returns_array[returns_array <= var_95])
            
            # èƒœç‡ç»Ÿè®¡
            positive_returns = len(returns_array[returns_array > 0])
            win_rate = positive_returns / len(returns_array) if len(returns_array) > 0 else 0
            
            return {
                'total_return': total_return,
                'annualized_return': annualized_return,
                'volatility': volatility,
                'max_drawdown': max_drawdown,
                'sharpe_ratio': sharpe_ratio,
                'sortino_ratio': sortino_ratio,
                'calmar_ratio': calmar_ratio,
                'var_95': var_95,
                'cvar_95': cvar_95,
                'win_rate': win_rate,
                'total_periods': len(values),
                'risk_events_count': len(self.risk_events),
                'start_value': values[0],
                'end_value': values[-1],
                'peak_value': max(values)
            }
            
        except Exception as e:
            logger.error(f"âŒ è®¡ç®—æŠ•èµ„ç»„åˆæŒ‡æ ‡å¤±è´¥: {e}")
            return {}
    
    async def _generate_portfolio_report(
        self,
        portfolio_metrics: Dict[str, Any],
        symbol_data: Dict[str, pd.DataFrame],
        portfolio_config: PortfolioConfig
    ) -> Dict[str, Any]:
        """ç”ŸæˆæŠ•èµ„ç»„åˆæŠ¥å‘Š"""
        try:
            # æŒ‰äº¤æ˜“å¯¹è´¡çŒ®åˆ†æ
            symbol_contribution = {}
            for symbol in symbol_data.keys():
                symbol_trades = [t for t in self.trades if t.symbol == symbol]
                if symbol_trades:
                    symbol_pnl = sum(t.pnl for t in symbol_trades)
                    symbol_contribution[symbol] = {
                        'total_pnl': symbol_pnl,
                        'trade_count': len(symbol_trades),
                        'contribution_percent': symbol_pnl / portfolio_metrics.get('total_return', 1) * 100
                    }
            
            # é£é™©åˆ†æ
            risk_analysis = {
                'risk_events': self.risk_events,
                'max_drawdown_periods': self._analyze_drawdown_periods(),
                'correlation_analysis': await self._analyze_correlations(symbol_data),
                'position_concentration': self._analyze_position_concentration()
            }
            
            # æ—¶é—´åºåˆ—åˆ†æ
            time_series_analysis = {
                'monthly_returns': self._calculate_monthly_returns(),
                'rolling_metrics': self._calculate_rolling_metrics(),
                'performance_periods': self._analyze_performance_periods()
            }
            
            return {
                'summary': portfolio_metrics,
                'symbol_contribution': symbol_contribution,
                'risk_analysis': risk_analysis,
                'time_series_analysis': time_series_analysis,
                'portfolio_composition': {
                    'symbols': list(symbol_data.keys()),
                    'weights': portfolio_config.weights,
                    'rebalance_frequency': portfolio_config.rebalance_frequency
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ ç”ŸæˆæŠ•èµ„ç»„åˆæŠ¥å‘Šå¤±è´¥: {e}")
            return {}
    
    def _analyze_drawdown_periods(self) -> List[Dict[str, Any]]:
        """åˆ†æå›æ’¤æœŸé—´"""
        if not self.portfolio_history:
            return []
        
        values = [h['total_value'] for h in self.portfolio_history]
        timestamps = [h['timestamp'] for h in self.portfolio_history]
        
        drawdown_periods = []
        peak_value = values[0]
        peak_time = timestamps[0]
        in_drawdown = False
        drawdown_start = None
        
        for i, (value, timestamp) in enumerate(zip(values, timestamps)):
            if value > peak_value:
                if in_drawdown:
                    # å›æ’¤ç»“æŸ
                    drawdown_periods.append({
                        'start': drawdown_start,
                        'end': timestamp,
                        'duration_days': (timestamp - drawdown_start).days,
                        'max_drawdown': (peak_value - min(values[peak_idx:i])) / peak_value,
                        'recovery_time': (timestamp - peak_time).days
                    })
                    in_drawdown = False
                
                peak_value = value
                peak_time = timestamp
                peak_idx = i
            elif not in_drawdown and value < peak_value * 0.99:  # 1%ä»¥ä¸Šå›æ’¤æ‰è®°å½•
                in_drawdown = True
                drawdown_start = timestamp
        
        return drawdown_periods
    
    async def _analyze_correlations(self, symbol_data: Dict[str, pd.DataFrame]) -> Dict[str, Any]:
        """åˆ†æäº¤æ˜“å¯¹ç›¸å…³æ€§"""
        try:
            # è®¡ç®—æ”¶ç›Šç‡ç›¸å…³æ€§çŸ©é˜µ
            returns_data = {}
            
            for symbol, data in symbol_data.items():
                returns = data['close'].pct_change().dropna()
                returns_data[symbol] = returns
            
            if len(returns_data) < 2:
                return {}
            
            # åˆ›å»ºæ”¶ç›Šç‡DataFrame
            returns_df = pd.DataFrame(returns_data)
            correlation_matrix = returns_df.corr()
            
            # æ‰¾å‡ºé«˜ç›¸å…³æ€§å¯¹
            high_correlations = []
            symbols = list(returns_data.keys())
            
            for i in range(len(symbols)):
                for j in range(i+1, len(symbols)):
                    corr = correlation_matrix.loc[symbols[i], symbols[j]]
                    if abs(corr) > 0.7:  # é«˜ç›¸å…³æ€§é˜ˆå€¼
                        high_correlations.append({
                            'pair': f"{symbols[i]}-{symbols[j]}",
                            'correlation': corr
                        })
            
            return {
                'correlation_matrix': correlation_matrix.to_dict(),
                'high_correlations': high_correlations,
                'average_correlation': correlation_matrix.values[np.triu_indices_from(correlation_matrix.values, k=1)].mean()
            }
            
        except Exception as e:
            logger.error(f"âŒ ç›¸å…³æ€§åˆ†æå¤±è´¥: {e}")
            return {}
    
    def _analyze_position_concentration(self) -> Dict[str, Any]:
        """åˆ†æä»“ä½é›†ä¸­åº¦"""
        if not self.portfolio_history:
            return {}
        
        # è®¡ç®—å¹³å‡ä»“ä½é›†ä¸­åº¦
        concentration_scores = []
        
        for record in self.portfolio_history:
            positions = record.get('positions', {})
            if positions:
                # è®¡ç®—HerfindahlæŒ‡æ•°ï¼ˆé›†ä¸­åº¦æŒ‡æ ‡ï¼‰
                total_value = sum(pos.size * pos.current_price for pos in positions.values())
                if total_value > 0:
                    weights_squared = [(pos.size * pos.current_price / total_value) ** 2 for pos in positions.values()]
                    herfindahl_index = sum(weights_squared)
                    concentration_scores.append(herfindahl_index)
        
        if concentration_scores:
            return {
                'average_concentration': np.mean(concentration_scores),
                'max_concentration': max(concentration_scores),
                'concentration_trend': 'increasing' if concentration_scores[-1] > concentration_scores[0] else 'decreasing'
            }
        
        return {}
    
    def _calculate_monthly_returns(self) -> Dict[str, float]:
        """è®¡ç®—æœˆåº¦æ”¶ç›Šç‡"""
        if not self.portfolio_history:
            return {}
        
        monthly_returns = {}
        
        # æŒ‰æœˆåˆ†ç»„
        monthly_data = {}
        for record in self.portfolio_history:
            month_key = record['timestamp'].strftime('%Y-%m')
            if month_key not in monthly_data:
                monthly_data[month_key] = []
            monthly_data[month_key].append(record['total_value'])
        
        # è®¡ç®—æ¯æœˆæ”¶ç›Šç‡
        for month, values in monthly_data.items():
            if len(values) > 1:
                monthly_return = (values[-1] - values[0]) / values[0]
                monthly_returns[month] = monthly_return
        
        return monthly_returns
    
    def _calculate_rolling_metrics(self, window_days: int = 30) -> Dict[str, List[float]]:
        """è®¡ç®—æ»šåŠ¨æŒ‡æ ‡"""
        if not self.portfolio_history or len(self.portfolio_history) < window_days:
            return {}
        
        values = [h['total_value'] for h in self.portfolio_history]
        
        rolling_sharpe = []
        rolling_volatility = []
        rolling_max_drawdown = []
        
        for i in range(window_days, len(values)):
            window_values = values[i-window_days:i]
            
            # è®¡ç®—æ”¶ç›Šç‡
            returns = [(window_values[j] - window_values[j-1]) / window_values[j-1] 
                      for j in range(1, len(window_values))]
            
            if returns:
                # æ»šåŠ¨å¤æ™®æ¯”ç‡
                mean_return = np.mean(returns)
                std_return = np.std(returns)
                sharpe = (mean_return / std_return) * np.sqrt(252) if std_return > 0 else 0
                rolling_sharpe.append(sharpe)
                
                # æ»šåŠ¨æ³¢åŠ¨ç‡
                volatility = std_return * np.sqrt(252)
                rolling_volatility.append(volatility)
                
                # æ»šåŠ¨æœ€å¤§å›æ’¤
                peak = max(window_values)
                trough = min(window_values)
                max_dd = (peak - trough) / peak if peak > 0 else 0
                rolling_max_drawdown.append(max_dd)
        
        return {
            'rolling_sharpe': rolling_sharpe,
            'rolling_volatility': rolling_volatility,
            'rolling_max_drawdown': rolling_max_drawdown
        }
    
    def _analyze_performance_periods(self) -> Dict[str, Any]:
        """åˆ†æä¸åŒæ—¶æœŸçš„è¡¨ç°"""
        if not self.portfolio_history:
            return {}
        
        # æŒ‰å­£åº¦åˆ†æ
        quarterly_performance = {}
        
        for record in self.portfolio_history:
            quarter_key = f"{record['timestamp'].year}-Q{(record['timestamp'].month-1)//3 + 1}"
            if quarter_key not in quarterly_performance:
                quarterly_performance[quarter_key] = []
            quarterly_performance[quarter_key].append(record['total_value'])
        
        # è®¡ç®—æ¯å­£åº¦è¡¨ç°
        quarterly_results = {}
        for quarter, values in quarterly_performance.items():
            if len(values) > 1:
                quarterly_return = (values[-1] - values[0]) / values[0]
                quarterly_results[quarter] = {
                    'return': quarterly_return,
                    'volatility': np.std([(values[i] - values[i-1]) / values[i-1] 
                                        for i in range(1, len(values))]) if len(values) > 1 else 0
                }
        
        return {
            'quarterly_performance': quarterly_results,
            'best_quarter': max(quarterly_results.items(), key=lambda x: x[1]['return']) if quarterly_results else None,
            'worst_quarter': min(quarterly_results.items(), key=lambda x: x[1]['return']) if quarterly_results else None
        }


class StrategyOptimizer:
    """ç­–ç•¥ä¼˜åŒ–å™¨"""
    
    def __init__(self, backtest_engine: AdvancedBacktestEngine):
        self.engine = backtest_engine
        self.optimization_results: List[OptimizationResult] = []
    
    async def optimize_strategy(
        self,
        symbol: str,
        strategy_parameters: List[StrategyParameter],
        start_date: datetime,
        end_date: datetime,
        optimization_method: OptimizationMethod = OptimizationMethod.GRID_SEARCH,
        optimization_metric: str = "sharpe_ratio",
        max_iterations: int = 1000,
        initial_balance: float = 10000.0
    ) -> OptimizationResult:
        """ä¼˜åŒ–ç­–ç•¥å‚æ•°"""
        try:
            start_time = datetime.now()
            logger.info(f"ğŸ¯ å¼€å§‹ç­–ç•¥ä¼˜åŒ–: {symbol} ({optimization_method.value})")
            
            if optimization_method == OptimizationMethod.GRID_SEARCH:
                result = await self._grid_search_optimization(
                    symbol, strategy_parameters, start_date, end_date,
                    optimization_metric, initial_balance
                )
            elif optimization_method == OptimizationMethod.RANDOM_SEARCH:
                result = await self._random_search_optimization(
                    symbol, strategy_parameters, start_date, end_date,
                    optimization_metric, max_iterations, initial_balance
                )
            elif optimization_method == OptimizationMethod.GENETIC_ALGORITHM:
                result = await self._genetic_algorithm_optimization(
                    symbol, strategy_parameters, start_date, end_date,
                    optimization_metric, max_iterations, initial_balance
                )
            else:
                raise BacktestError(f"ä¸æ”¯æŒçš„ä¼˜åŒ–æ–¹æ³•: {optimization_method}")
            
            optimization_time = (datetime.now() - start_time).total_seconds()
            result.optimization_time = optimization_time
            
            self.optimization_results.append(result)
            
            logger.info(f"âœ… ç­–ç•¥ä¼˜åŒ–å®Œæˆï¼Œæœ€ä½³å¾—åˆ†: {result.best_score:.4f}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ ç­–ç•¥ä¼˜åŒ–å¤±è´¥: {e}")
            raise BacktestError(f"ç­–ç•¥ä¼˜åŒ–å¤±è´¥: {str(e)}")
    
    async def _grid_search_optimization(
        self,
        symbol: str,
        parameters: List[StrategyParameter],
        start_date: datetime,
        end_date: datetime,
        metric: str,
        initial_balance: float
    ) -> OptimizationResult:
        """ç½‘æ ¼æœç´¢ä¼˜åŒ–"""
        try:
            # ç”Ÿæˆå‚æ•°ç»„åˆ
            param_ranges = []
            for param in parameters:
                if param.param_type == int:
                    values = list(range(int(param.min_value), int(param.max_value) + 1, int(param.step)))
                else:
                    values = np.arange(param.min_value, param.max_value + param.step, param.step).tolist()
                param_ranges.append(values)
            
            all_combinations = list(itertools.product(*param_ranges))
            total_combinations = len(all_combinations)
            
            logger.info(f"ğŸ“Š ç½‘æ ¼æœç´¢: {total_combinations} ç§å‚æ•°ç»„åˆ")
            
            # å¹¶è¡Œæ‰§è¡Œå›æµ‹
            results = []
            batch_size = min(10, total_combinations)  # æ‰¹é‡å¤„ç†ä»¥æ§åˆ¶å†…å­˜ä½¿ç”¨
            
            for i in range(0, total_combinations, batch_size):
                batch_combinations = all_combinations[i:i+batch_size]
                batch_results = await self._run_batch_backtests(
                    symbol, parameters, batch_combinations, start_date, end_date, initial_balance
                )
                results.extend(batch_results)
                
                logger.info(f"ğŸ“ˆ å·²å®Œæˆ {min(i+batch_size, total_combinations)}/{total_combinations} ç»„åˆ")
            
            # æ‰¾åˆ°æœ€ä½³ç»“æœ
            best_result = max(results, key=lambda x: x.get(metric, 0))
            
            return OptimizationResult(
                best_params=best_result['params'],
                best_score=best_result.get(metric, 0),
                optimization_metric=metric,
                all_results=results,
                optimization_time=0,  # å°†åœ¨è°ƒç”¨å‡½æ•°ä¸­è®¾ç½®
                total_combinations=total_combinations
            )
            
        except Exception as e:
            logger.error(f"âŒ ç½‘æ ¼æœç´¢ä¼˜åŒ–å¤±è´¥: {e}")
            raise
    
    async def _random_search_optimization(
        self,
        symbol: str,
        parameters: List[StrategyParameter],
        start_date: datetime,
        end_date: datetime,
        metric: str,
        max_iterations: int,
        initial_balance: float
    ) -> OptimizationResult:
        """éšæœºæœç´¢ä¼˜åŒ–"""
        try:
            logger.info(f"ğŸ² éšæœºæœç´¢: {max_iterations} æ¬¡è¿­ä»£")
            
            results = []
            
            for i in range(max_iterations):
                # éšæœºç”Ÿæˆå‚æ•°ç»„åˆ
                random_params = []
                for param in parameters:
                    if param.param_type == int:
                        value = np.random.randint(param.min_value, param.max_value + 1)
                    else:
                        value = np.random.uniform(param.min_value, param.max_value)
                    random_params.append(value)
                
                # æ‰§è¡Œå›æµ‹
                param_dict = {param.name: value for param, value in zip(parameters, random_params)}
                
                try:
                    backtest_result = await self._run_single_backtest(
                        symbol, param_dict, start_date, end_date, initial_balance
                    )
                    backtest_result['params'] = param_dict
                    results.append(backtest_result)
                    
                except Exception as e:
                    logger.warning(f"âš ï¸ å›æµ‹å¤±è´¥ (ç¬¬{i+1}æ¬¡): {e}")
                    continue
                
                if (i + 1) % 100 == 0:
                    logger.info(f"ğŸ“ˆ å·²å®Œæˆ {i+1}/{max_iterations} æ¬¡è¿­ä»£")
            
            if not results:
                raise BacktestError("æ²¡æœ‰æˆåŠŸçš„å›æµ‹ç»“æœ")
            
            # æ‰¾åˆ°æœ€ä½³ç»“æœ
            best_result = max(results, key=lambda x: x.get(metric, 0))
            
            return OptimizationResult(
                best_params=best_result['params'],
                best_score=best_result.get(metric, 0),
                optimization_metric=metric,
                all_results=results,
                optimization_time=0,
                total_combinations=max_iterations
            )
            
        except Exception as e:
            logger.error(f"âŒ éšæœºæœç´¢ä¼˜åŒ–å¤±è´¥: {e}")
            raise
    
    async def _genetic_algorithm_optimization(
        self,
        symbol: str,
        parameters: List[StrategyParameter],
        start_date: datetime,
        end_date: datetime,
        metric: str,
        max_generations: int,
        initial_balance: float,
        population_size: int = 50,
        mutation_rate: float = 0.1
    ) -> OptimizationResult:
        """é—ä¼ ç®—æ³•ä¼˜åŒ–"""
        try:
            logger.info(f"ğŸ§¬ é—ä¼ ç®—æ³•ä¼˜åŒ–: {max_generations} ä»£ï¼Œç§ç¾¤å¤§å° {population_size}")
            
            # åˆå§‹åŒ–ç§ç¾¤
            population = []
            for _ in range(population_size):
                individual = []
                for param in parameters:
                    if param.param_type == int:
                        value = np.random.randint(param.min_value, param.max_value + 1)
                    else:
                        value = np.random.uniform(param.min_value, param.max_value)
                    individual.append(value)
                population.append(individual)
            
            all_results = []
            best_scores = []
            
            for generation in range(max_generations):
                # è¯„ä¼°ç§ç¾¤
                generation_results = []
                
                for individual in population:
                    param_dict = {param.name: value for param, value in zip(parameters, individual)}
                    
                    try:
                        result = await self._run_single_backtest(
                            symbol, param_dict, start_date, end_date, initial_balance
                        )
                        result['params'] = param_dict
                        result['individual'] = individual
                        generation_results.append(result)
                        
                    except Exception as e:
                        # å¯¹äºå¤±è´¥çš„ä¸ªä½“ï¼Œç»™äºˆå¾ˆä½çš„å¾—åˆ†
                        result = {
                            'params': param_dict,
                            'individual': individual,
                            metric: -999999
                        }
                        generation_results.append(result)
                
                all_results.extend(generation_results)
                
                # é€‰æ‹©æœ€ä½³ä¸ªä½“
                generation_results.sort(key=lambda x: x.get(metric, -999999), reverse=True)
                best_scores.append(generation_results[0].get(metric, -999999))
                
                # é€‰æ‹©ã€äº¤å‰ã€å˜å¼‚ç”Ÿæˆä¸‹ä¸€ä»£
                if generation < max_generations - 1:
                    population = self._evolve_population(
                        generation_results, parameters, population_size, mutation_rate
                    )
                
                logger.info(f"ğŸ§¬ ç¬¬ {generation+1} ä»£å®Œæˆï¼Œæœ€ä½³å¾—åˆ†: {best_scores[-1]:.4f}")
            
            # æ‰¾åˆ°å…¨å±€æœ€ä½³ç»“æœ
            best_result = max(all_results, key=lambda x: x.get(metric, -999999))
            
            return OptimizationResult(
                best_params=best_result['params'],
                best_score=best_result.get(metric, 0),
                optimization_metric=metric,
                all_results=all_results,
                optimization_time=0,
                total_combinations=len(all_results)
            )
            
        except Exception as e:
            logger.error(f"âŒ é—ä¼ ç®—æ³•ä¼˜åŒ–å¤±è´¥: {e}")
            raise
    
    def _evolve_population(
        self,
        evaluated_population: List[Dict[str, Any]],
        parameters: List[StrategyParameter],
        population_size: int,
        mutation_rate: float
    ) -> List[List[float]]:
        """è¿›åŒ–ç§ç¾¤"""
        # é€‰æ‹©top 50%ä½œä¸ºçˆ¶ä»£
        parents = evaluated_population[:population_size // 2]
        new_population = []
        
        # ä¿ç•™æœ€ä½³ä¸ªä½“ï¼ˆç²¾è‹±ç­–ç•¥ï¼‰
        elite_count = max(1, population_size // 10)
        for i in range(elite_count):
            new_population.append(parents[i]['individual'])
        
        # ç”Ÿæˆå­ä»£
        while len(new_population) < population_size:
            # éšæœºé€‰æ‹©ä¸¤ä¸ªçˆ¶ä»£
            parent1 = np.random.choice(len(parents))
            parent2 = np.random.choice(len(parents))
            
            # äº¤å‰
            child = self._crossover(
                parents[parent1]['individual'],
                parents[parent2]['individual']
            )
            
            # å˜å¼‚
            child = self._mutate(child, parameters, mutation_rate)
            
            new_population.append(child)
        
        return new_population
    
    def _crossover(self, parent1: List[float], parent2: List[float]) -> List[float]:
        """äº¤å‰æ“ä½œ"""
        crossover_point = np.random.randint(1, len(parent1))
        child = parent1[:crossover_point] + parent2[crossover_point:]
        return child
    
    def _mutate(
        self,
        individual: List[float],
        parameters: List[StrategyParameter],
        mutation_rate: float
    ) -> List[float]:
        """å˜å¼‚æ“ä½œ"""
        mutated = individual.copy()
        
        for i in range(len(mutated)):
            if np.random.random() < mutation_rate:
                param = parameters[i]
                if param.param_type == int:
                    mutated[i] = np.random.randint(param.min_value, param.max_value + 1)
                else:
                    mutated[i] = np.random.uniform(param.min_value, param.max_value)
        
        return mutated
    
    async def _run_batch_backtests(
        self,
        symbol: str,
        parameters: List[StrategyParameter],
        combinations: List[Tuple],
        start_date: datetime,
        end_date: datetime,
        initial_balance: float
    ) -> List[Dict[str, Any]]:
        """æ‰¹é‡è¿è¡Œå›æµ‹"""
        results = []
        
        for combination in combinations:
            param_dict = {param.name: value for param, value in zip(parameters, combination)}
            
            try:
                result = await self._run_single_backtest(
                    symbol, param_dict, start_date, end_date, initial_balance
                )
                result['params'] = param_dict
                results.append(result)
                
            except Exception as e:
                logger.warning(f"âš ï¸ å›æµ‹å¤±è´¥ {param_dict}: {e}")
                continue
        
        return results
    
    async def _run_single_backtest(
        self,
        symbol: str,
        params: Dict[str, Any],
        start_date: datetime,
        end_date: datetime,
        initial_balance: float
    ) -> Dict[str, Any]:
        """è¿è¡Œå•æ¬¡å›æµ‹"""
        try:
            # åˆ›å»ºæ–°çš„å›æµ‹å¼•æ“å®ä¾‹
            engine = AdvancedBacktestEngine()
            
            # è®¾ç½®ç­–ç•¥å‚æ•°
            strategy_configs = {
                'strategy_type': 'supertrend',
                'use_ml': False,  # ä¼˜åŒ–æ—¶æš‚æ—¶å…³é—­MLä»¥æé«˜é€Ÿåº¦
                **params
            }
            
            # è¿è¡Œå›æµ‹
            result = await engine.run_backtest(
                symbols=[symbol],
                start_date=start_date,
                end_date=end_date,
                initial_balance=initial_balance,
                interval="1h",
                strategy_configs=strategy_configs
            )
            
            # æå–å…³é”®æŒ‡æ ‡
            metrics = result.get('metrics')
            if not metrics:
                return {'sharpe_ratio': -999999, 'total_pnl_percent': -999999}
            
            return {
                'sharpe_ratio': getattr(metrics, 'sharpe_ratio', 0),
                'total_pnl_percent': getattr(metrics, 'total_pnl_percent', 0),
                'max_drawdown_percent': getattr(metrics, 'max_drawdown_percent', 100),
                'win_rate': getattr(metrics, 'win_rate', 0),
                'total_trades': getattr(metrics, 'total_trades', 0),
                'profit_factor': getattr(metrics, 'profit_factor', 0)
            }
            
        except Exception as e:
            logger.error(f"âŒ å•æ¬¡å›æµ‹å¤±è´¥: {e}")
            return {'sharpe_ratio': -999999, 'total_pnl_percent': -999999}


class CompleteBacktestService:
    """å®Œæ•´å›æµ‹æœåŠ¡"""
    
    def __init__(self):
        self.basic_service = BacktestService()
        self.advanced_engine = AdvancedBacktestEngine()
        self.optimizer = StrategyOptimizer(self.advanced_engine)
        self.visualization_enabled = True
    
    async def run_comprehensive_backtest(
        self,
        config: Dict[str, Any]
    ) -> Dict[str, Any]:
        """è¿è¡Œç»¼åˆå›æµ‹"""
        try:
            backtest_type = config.get('type', 'single')
            
            if backtest_type == 'single':
                return await self._run_single_symbol_comprehensive(config)
            elif backtest_type == 'portfolio':
                return await self._run_portfolio_comprehensive(config)
            elif backtest_type == 'optimization':
                return await self._run_optimization_comprehensive(config)
            elif backtest_type == 'strategy_comparison':
                return await self._run_strategy_comparison_comprehensive(config)
            else:
                raise BacktestError(f"ä¸æ”¯æŒçš„å›æµ‹ç±»å‹: {backtest_type}")
                
        except Exception as e:
            logger.error(f"âŒ ç»¼åˆå›æµ‹å¤±è´¥: {e}")
            raise BacktestError(f"ç»¼åˆå›æµ‹å¤±è´¥: {str(e)}")
    
    async def _run_single_symbol_comprehensive(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """è¿è¡Œå•äº¤æ˜“å¯¹ç»¼åˆå›æµ‹"""
        symbol = config['symbol']
        start_date = datetime.fromisoformat(config['start_date'])
        end_date = datetime.fromisoformat(config['end_date'])
        
        # è¿è¡ŒåŸºç¡€å›æµ‹
        basic_result = await self.basic_service.run_single_strategy_backtest(
            symbol=symbol,
            start_date=start_date,
            end_date=end_date,
            **config.get('basic_params', {})
        )
        
        # è¿è¡Œé«˜çº§åˆ†æ
        risk_config = RiskManagementConfig(**config.get('risk_config', {}))
        advanced_engine = AdvancedBacktestEngine(risk_config)
        
        advanced_result = await advanced_engine.run_backtest(
            symbols=[symbol],
            start_date=start_date,
            end_date=end_date,
            **config.get('advanced_params', {})
        )
        
        # ç”Ÿæˆå¯è§†åŒ–
        if self.visualization_enabled:
            charts = await self._generate_charts(basic_result, advanced_result)
        else:
            charts = {}
        
        return {
            'type': 'single_comprehensive',
            'basic_result': basic_result,
            'advanced_result': advanced_result,
            'charts': charts,
            'recommendations': self._generate_recommendations(basic_result, advanced_result)
        }
    
    async def _run_portfolio_comprehensive(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """è¿è¡ŒæŠ•èµ„ç»„åˆç»¼åˆå›æµ‹"""
        portfolio_config = PortfolioConfig(**config['portfolio_config'])
        risk_config = RiskManagementConfig(**config.get('risk_config', {}))
        
        advanced_engine = AdvancedBacktestEngine(risk_config)
        
        result = await advanced_engine.run_portfolio_backtest(
            portfolio_config=portfolio_config,
            start_date=datetime.fromisoformat(config['start_date']),
            end_date=datetime.fromisoformat(config['end_date']),
            **config.get('params', {})
        )
        
        # ç”ŸæˆæŠ•èµ„ç»„åˆç‰¹å®šçš„å¯è§†åŒ–
        if self.visualization_enabled:
            charts = await self._generate_portfolio_charts(result)
        else:
            charts = {}
        
        return {
            'type': 'portfolio_comprehensive',
            'result': result,
            'charts': charts,
            'recommendations': self._generate_portfolio_recommendations(result)
        }
    
    async def _run_optimization_comprehensive(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """è¿è¡Œç­–ç•¥ä¼˜åŒ–ç»¼åˆå›æµ‹"""
        symbol = config['symbol']
        
        # å®šä¹‰ä¼˜åŒ–å‚æ•°
        parameters = []
        for param_config in config['parameters']:
            parameters.append(StrategyParameter(**param_config))
        
        # è¿è¡Œä¼˜åŒ–
        optimization_result = await self.optimizer.optimize_strategy(
            symbol=symbol,
            strategy_parameters=parameters,
            start_date=datetime.fromisoformat(config['start_date']),
            end_date=datetime.fromisoformat(config['end_date']),
            optimization_method=OptimizationMethod(config.get('method', 'grid_search')),
            **config.get('optimization_params', {})
        )
        
        # ä½¿ç”¨æœ€ä½³å‚æ•°è¿è¡Œè¯¦ç»†å›æµ‹
        best_params_result = await self.basic_service.run_single_strategy_backtest(
            symbol=symbol,
            start_date=datetime.fromisoformat(config['start_date']),
            end_date=datetime.fromisoformat(config['end_date']),
            strategy_params=optimization_result.best_params,
            **config.get('backtest_params', {})
        )
        
        # ç”Ÿæˆä¼˜åŒ–ç»“æœå¯è§†åŒ–
        if self.visualization_enabled:
            charts = await self._generate_optimization_charts(optimization_result)
        else:
            charts = {}
        
        return {
            'type': 'optimization_comprehensive',
            'optimization_result': optimization_result,
            'best_params_backtest': best_params_result,
            'charts': charts,
            'recommendations': self._generate_optimization_recommendations(optimization_result)
        }
    
    async def _run_strategy_comparison_comprehensive(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """è¿è¡Œç­–ç•¥æ¯”è¾ƒç»¼åˆå›æµ‹"""
        symbol = config['symbol']
        strategies = config['strategies']
        
        # è¿è¡Œç­–ç•¥æ¯”è¾ƒ
        comparison_result = await self.basic_service.compare_strategies(
            symbol=symbol,
            strategies=strategies,
            start_date=datetime.fromisoformat(config['start_date']),
            end_date=datetime.fromisoformat(config['end_date']),
            **config.get('params', {})
        )
        
        # ç”Ÿæˆæ¯”è¾ƒå›¾è¡¨
        if self.visualization_enabled:
            charts = await self._generate_comparison_charts(comparison_result)
        else:
            charts = {}
        
        return {
            'type': 'strategy_comparison_comprehensive',
            'comparison_result': comparison_result,
            'charts': charts,
            'recommendations': self._generate_comparison_recommendations(comparison_result)
        }
    
    async def _generate_charts(
        self,
        basic_result: Dict[str, Any],
        advanced_result: Dict[str, Any]
    ) -> Dict[str, str]:
        """ç”Ÿæˆå›¾è¡¨"""
        charts = {}
        
        try:
            # è®¾ç½®ç»˜å›¾æ ·å¼
            plt.style.use('seaborn-v0_8')
            
            # æƒç›Šæ›²çº¿
            fig, ax = plt.subplots(figsize=(12, 6))
            if basic_result.get('balance_history'):
                timestamps, balances = zip(*basic_result['balance_history'])
                ax.plot(timestamps, balances, label='è´¦æˆ·ä½™é¢', linewidth=2)
                ax.set_title('æƒç›Šæ›²çº¿')
                ax.set_xlabel('æ—¶é—´')
                ax.set_ylabel('è´¦æˆ·ä½™é¢')
                ax.legend()
                ax.grid(True, alpha=0.3)
                
                # ä¿å­˜å›¾è¡¨
                chart_path = f"logs/cache/equity_curve_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
                Path(chart_path).parent.mkdir(parents=True, exist_ok=True)
                plt.savefig(chart_path, dpi=150, bbox_inches='tight')
                charts['equity_curve'] = chart_path
                plt.close()
            
            # å›æ’¤åˆ†æ
            if advanced_result.get('balance_history'):
                fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))
                
                timestamps, balances = zip(*advanced_result['balance_history'])
                
                # æƒç›Šæ›²çº¿
                ax1.plot(timestamps, balances, label='æŠ•èµ„ç»„åˆä»·å€¼', linewidth=2)
                ax1.set_title('æŠ•èµ„ç»„åˆè¡¨ç°')
                ax1.set_ylabel('ä»·å€¼')
                ax1.legend()
                ax1.grid(True, alpha=0.3)
                
                # å›æ’¤æ›²çº¿
                peak = np.maximum.accumulate(balances)
                drawdown = (np.array(balances) - peak) / peak * 100
                ax2.fill_between(timestamps, drawdown, 0, alpha=0.3, color='red', label='å›æ’¤')
                ax2.plot(timestamps, drawdown, color='red', linewidth=1)
                ax2.set_title('å›æ’¤åˆ†æ')
                ax2.set_xlabel('æ—¶é—´')
                ax2.set_ylabel('å›æ’¤ (%)')
                ax2.legend()
                ax2.grid(True, alpha=0.3)
                
                chart_path = f"logs/cache/portfolio_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
                plt.savefig(chart_path, dpi=150, bbox_inches='tight')
                charts['portfolio_analysis'] = chart_path
                plt.close()
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆå›¾è¡¨å¤±è´¥: {e}")
        
        return charts
    
    async def _generate_portfolio_charts(self, result: Dict[str, Any]) -> Dict[str, str]:
        """ç”ŸæˆæŠ•èµ„ç»„åˆå›¾è¡¨"""
        charts = {}
        
        try:
            portfolio_history = result.get('portfolio_history', [])
            if not portfolio_history:
                return charts
            
            # æŠ•èµ„ç»„åˆæƒé‡å˜åŒ–
            fig, ax = plt.subplots(figsize=(12, 6))
            
            timestamps = [h['timestamp'] for h in portfolio_history[::24]]  # æ¯å¤©ä¸€ä¸ªæ•°æ®ç‚¹
            weights_data = {}
            
            for h in portfolio_history[::24]:
                for symbol, weight in h.get('weights', {}).items():
                    if symbol not in weights_data:
                        weights_data[symbol] = []
                    weights_data[symbol].append(weight)
            
            # ç»˜åˆ¶æƒé‡å˜åŒ–
            for symbol, weights in weights_data.items():
                ax.plot(timestamps[:len(weights)], weights, label=symbol, linewidth=2, marker='o', markersize=3)
            
            ax.set_title('æŠ•èµ„ç»„åˆæƒé‡å˜åŒ–')
            ax.set_xlabel('æ—¶é—´')
            ax.set_ylabel('æƒé‡')
            ax.legend()
            ax.grid(True, alpha=0.3)
            
            chart_path = f"logs/cache/portfolio_weights_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
            Path(chart_path).parent.mkdir(parents=True, exist_ok=True)
            plt.savefig(chart_path, dpi=150, bbox_inches='tight')
            charts['portfolio_weights'] = chart_path
            plt.close()
            
        except Exception as e:
            logger.error(f"âŒ ç”ŸæˆæŠ•èµ„ç»„åˆå›¾è¡¨å¤±è´¥: {e}")
        
        return charts
    
    async def _generate_optimization_charts(self, optimization_result: OptimizationResult) -> Dict[str, str]:
        """ç”Ÿæˆä¼˜åŒ–ç»“æœå›¾è¡¨"""
        charts = {}
        
        try:
            results = optimization_result.all_results
            if not results:
                return charts
            
            # å‚æ•°vsæ€§èƒ½æ•£ç‚¹å›¾
            param_names = list(optimization_result.best_params.keys())
            
            if len(param_names) >= 2:
                fig, ax = plt.subplots(figsize=(10, 8))
                
                x_param = param_names[0]
                y_param = param_names[1]
                
                x_values = [r['params'][x_param] for r in results if 'params' in r]
                y_values = [r['params'][y_param] for r in results if 'params' in r]
                scores = [r.get(optimization_result.optimization_metric, 0) for r in results if 'params' in r]
                
                scatter = ax.scatter(x_values, y_values, c=scores, cmap='viridis', alpha=0.6)
                ax.set_xlabel(x_param)
                ax.set_ylabel(y_param)
                ax.set_title(f'å‚æ•°ä¼˜åŒ–ç»“æœ ({optimization_result.optimization_metric})')
                
                # æ ‡è®°æœ€ä½³ç‚¹
                best_x = optimization_result.best_params[x_param]
                best_y = optimization_result.best_params[y_param]
                ax.scatter([best_x], [best_y], color='red', s=100, marker='*', label='æœ€ä½³å‚æ•°')
                
                plt.colorbar(scatter, ax=ax, label=optimization_result.optimization_metric)
                ax.legend()
                ax.grid(True, alpha=0.3)
                
                chart_path = f"logs/cache/optimization_scatter_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
                Path(chart_path).parent.mkdir(parents=True, exist_ok=True)
                plt.savefig(chart_path, dpi=150, bbox_inches='tight')
                charts['optimization_scatter'] = chart_path
                plt.close()
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆä¼˜åŒ–å›¾è¡¨å¤±è´¥: {e}")
        
        return charts
    
    async def _generate_comparison_charts(self, comparison_result: Dict[str, Any]) -> Dict[str, str]:
        """ç”Ÿæˆç­–ç•¥æ¯”è¾ƒå›¾è¡¨"""
        charts = {}
        
        try:
            individual_results = comparison_result.get('individual_results', {})
            comparison = comparison_result.get('comparison', {})
            
            if not individual_results:
                return charts
            
            # ç­–ç•¥æ€§èƒ½æ¯”è¾ƒæ¡å½¢å›¾
            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
            
            strategies = list(individual_results.keys())
            metrics = ['total_pnl_percent', 'win_rate', 'sharpe_ratio', 'max_drawdown_percent']
            metric_labels = ['æ€»æ”¶ç›Šç‡ (%)', 'èƒœç‡', 'å¤æ™®æ¯”ç‡', 'æœ€å¤§å›æ’¤ (%)']
            
            axes = [ax1, ax2, ax3, ax4]
            
            for i, (metric, label, ax) in enumerate(zip(metrics, metric_labels, axes)):
                values = []
                for strategy in strategies:
                    result = individual_results[strategy]
                    if 'error' not in result:
                        metric_value = getattr(result.get('metrics'), metric, 0)
                        values.append(metric_value)
                    else:
                        values.append(0)
                
                bars = ax.bar(strategies, values, alpha=0.7)
                ax.set_title(label)
                ax.set_ylabel(label)
                
                # æ—‹è½¬xè½´æ ‡ç­¾
                ax.tick_params(axis='x', rotation=45)
                
                # ä¸ºæ¡å½¢å›¾æ·»åŠ æ•°å€¼æ ‡ç­¾
                for bar, value in zip(bars, values):
                    height = bar.get_height()
                    ax.text(bar.get_x() + bar.get_width()/2., height,
                           f'{value:.2f}', ha='center', va='bottom')
            
            plt.tight_layout()
            
            chart_path = f"logs/cache/strategy_comparison_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
            Path(chart_path).parent.mkdir(parents=True, exist_ok=True)
            plt.savefig(chart_path, dpi=150, bbox_inches='tight')
            charts['strategy_comparison'] = chart_path
            plt.close()
            
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆç­–ç•¥æ¯”è¾ƒå›¾è¡¨å¤±è´¥: {e}")
        
        return charts
    
    def _generate_recommendations(
        self,
        basic_result: Dict[str, Any],
        advanced_result: Dict[str, Any]
    ) -> List[str]:
        """ç”Ÿæˆå›æµ‹å»ºè®®"""
        recommendations = []
        
        try:
            basic_metrics = basic_result.get('metrics')
            if basic_metrics:
                # åŸºäºèƒœç‡çš„å»ºè®®
                win_rate = getattr(basic_metrics, 'win_rate', 0)
                if win_rate < 0.4:
                    recommendations.append("âš ï¸ èƒœç‡è¾ƒä½ï¼Œå»ºè®®ä¼˜åŒ–å…¥åœºæ¡ä»¶æˆ–è°ƒæ•´ç­–ç•¥å‚æ•°")
                elif win_rate > 0.7:
                    recommendations.append("âœ… èƒœç‡è¡¨ç°è‰¯å¥½ï¼Œç­–ç•¥å…·æœ‰è¾ƒå¼ºçš„ç›ˆåˆ©èƒ½åŠ›")
                
                # åŸºäºå¤æ™®æ¯”ç‡çš„å»ºè®®
                sharpe = getattr(basic_metrics, 'sharpe_ratio', 0)
                if sharpe < 1.0:
                    recommendations.append("ğŸ“ˆ å¤æ™®æ¯”ç‡åä½ï¼Œå»ºè®®ä¼˜åŒ–é£é™©æ”¶ç›Šæ¯”")
                elif sharpe > 2.0:
                    recommendations.append("ğŸ¯ å¤æ™®æ¯”ç‡ä¼˜ç§€ï¼Œç­–ç•¥é£é™©è°ƒæ•´åæ”¶ç›Šè‰¯å¥½")
                
                # åŸºäºæœ€å¤§å›æ’¤çš„å»ºè®®
                max_dd = getattr(basic_metrics, 'max_drawdown_percent', 0)
                if max_dd > 20:
                    recommendations.append("ğŸ›‘ æœ€å¤§å›æ’¤è¿‡å¤§ï¼Œå»ºè®®å¢å¼ºæ­¢æŸæœºåˆ¶")
                elif max_dd < 5:
                    recommendations.append("ğŸ”’ å›æ’¤æ§åˆ¶è‰¯å¥½ï¼Œé£é™©ç®¡ç†æœ‰æ•ˆ")
                
                # åŸºäºäº¤æ˜“é¢‘ç‡çš„å»ºè®®
                total_trades = getattr(basic_metrics, 'total_trades', 0)
                if total_trades < 10:
                    recommendations.append("ğŸ“Š äº¤æ˜“æ¬¡æ•°è¾ƒå°‘ï¼Œå¯èƒ½é”™è¿‡è¾ƒå¤šæœºä¼šï¼Œå»ºè®®é™ä½å…¥åœºé—¨æ§›")
                elif total_trades > 100:
                    recommendations.append("âš¡ äº¤æ˜“é¢‘ç‡è¾ƒé«˜ï¼Œæ³¨æ„äº¤æ˜“æˆæœ¬å¯¹æ”¶ç›Šçš„å½±å“")
            
            # åŸºäºé«˜çº§åˆ†æçš„å»ºè®®
            advanced_metrics = advanced_result.get('portfolio_metrics', {})
            if advanced_metrics:
                annual_return = advanced_metrics.get('annualized_return', 0)
                if annual_return > 0.2:
                    recommendations.append("ğŸš€ å¹´åŒ–æ”¶ç›Šç‡è¡¨ç°ä¼˜å¼‚ï¼Œç­–ç•¥å…·æœ‰å¾ˆå¼ºçš„ç›ˆåˆ©æ½œåŠ›")
                elif annual_return < 0:
                    recommendations.append("ğŸ“‰ å¹´åŒ–æ”¶ç›Šç‡ä¸ºè´Ÿï¼Œå»ºè®®é‡æ–°è¯„ä¼°ç­–ç•¥æœ‰æ•ˆæ€§")
        
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆå»ºè®®å¤±è´¥: {e}")
            recommendations.append("âŒ æ— æ³•ç”Ÿæˆè¯¦ç»†å»ºè®®ï¼Œè¯·æ£€æŸ¥å›æµ‹ç»“æœ")
        
        return recommendations
    
    def _generate_portfolio_recommendations(self, result: Dict[str, Any]) -> List[str]:
        """ç”ŸæˆæŠ•èµ„ç»„åˆå»ºè®®"""
        recommendations = []
        
        try:
            portfolio_metrics = result.get('portfolio_metrics', {})
            risk_events = result.get('risk_events', [])
            
            # åŸºäºæŠ•èµ„ç»„åˆæŒ‡æ ‡çš„å»ºè®®
            if portfolio_metrics:
                sharpe = portfolio_metrics.get('sharpe_ratio', 0)
                if sharpe > 1.5:
                    recommendations.append("ğŸ“ˆ æŠ•èµ„ç»„åˆå¤æ™®æ¯”ç‡ä¼˜ç§€ï¼Œé£é™©è°ƒæ•´åæ”¶ç›Šè‰¯å¥½")
                elif sharpe < 0.5:
                    recommendations.append("âš ï¸ æŠ•èµ„ç»„åˆå¤æ™®æ¯”ç‡åä½ï¼Œå»ºè®®ä¼˜åŒ–èµ„äº§é…ç½®")
                
                max_dd = portfolio_metrics.get('max_drawdown', 0)
                if max_dd > 0.3:
                    recommendations.append("ğŸ›‘ æŠ•èµ„ç»„åˆæœ€å¤§å›æ’¤è¿‡å¤§ï¼Œå»ºè®®å¢å¼ºé£é™©æ§åˆ¶")
                
                correlation = result.get('report', {}).get('risk_analysis', {}).get('correlation_analysis', {})
                avg_corr = correlation.get('average_correlation', 0)
                if avg_corr > 0.7:
                    recommendations.append("ğŸ”— æŠ•èµ„ç»„åˆç›¸å…³æ€§è¾ƒé«˜ï¼Œå»ºè®®å¢åŠ å¤šæ ·åŒ–èµ„äº§")
                elif avg_corr < 0.3:
                    recommendations.append("âœ… æŠ•èµ„ç»„åˆåˆ†æ•£åŒ–è‰¯å¥½ï¼Œé™ä½äº†ç³»ç»Ÿæ€§é£é™©")
            
            # åŸºäºé£é™©äº‹ä»¶çš„å»ºè®®
            if risk_events:
                recommendations.append(f"âš ï¸ å›æµ‹æœŸé—´å‘ç”Ÿ {len(risk_events)} æ¬¡é£é™©äº‹ä»¶ï¼Œå»ºè®®å®¡æŸ¥é£é™©ç®¡ç†ç­–ç•¥")
            else:
                recommendations.append("âœ… å›æµ‹æœŸé—´æœªè§¦å‘é£é™©äº‹ä»¶ï¼Œé£é™©æ§åˆ¶æœºåˆ¶è¿è¡Œè‰¯å¥½")
        
        except Exception as e:
            logger.error(f"âŒ ç”ŸæˆæŠ•èµ„ç»„åˆå»ºè®®å¤±è´¥: {e}")
        
        return recommendations
    
    def _generate_optimization_recommendations(self, optimization_result: OptimizationResult) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        try:
            best_score = optimization_result.best_score
            metric = optimization_result.optimization_metric
            
            recommendations.append(f"ğŸ¯ æœ€ä¼˜å‚æ•°ç»„åˆåœ¨ {metric} æŒ‡æ ‡ä¸Šè¾¾åˆ° {best_score:.4f}")
            
            # åˆ†æå‚æ•°æ•æ„Ÿæ€§
            all_results = optimization_result.all_results
            if len(all_results) > 10:
                scores = [r.get(metric, 0) for r in all_results]
                score_std = np.std(scores)
                score_mean = np.mean(scores)
                
                if score_std / abs(score_mean) > 0.5:
                    recommendations.append("âš ï¸ ç­–ç•¥å¯¹å‚æ•°å˜åŒ–è¾ƒä¸ºæ•æ„Ÿï¼Œå»ºè®®è¿›è¡Œç¨³å¥æ€§æµ‹è¯•")
                else:
                    recommendations.append("âœ… ç­–ç•¥å¯¹å‚æ•°å˜åŒ–ç›¸å¯¹ç¨³å¥")
                
                # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ˜æ˜¾æ›´ä¼˜çš„å‚æ•°åŒºåŸŸ
                top_10_percent = sorted(all_results, key=lambda x: x.get(metric, 0), reverse=True)[:len(all_results)//10]
                if len(top_10_percent) > 1:
                    recommendations.append("ğŸ’¡ å‘ç°å¤šä¸ªé«˜æ€§èƒ½å‚æ•°ç»„åˆï¼Œå»ºè®®è¿›ä¸€æ­¥ç»†åŒ–æœç´¢èŒƒå›´")
        
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆä¼˜åŒ–å»ºè®®å¤±è´¥: {e}")
        
        return recommendations
    
    def _generate_comparison_recommendations(self, comparison_result: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆç­–ç•¥æ¯”è¾ƒå»ºè®®"""
        recommendations = []
        
        try:
            comparison = comparison_result.get('comparison', {})
            summary = comparison.get('summary', {})
            
            if summary:
                best_return_strategy = summary.get('best_return_strategy')
                best_sharpe_strategy = summary.get('best_sharpe_strategy')
                
                if best_return_strategy:
                    recommendations.append(f"ğŸ“ˆ {best_return_strategy} åœ¨æ€»æ”¶ç›Šç‡æ–¹é¢è¡¨ç°æœ€ä½³")
                
                if best_sharpe_strategy and best_sharpe_strategy != best_return_strategy:
                    recommendations.append(f"âš–ï¸ {best_sharpe_strategy} åœ¨é£é™©è°ƒæ•´æ”¶ç›Šæ–¹é¢è¡¨ç°æœ€ä½³")
                    recommendations.append("ğŸ’¡ å»ºè®®ç»¼åˆè€ƒè™‘æ”¶ç›Šå’Œé£é™©ï¼Œé€‰æ‹©é€‚åˆçš„ç­–ç•¥")
                elif best_sharpe_strategy == best_return_strategy:
                    recommendations.append(f"ğŸ¯ {best_return_strategy} åœ¨æ”¶ç›Šå’Œé£é™©å¹³è¡¡æ–¹é¢éƒ½è¡¨ç°æœ€ä½³")
                
                rankings = comparison.get('rankings', {})
                if 'max_drawdown_percent' in rankings:
                    best_dd_strategy = rankings['max_drawdown_percent'][0]['strategy']
                    recommendations.append(f"ğŸ›¡ï¸ {best_dd_strategy} åœ¨é£é™©æ§åˆ¶æ–¹é¢è¡¨ç°æœ€ä½³")
        
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆç­–ç•¥æ¯”è¾ƒå»ºè®®å¤±è´¥: {e}")
        
        return recommendations
    
    async def export_results(
        self,
        results: Dict[str, Any],
        export_format: str = "json",
        file_path: str = None
    ) -> str:
        """å¯¼å‡ºå›æµ‹ç»“æœ"""
        try:
            if not file_path:
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                file_path = f"logs/cache/backtest_results_{timestamp}.{export_format}"
            
            Path(file_path).parent.mkdir(parents=True, exist_ok=True)
            
            if export_format == "json":
                # å¤„ç†ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡
                serializable_results = self._make_serializable(results)
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(serializable_results, f, ensure_ascii=False, indent=2)
                    
            elif export_format == "pickle":
                with open(file_path, 'wb') as f:
                    pickle.dump(results, f)
                    
            elif export_format == "excel":
                # å¯¼å‡ºåˆ°Excelï¼ˆéœ€è¦openpyxlï¼‰
                await self._export_to_excel(results, file_path)
            else:
                raise BacktestError(f"ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼: {export_format}")
            
            logger.info(f"ğŸ“ å›æµ‹ç»“æœå·²å¯¼å‡ºåˆ°: {file_path}")
            return file_path
            
        except Exception as e:
            logger.error(f"âŒ å¯¼å‡ºå›æµ‹ç»“æœå¤±è´¥: {e}")
            raise BacktestError(f"å¯¼å‡ºå¤±è´¥: {str(e)}")
    
    def _make_serializable(self, obj: Any) -> Any:
        """å°†å¯¹è±¡è½¬æ¢ä¸ºå¯åºåˆ—åŒ–æ ¼å¼"""
        if isinstance(obj, datetime):
            return obj.isoformat()
        elif isinstance(obj, (BacktestMetrics, BacktestTrade)):
            return obj.__dict__
        elif isinstance(obj, dict):
            return {key: self._make_serializable(value) for key, value in obj.items()}
        elif isinstance(obj, list):
            return [self._make_serializable(item) for item in obj]
        elif hasattr(obj, '__dict__'):
            return self._make_serializable(obj.__dict__)
        else:
            return obj
    
    async def _export_to_excel(self, results: Dict[str, Any], file_path: str):
        """å¯¼å‡ºåˆ°Excelæ–‡ä»¶"""
        try:
            import pandas as pd
            
            with pd.ExcelWriter(file_path, engine='openpyxl') as writer:
                # åŸºç¡€æŒ‡æ ‡
                if 'metrics' in results:
                    metrics = results['metrics']
                    metrics_df = pd.DataFrame([metrics.__dict__ if hasattr(metrics, '__dict__') else metrics])
                    metrics_df.to_excel(writer, sheet_name='æŒ‡æ ‡æ±‡æ€»', index=False)
                
                # äº¤æ˜“è®°å½•
                if 'trades' in results:
                    trades_df = pd.DataFrame(results['trades'])
                    if not trades_df.empty:
                        trades_df.to_excel(writer, sheet_name='äº¤æ˜“è®°å½•', index=False)
                
                # ä½™é¢å†å²
                if 'balance_history' in results:
                    balance_df = pd.DataFrame(results['balance_history'], columns=['æ—¶é—´', 'ä½™é¢'])
                    balance_df.to_excel(writer, sheet_name='ä½™é¢å†å²', index=False)
                
        except ImportError:
            logger.warning("âš ï¸ æœªå®‰è£…openpyxlï¼Œæ— æ³•å¯¼å‡ºExcelæ ¼å¼")
            raise BacktestError("éœ€è¦å®‰è£…openpyxlåº“æ¥å¯¼å‡ºExcelæ ¼å¼")
        except Exception as e:
            logger.error(f"âŒ å¯¼å‡ºExcelå¤±è´¥: {e}")
            raise


