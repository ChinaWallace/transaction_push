# -*- coding: utf-8 -*-
"""
Kronosé¢„æµ‹æœåŠ¡
æä¾›åŸºäºKronosæ¨¡å‹çš„ä»·æ ¼é¢„æµ‹åŠŸèƒ½
"""

import asyncio
import sys
import os
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
from dataclasses import dataclass
import pandas as pd
import numpy as np

# æ·»åŠ Kronosæ¨¡å‹è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '../../Kronos-master'))

from app.core.config import get_settings
from app.core.logging import get_logger
from app.utils.exceptions import TradingToolError

# å…¨å±€æœåŠ¡å®ä¾‹
_kronos_service = None


@dataclass
class KronosPrediction:
    """Kronosé¢„æµ‹ç»“æœ"""
    symbol: str
    timestamp: datetime
    current_price: float
    predicted_price: float
    price_change_pct: float
    confidence: float
    prediction_horizon: int  # é¢„æµ‹æ—¶é—´èŒƒå›´ï¼ˆå°æ—¶ï¼‰
    raw_prediction: Optional[Dict] = None
    
    # æ™ºèƒ½é€šçŸ¥æœåŠ¡éœ€è¦çš„é¢å¤–å±æ€§
    signal: str = "hold"  # äº¤æ˜“ä¿¡å·: buy, sell, strong_buy, strong_sell, hold
    volatility: float = 0.0  # æ³¢åŠ¨ç‡
    trend_direction: str = "sideways"  # è¶‹åŠ¿æ–¹å‘: bullish, bearish, sideways
    
    def __post_init__(self):
        """åˆå§‹åŒ–åå¤„ç†ï¼Œæ ¹æ®ä»·æ ¼å˜åŒ–è®¡ç®—ä¿¡å·å’Œè¶‹åŠ¿"""
        if self.price_change_pct > 0.05:  # 5%ä»¥ä¸Šä¸Šæ¶¨
            self.signal = "strong_buy"
            self.trend_direction = "bullish"
        elif self.price_change_pct > 0.02:  # 2%ä»¥ä¸Šä¸Šæ¶¨
            self.signal = "buy"
            self.trend_direction = "bullish"
        elif self.price_change_pct < -0.05:  # 5%ä»¥ä¸Šä¸‹è·Œ
            self.signal = "strong_sell"
            self.trend_direction = "bearish"
        elif self.price_change_pct < -0.02:  # 2%ä»¥ä¸Šä¸‹è·Œ
            self.signal = "sell"
            self.trend_direction = "bearish"
        else:
            self.signal = "hold"
            self.trend_direction = "sideways"
        
        # æ ¹æ®ä»·æ ¼å˜åŒ–å¹…åº¦ä¼°ç®—æ³¢åŠ¨ç‡
        self.volatility = abs(self.price_change_pct) * 0.5  # ç®€å•ä¼°ç®—


class KronosPredictionService:
    """Kronosé¢„æµ‹æœåŠ¡"""
    
    def __init__(self):
        self.settings = get_settings()
        self.logger = get_logger(__name__)
        
        # Kronosé…ç½®
        self.kronos_config = self.settings.kronos_config
        self.enable_kronos = self.kronos_config.get('enable_kronos_prediction', True)
        
        # æ¨¡å‹ç›¸å…³
        self.model = None
        self.tokenizer = None
        self.predictor = None
        self.model_loaded = False
        
        # é¢„æµ‹ç¼“å­˜
        self.prediction_cache = {}
        self.cache_ttl = 300  # 5åˆ†é’Ÿç¼“å­˜
        
        # é¢„æµ‹é…ç½®
        self.prediction_timeout = self.kronos_config.get('prediction_timeout', 120)  # 2åˆ†é’Ÿè¶…æ—¶
        self.max_retries = self.kronos_config.get('max_retries', 2)  # æœ€å¤§é‡è¯•æ¬¡æ•°
        
    async def initialize(self):
        """åˆå§‹åŒ–Kronosæ¨¡å‹"""
        if not self.enable_kronos:
            self.logger.info("Kronosé¢„æµ‹åŠŸèƒ½å·²ç¦ç”¨")
            return False
            
        try:
            self.logger.info("å¼€å§‹åˆå§‹åŒ–Kronosæ¨¡å‹...")
            
            # åŠ¨æ€å¯¼å…¥Kronosæ¨¡å‹
            from model import Kronos, KronosTokenizer, KronosPredictor
            
            # è·å–æ¨¡å‹é…ç½®
            model_name = self.kronos_config.get('model_name', 'NeoQuasar/Kronos-small')
            tokenizer_name = self.kronos_config.get('tokenizer_name', 'NeoQuasar/Kronos-Tokenizer-base')
            device = self.kronos_config.get('device', 'cpu')
            max_context = self.kronos_config.get('max_context', 200)  # å‡å°‘ä¸Šä¸‹æ–‡é•¿åº¦é¿å…å†…å­˜é—®é¢˜
            
            # åŠ è½½tokenizerå’Œæ¨¡å‹
            self.logger.info(f"åˆå§‹åŒ–Kronos tokenizer...")
            # KronosTokenizer å‚æ•°é…ç½®
            tokenizer_params = {
                'd_in': 6,  # è¾“å…¥ç»´åº¦ (OHLCV + amount)
                'd_model': 256,
                'n_heads': 8,
                'ff_dim': 1024,
                'n_enc_layers': 4,
                'n_dec_layers': 4,
                'ffn_dropout_p': 0.1,
                'attn_dropout_p': 0.1,
                'resid_dropout_p': 0.1,
                's1_bits': 8,
                's2_bits': 8,
                'beta': 0.25,
                'gamma0': 1.0,
                'gamma': 0.99,
                'zeta': 1e-4,
                'group_size': 1
            }
            self.tokenizer = KronosTokenizer(**tokenizer_params)
            
            self.logger.info(f"åˆå§‹åŒ–Kronosæ¨¡å‹...")
            # Kronos æ¨¡å‹å‚æ•°é…ç½®
            model_params = {
                's1_bits': 8,
                's2_bits': 8,
                'n_layers': 6,  # å¿…éœ€å‚æ•°
                'd_model': 256,
                'n_heads': 8,
                'ff_dim': 1024,
                'ffn_dropout_p': 0.1,
                'attn_dropout_p': 0.1,
                'resid_dropout_p': 0.1,
                'token_dropout_p': 0.1,  # å¿…éœ€å‚æ•°
                'learn_te': True  # å¿…éœ€å‚æ•°
            }
            self.model = Kronos(**model_params)
            
            # åˆå§‹åŒ–é¢„æµ‹å™¨
            self.predictor = KronosPredictor(
                model=self.model,
                tokenizer=self.tokenizer,
                device=device,
                max_context=max_context
            )
            
            self.model_loaded = True
            self.logger.info("âœ… Kronosæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Kronosæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            self.model_loaded = False
            return False
    
    async def predict_symbol(
        self,
        symbol: str,
        lookback_periods: int = 100,
        prediction_horizon: int = 12,
        force_update: bool = False
    ) -> Optional[Dict[str, Any]]:
        """é¢„æµ‹æŒ‡å®šäº¤æ˜“å¯¹çš„ä»·æ ¼å˜åŒ–"""
        try:
            # è·å–å†å²æ•°æ®
            from app.services.unified_data_service import get_unified_data_service, DataRequest
            data_service = await get_unified_data_service()
            
            # åˆ›å»ºæ•°æ®è¯·æ±‚
            request = DataRequest(
                symbol=symbol,
                timeframe='1h',
                limit=lookback_periods,
                use_cache=True
            )
            
            # è·å–Kçº¿æ•°æ®
            result = await data_service.get_kline_data(request)
            historical_data = result.data
            
            if historical_data is None or len(historical_data) < 50:
                self.logger.warning(f"å†å²æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡ŒKronosé¢„æµ‹: {symbol}")
                return None
            
            # æ‰§è¡Œé¢„æµ‹
            prediction = await self.get_prediction(symbol, historical_data, force_update)
            
            if prediction is None:
                return None
            
            # è¿”å›æ ‡å‡†æ ¼å¼
            return {
                'symbol': prediction.symbol,
                'current_price': prediction.current_price,
                'predicted_price': prediction.predicted_price,
                'price_change_pct': prediction.price_change_pct,
                'confidence': prediction.confidence,
                'prediction_horizon': prediction.prediction_horizon,
                'predictions': [
                    {
                        'timestamp': prediction.timestamp,
                        'close': prediction.predicted_price,
                        'confidence': prediction.confidence
                    }
                ]
            }
            
        except Exception as e:
            self.logger.error(f"é¢„æµ‹{symbol}å¤±è´¥: {e}")
            return None

    async def get_prediction(
        self,
        symbol: str,
        historical_data: pd.DataFrame,
        force_update: bool = False
    ) -> Optional[KronosPrediction]:
        """è·å–Kronosä»·æ ¼é¢„æµ‹"""
        try:
            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åŠ è½½
            if not self.model_loaded:
                if not await self.initialize():
                    return None
            
            # æ£€æŸ¥ç¼“å­˜
            cache_key = f"{symbol}_{len(historical_data)}"
            if not force_update and cache_key in self.prediction_cache:
                cached_result, cache_time = self.prediction_cache[cache_key]
                if (datetime.now() - cache_time).seconds < self.cache_ttl:
                    self.logger.debug(f"ä½¿ç”¨ç¼“å­˜çš„Kronosé¢„æµ‹: {symbol}")
                    return cached_result
            
            # æ•°æ®é¢„å¤„ç†
            processed_data = self._preprocess_data(historical_data)
            if processed_data is None or len(processed_data) < 50:
                self.logger.warning(f"å†å²æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡ŒKronosé¢„æµ‹: {symbol}")
                return None
            
            # æ‰§è¡Œé¢„æµ‹
            prediction_result = await self._run_prediction(symbol, processed_data)
            
            # ç¼“å­˜ç»“æœ
            if prediction_result:
                self.prediction_cache[cache_key] = (prediction_result, datetime.now())
            
            return prediction_result
            
        except Exception as e:
            self.logger.error(f"è·å–{symbol}çš„Kronosé¢„æµ‹å¤±è´¥: {e}")
            return None
    
    def _preprocess_data(self, df: pd.DataFrame) -> Optional[pd.DataFrame]:
        """é¢„å¤„ç†å†å²æ•°æ®"""
        try:
            # ç¡®ä¿å¿…è¦çš„åˆ—å­˜åœ¨
            required_columns = ['open', 'high', 'low', 'close']
            if not all(col in df.columns for col in required_columns):
                self.logger.error(f"å†å²æ•°æ®ç¼ºå°‘å¿…è¦åˆ—: {required_columns}")
                return None
            
            # åˆ›å»ºå‰¯æœ¬é¿å…ä¿®æ”¹åŸæ•°æ®
            processed_df = df.copy()
            
            # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
            for col in required_columns:
                processed_df[col] = pd.to_numeric(processed_df[col], errors='coerce')
            
            # å¤„ç†volumeåˆ—ï¼ˆå¯é€‰ï¼‰
            if 'volume' in processed_df.columns:
                processed_df['volume'] = pd.to_numeric(processed_df['volume'], errors='coerce')
                processed_df['volume'] = processed_df['volume'].fillna(0)
            else:
                processed_df['volume'] = 0
            
            # å¤„ç†amountåˆ—ï¼ˆå¯é€‰ï¼‰
            if 'amount' not in processed_df.columns:
                processed_df['amount'] = processed_df['close'] * processed_df['volume']
            else:
                processed_df['amount'] = pd.to_numeric(processed_df['amount'], errors='coerce')
                processed_df['amount'] = processed_df['amount'].fillna(0)
            
            # åˆ é™¤åŒ…å«NaNçš„è¡Œ
            processed_df = processed_df.dropna(subset=required_columns)
            
            # ç¡®ä¿æ•°æ®è´¨é‡
            if len(processed_df) < 20:
                self.logger.error(f"é¢„å¤„ç†åæ•°æ®ä¸è¶³: {len(processed_df)} < 20")
                return None
            
            # æŒ‰æ—¶é—´æ’åºï¼ˆå¦‚æœæœ‰æ—¶é—´ç´¢å¼•ï¼‰
            if isinstance(processed_df.index, pd.DatetimeIndex):
                processed_df = processed_df.sort_index()
            
            # é™åˆ¶æ•°æ®é•¿åº¦ï¼ˆKronosæ¨¡å‹çš„ä¸Šä¸‹æ–‡é™åˆ¶ï¼‰
            max_length = self.kronos_config.get('max_context', 200)  # å‡å°‘ä¸Šä¸‹æ–‡é•¿åº¦é¿å…å†…å­˜é—®é¢˜
            if len(processed_df) > max_length:
                processed_df = processed_df.tail(max_length)
            
            # ç¡®ä¿æ•°æ®è¿ç»­æ€§ï¼ˆæ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸å€¼ï¼‰
            for col in required_columns:
                # ç§»é™¤æç«¯å¼‚å¸¸å€¼ï¼ˆè¶…è¿‡3ä¸ªæ ‡å‡†å·®ï¼‰
                mean_val = processed_df[col].mean()
                std_val = processed_df[col].std()
                if std_val > 0:
                    lower_bound = mean_val - 3 * std_val
                    upper_bound = mean_val + 3 * std_val
                    processed_df = processed_df[
                        (processed_df[col] >= lower_bound) & 
                        (processed_df[col] <= upper_bound)
                    ]
            
            # æœ€ç»ˆæ£€æŸ¥
            if len(processed_df) < 20:
                self.logger.error(f"å¼‚å¸¸å€¼è¿‡æ»¤åæ•°æ®ä¸è¶³: {len(processed_df)} < 20")
                return None
            
            self.logger.debug(f"é¢„å¤„ç†å®Œæˆï¼Œæ•°æ®é•¿åº¦: {len(processed_df)}")
            return processed_df
            
        except Exception as e:
            self.logger.error(f"æ•°æ®é¢„å¤„ç†å¤±è´¥: {e}")
            return None
    
    async def _run_prediction(
        self,
        symbol: str,
        historical_data: pd.DataFrame
    ) -> Optional[KronosPrediction]:
        """æ‰§è¡ŒKronosé¢„æµ‹"""
        try:
            # é¢„æµ‹é…ç½® - ä½¿ç”¨æ›´ä¿å®ˆçš„è®¾ç½®
            pred_len = min(self.kronos_config.get('prediction_length', 12), 24)  # æœ€å¤šé¢„æµ‹24å°æ—¶ï¼Œé»˜è®¤12å°æ—¶
            temperature = self.kronos_config.get('temperature', 0.8)  # é™ä½æ¸©åº¦æé«˜ç¨³å®šæ€§
            top_p = self.kronos_config.get('top_p', 0.95)  # æé«˜top_pæé«˜ç¨³å®šæ€§
            sample_count = self.kronos_config.get('sample_count', 1)  # ä¿æŒå•æ ·æœ¬é¿å…å†…å­˜é—®é¢˜
            
            # å‡†å¤‡æ—¶é—´æˆ³
            if isinstance(historical_data.index, pd.DatetimeIndex):
                x_timestamp = historical_data.index
                # ç”Ÿæˆæœªæ¥æ—¶é—´æˆ³ï¼ˆå‡è®¾1å°æ—¶é—´éš”ï¼‰
                last_time = x_timestamp[-1]
                y_timestamp = pd.date_range(
                    start=last_time + timedelta(hours=1),
                    periods=pred_len,
                    freq='h'
                )
            else:
                # å¦‚æœæ²¡æœ‰æ—¶é—´ç´¢å¼•ï¼Œåˆ›å»ºè™šæ‹Ÿæ—¶é—´æˆ³
                now = datetime.now()
                x_timestamp = pd.date_range(
                    end=now,
                    periods=len(historical_data),
                    freq='h'
                )
                y_timestamp = pd.date_range(
                    start=now + timedelta(hours=1),
                    periods=pred_len,
                    freq='h'
                )
            
            # æ‰§è¡Œé¢„æµ‹
            self.logger.debug(f"å¼€å§‹Kronosé¢„æµ‹: {symbol}, é¢„æµ‹é•¿åº¦: {pred_len}")
            
            # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œé¢„æµ‹ï¼ˆé¿å…é˜»å¡ï¼‰ï¼Œæ·»åŠ è¶…æ—¶æ§åˆ¶
            loop = asyncio.get_event_loop()
            try:
                pred_df = await asyncio.wait_for(
                    loop.run_in_executor(
                        None,
                        self._sync_predict,
                        historical_data,
                        x_timestamp,
                        y_timestamp,
                        pred_len,
                        temperature,
                        top_p,
                        sample_count
                    ),
                    timeout=self.prediction_timeout
                )
            except asyncio.TimeoutError:
                self.logger.error(f"Kronosé¢„æµ‹è¶…æ—¶ ({self.prediction_timeout}ç§’): {symbol}")
                return None
            
            if pred_df is None or pred_df.empty:
                self.logger.warning(f"Kronosé¢„æµ‹è¿”å›ç©ºç»“æœ: {symbol}")
                return None
            
            # è§£æé¢„æµ‹ç»“æœ
            current_price = float(historical_data['close'].iloc[-1])
            predicted_price = float(pred_df['close'].iloc[-1])  # å–æœ€åä¸€ä¸ªé¢„æµ‹ä»·æ ¼
            price_change_pct = (predicted_price - current_price) / current_price
            
            # è®¡ç®—ç½®ä¿¡åº¦ï¼ˆåŸºäºé¢„æµ‹çš„ç¨³å®šæ€§ï¼‰
            confidence = self._calculate_confidence(pred_df, historical_data)
            
            prediction = KronosPrediction(
                symbol=symbol,
                timestamp=datetime.now(),
                current_price=current_price,
                predicted_price=predicted_price,
                price_change_pct=price_change_pct,
                confidence=confidence,
                prediction_horizon=pred_len,
                raw_prediction={
                    'prediction_df': pred_df.to_dict(),
                    'prediction_length': pred_len,
                    'model_config': {
                        'temperature': temperature,
                        'top_p': top_p,
                        'sample_count': sample_count
                    }
                }
            )
            
            self.logger.info(
                f"Kronosé¢„æµ‹å®Œæˆ - {symbol}: "
                f"å½“å‰ä»·æ ¼ {current_price:.4f} -> é¢„æµ‹ä»·æ ¼ {predicted_price:.4f} "
                f"({price_change_pct*100:+.2f}%, ç½®ä¿¡åº¦: {confidence:.2f})"
            )
            
            return prediction
            
        except Exception as e:
            self.logger.error(f"æ‰§è¡ŒKronosé¢„æµ‹å¤±è´¥: {e}")
            return None
    
    def _sync_predict(
        self,
        df: pd.DataFrame,
        x_timestamp: pd.Series,
        y_timestamp: pd.Series,
        pred_len: int,
        temperature: float,
        top_p: float,
        sample_count: int
    ) -> Optional[pd.DataFrame]:
        """åŒæ­¥é¢„æµ‹æ–¹æ³•ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼‰"""
        try:
            # æ·»åŠ è¾“å…¥éªŒè¯
            if df is None or len(df) == 0:
                self.logger.error("è¾“å…¥æ•°æ®ä¸ºç©º")
                return None
                
            if x_timestamp is None or y_timestamp is None:
                self.logger.error("æ—¶é—´æˆ³æ•°æ®ä¸ºç©º")
                return None
            
            # éªŒè¯æ•°æ®é•¿åº¦åŒ¹é…
            if len(df) != len(x_timestamp):
                self.logger.error(f"æ•°æ®é•¿åº¦ä¸åŒ¹é…: df={len(df)}, x_timestamp={len(x_timestamp)}")
                return None
                
            # é™åˆ¶é¢„æµ‹é•¿åº¦ä»¥é¿å…å†…å­˜é—®é¢˜
            max_pred_len = min(pred_len, len(y_timestamp), 50)  # æœ€å¤šé¢„æµ‹50æ­¥
            if max_pred_len != pred_len:
                self.logger.warning(f"é¢„æµ‹é•¿åº¦ä» {pred_len} è°ƒæ•´ä¸º {max_pred_len}")
                pred_len = max_pred_len
                y_timestamp = y_timestamp[:pred_len]
            
            # æ·»åŠ è¶…æ—¶å’Œé‡è¯•æœºåˆ¶
            max_retries = 2
            for attempt in range(max_retries):
                try:
                    self.logger.debug(f"å¼€å§‹é¢„æµ‹å°è¯• {attempt + 1}/{max_retries}")
                    
                    # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
                    df_clean = df.copy()
                    
                    # éªŒè¯å¿…è¦åˆ—å­˜åœ¨
                    required_cols = ['open', 'high', 'low', 'close']
                    if not all(col in df_clean.columns for col in required_cols):
                        self.logger.error(f"ç¼ºå°‘å¿…è¦åˆ—: {required_cols}")
                        return None
                    
                    # ç¡®ä¿æ•°å€¼ç±»å‹
                    for col in required_cols + ['volume', 'amount']:
                        if col in df_clean.columns:
                            df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')
                    
                    # åˆ é™¤NaNè¡Œ
                    df_clean = df_clean.dropna(subset=required_cols)
                    if len(df_clean) < 10:
                        self.logger.error("æ¸…ç†åæ•°æ®ä¸è¶³")
                        return None
                    
                    # è°ƒæ•´æ—¶é—´æˆ³é•¿åº¦ä»¥åŒ¹é…æ¸…ç†åçš„æ•°æ®
                    if len(df_clean) != len(x_timestamp):
                        x_timestamp_clean = x_timestamp[-len(df_clean):]
                    else:
                        x_timestamp_clean = x_timestamp
                    
                    result = self.predictor.predict(
                        df=df_clean,
                        x_timestamp=x_timestamp_clean,
                        y_timestamp=y_timestamp,
                        pred_len=pred_len,
                        T=temperature,
                        top_p=top_p,
                        sample_count=sample_count,
                        verbose=True  # æ˜¾ç¤ºè¿›åº¦æ¡
                    )
                    
                    # éªŒè¯ç»“æœ
                    if result is None:
                        self.logger.warning(f"é¢„æµ‹å°è¯• {attempt + 1} è¿”å› None")
                        if attempt < max_retries - 1:
                            continue
                        return None
                    
                    # æ£€æŸ¥ç»“æœç±»å‹å’Œå½¢çŠ¶
                    if not isinstance(result, pd.DataFrame):
                        self.logger.error(f"é¢„æµ‹ç»“æœç±»å‹é”™è¯¯: {type(result)}")
                        if attempt < max_retries - 1:
                            continue
                        return None
                    
                    if len(result) == 0:
                        self.logger.warning(f"é¢„æµ‹å°è¯• {attempt + 1} è¿”å›ç©ºç»“æœ")
                        if attempt < max_retries - 1:
                            continue
                        return None
                    
                    # éªŒè¯é¢„æµ‹é•¿åº¦æ˜¯å¦æ­£ç¡®
                    if len(result) != pred_len:
                        self.logger.warning(f"é¢„æµ‹é•¿åº¦ä¸åŒ¹é…: æœŸæœ› {pred_len}, å®é™… {len(result)}")
                        # æˆªå–æˆ–å¡«å……åˆ°æ­£ç¡®é•¿åº¦
                        if len(result) > pred_len:
                            result = result.iloc[:pred_len]
                        elif len(result) < pred_len:
                            # ç”¨æœ€åä¸€è¡Œå¡«å……
                            last_row = result.iloc[-1:].copy()
                            for _ in range(pred_len - len(result)):
                                result = pd.concat([result, last_row], ignore_index=True)
                    
                    # ç¡®ä¿æ—¶é—´æˆ³æ­£ç¡®
                    if len(result) == len(y_timestamp):
                        result.index = y_timestamp
                    
                    self.logger.debug(f"é¢„æµ‹æˆåŠŸï¼Œç»“æœé•¿åº¦: {len(result)}")
                    return result
                    
                except Exception as e:
                    self.logger.error(f"é¢„æµ‹å°è¯• {attempt + 1} å¤±è´¥: {e}")
                    if attempt < max_retries - 1:
                        # çŸ­æš‚ç­‰å¾…åé‡è¯•
                        import time
                        time.sleep(1)
                        continue
                    raise e
            
            return None
            
        except Exception as e:
            self.logger.error(f"åŒæ­¥é¢„æµ‹æ‰§è¡Œå¤±è´¥: {e}")
            return None
    
    def _calculate_confidence(
        self,
        pred_df: pd.DataFrame,
        historical_data: pd.DataFrame
    ) -> float:
        """è®¡ç®—é¢„æµ‹ç½®ä¿¡åº¦"""
        try:
            # åŸºäºå¤šä¸ªå› ç´ è®¡ç®—ç½®ä¿¡åº¦
            confidence_factors = []
            
            # 1. é¢„æµ‹ä»·æ ¼çš„ç¨³å®šæ€§ï¼ˆæ³¢åŠ¨è¶Šå°ï¼Œç½®ä¿¡åº¦è¶Šé«˜ï¼‰
            if len(pred_df) > 1:
                price_volatility = pred_df['close'].std() / pred_df['close'].mean()
                volatility_confidence = max(0, 1 - price_volatility * 10)  # æ³¢åŠ¨ç‡è½¬ç½®ä¿¡åº¦
                confidence_factors.append(volatility_confidence)
            
            # 2. é¢„æµ‹è¶‹åŠ¿çš„ä¸€è‡´æ€§
            if len(pred_df) > 2:
                price_changes = pred_df['close'].pct_change().dropna()
                trend_consistency = 1 - abs(price_changes.std())  # å˜åŒ–ç‡çš„æ ‡å‡†å·®è¶Šå°è¶Šå¥½
                confidence_factors.append(max(0, min(1, trend_consistency)))
            
            # 3. å†å²æ•°æ®è´¨é‡ï¼ˆæ•°æ®è¶Šå¤šè¶Šç¨³å®šï¼Œç½®ä¿¡åº¦è¶Šé«˜ï¼‰
            data_quality = min(1.0, len(historical_data) / 200)  # 200ä¸ªæ•°æ®ç‚¹ä¸ºæ»¡åˆ†
            confidence_factors.append(data_quality)
            
            # 4. é¢„æµ‹å¹…åº¦åˆç†æ€§ï¼ˆè¿‡å¤§çš„é¢„æµ‹å˜åŒ–é™ä½ç½®ä¿¡åº¦ï¼‰
            current_price = historical_data['close'].iloc[-1]
            predicted_price = pred_df['close'].iloc[-1]
            price_change = abs((predicted_price - current_price) / current_price)
            
            if price_change > 0.2:  # è¶…è¿‡20%å˜åŒ–
                magnitude_confidence = 0.3
            elif price_change > 0.1:  # è¶…è¿‡10%å˜åŒ–
                magnitude_confidence = 0.6
            elif price_change > 0.05:  # è¶…è¿‡5%å˜åŒ–
                magnitude_confidence = 0.8
            else:
                magnitude_confidence = 1.0
            
            confidence_factors.append(magnitude_confidence)
            
            # ç»¼åˆç½®ä¿¡åº¦ï¼ˆåŠ æƒå¹³å‡ï¼‰
            if confidence_factors:
                final_confidence = np.mean(confidence_factors)
                # ç¡®ä¿ç½®ä¿¡åº¦åœ¨åˆç†èŒƒå›´å†…
                return max(0.1, min(0.95, final_confidence))
            else:
                return 0.5  # é»˜è®¤ä¸­ç­‰ç½®ä¿¡åº¦
                
        except Exception as e:
            self.logger.error(f"è®¡ç®—ç½®ä¿¡åº¦å¤±è´¥: {e}")
            return 0.5
    
    async def batch_predict(
        self,
        symbols_data: Dict[str, pd.DataFrame],
        force_update: bool = False
    ) -> Dict[str, Optional[KronosPrediction]]:
        """æ‰¹é‡é¢„æµ‹å¤šä¸ªäº¤æ˜“å¯¹"""
        results = {}
        
        for symbol, data in symbols_data.items():
            try:
                prediction = await self.get_prediction(symbol, data, force_update)
                results[symbol] = prediction
            except Exception as e:
                self.logger.error(f"æ‰¹é‡é¢„æµ‹{symbol}å¤±è´¥: {e}")
                results[symbol] = None
        
        return results
    
    def get_model_info(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        return {
            'model_loaded': self.model_loaded,
            'enable_kronos': self.enable_kronos,
            'model_config': self.kronos_config,
            'cache_size': len(self.prediction_cache)
        }
    
    def get_cached_prediction(self, symbol: str) -> Optional[KronosPrediction]:
        """è·å–ç¼“å­˜çš„é¢„æµ‹ç»“æœ"""
        try:
            # æŸ¥æ‰¾æœ€æ–°çš„ç¼“å­˜ç»“æœ
            for cache_key, (cached_result, cache_time) in self.prediction_cache.items():
                if symbol in cache_key:
                    # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
                    if (datetime.now() - cache_time).seconds < self.cache_ttl:
                        self.logger.debug(f"ğŸ” è·å–ç¼“å­˜çš„Kronosé¢„æµ‹: {symbol}")
                        return cached_result
            
            self.logger.debug(f"ğŸ” æœªæ‰¾åˆ°æœ‰æ•ˆç¼“å­˜: {symbol}")
            return None
            
        except Exception as e:
            self.logger.warning(f"è·å–ç¼“å­˜é¢„æµ‹å¤±è´¥ {symbol}: {e}")
            return None
    
    def clear_cache(self):
        """æ¸…ç©ºé¢„æµ‹ç¼“å­˜"""
        self.prediction_cache.clear()
        self.logger.info("Kronosé¢„æµ‹ç¼“å­˜å·²æ¸…ç©º")


async def get_kronos_service() -> Optional[KronosPredictionService]:
    """è·å–Kronosé¢„æµ‹æœåŠ¡å®ä¾‹"""
    global _kronos_service
    
    if _kronos_service is None:
        _kronos_service = KronosPredictionService()
        
        # å°è¯•åˆå§‹åŒ–
        if not await _kronos_service.initialize():
            _kronos_service = None
            return None
    
    return _kronos_service