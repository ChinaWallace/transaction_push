# -*- coding: utf-8 -*-
"""
æ–°é—»åˆ†æAPIæ¥å£
"""

from typing import List, Optional
from datetime import datetime, timedelta
from fastapi import APIRouter, Query, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse

from app.core.logging import get_logger
from app.schemas.news import (
    NewsRequest, NewsResponse, NewsAnalysisRequest, NewsAnalysisResponse,
    NewsItem, NewsAnalysisResult
)
from app.services.news_analysis_service import NewsAnalysisService
from app.services.notification_service import NotificationService

logger = get_logger(__name__)
router = APIRouter()


@router.get("/latest", response_model=NewsResponse)
async def get_latest_news(
    limit: int = Query(default=20, ge=1, le=100, description="è·å–æ–°é—»æ•°é‡"),
    category: Optional[str] = Query(default=None, description="æ–°é—»åˆ†ç±»"),
    hours_back: int = Query(default=24, ge=1, le=168, description="è·å–å¤šå°‘å°æ—¶å†…çš„æ–°é—»")
) -> NewsResponse:
    """è·å–æœ€æ–°æ–°é—»"""
    try:
        async with NewsAnalysisService() as news_service:
            news_items = await news_service.fetch_latest_news(
                limit=limit,
                category=category
            )
            
            # è¿‡æ»¤æ—¶é—´èŒƒå›´
            if hours_back < 168:  # å¦‚æœä¸æ˜¯è·å–å…¨éƒ¨
                cutoff_time = datetime.now() - timedelta(hours=hours_back)
                news_items = [
                    item for item in news_items 
                    if item.publish_time >= cutoff_time
                ]
            
            return NewsResponse(
                status="success",
                message=f"æˆåŠŸè·å– {len(news_items)} æ¡æ–°é—»",
                data=news_items,
                total_count=len(news_items),
                timestamp=datetime.now()
            )
            
    except Exception as e:
        logger.error(f"è·å–æœ€æ–°æ–°é—»å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–æ–°é—»å¤±è´¥: {str(e)}")


@router.post("/analyze", response_model=NewsAnalysisResponse)
async def analyze_news(
    request: NewsAnalysisRequest,
    background_tasks: BackgroundTasks
) -> NewsAnalysisResponse:
    """åˆ†ææ–°é—»å¹¶é›†æˆKronosé¢„æµ‹"""
    try:
        async with NewsAnalysisService() as news_service:
            # è·å–è¦åˆ†æçš„æ–°é—»
            if request.auto_fetch:
                # è‡ªåŠ¨è·å–æœ€æ–°æ–°é—»
                news_items = await news_service.fetch_latest_news(limit=30)
                
                # å¦‚æœæœ‰å¸ç§è¿‡æ»¤ï¼Œåªåˆ†æç›¸å…³æ–°é—»
                if request.symbol_filter:
                    filtered_news = []
                    for item in news_items:
                        if any(symbol in item.mentioned_symbols for symbol in request.symbol_filter):
                            filtered_news.append(item)
                    news_items = filtered_news
            else:
                # æ ¹æ®æŒ‡å®šIDè·å–æ–°é—»ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…éœ€è¦å®ç°æ ¹æ®IDè·å–ï¼‰
                news_items = await news_service.fetch_latest_news(limit=10)
            
            # æ‰§è¡Œåˆ†æ
            if request.enable_kronos:
                analysis_results = await news_service.analyze_news_with_kronos(news_items)
            else:
                # åªåšåŸºç¡€åˆ†æï¼Œä¸ä½¿ç”¨Kronos
                analysis_results = []
                for item in news_items:
                    basic_analysis = await news_service._analyze_single_news(item)
                    analysis_results.append(basic_analysis)
            
            # ç”Ÿæˆåˆ†ææ‘˜è¦
            summary = _generate_analysis_summary(analysis_results)
            
            # åå°ä»»åŠ¡ï¼šå‘é€é‡è¦ä¿¡å·é€šçŸ¥
            if analysis_results:
                background_tasks.add_task(
                    _send_important_signals_notification,
                    analysis_results
                )
            
            return NewsAnalysisResponse(
                status="success",
                message=f"æˆåŠŸåˆ†æ {len(analysis_results)} æ¡æ–°é—»",
                data=analysis_results,
                summary=summary,
                timestamp=datetime.now()
            )
            
    except Exception as e:
        logger.error(f"æ–°é—»åˆ†æå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"åˆ†æå¤±è´¥: {str(e)}")


@router.get("/market-impact", response_model=NewsAnalysisResponse)
async def get_market_impact_news(
    hours_back: int = Query(default=24, ge=1, le=168, description="å›çœ‹æ—¶é—´ï¼ˆå°æ—¶ï¼‰"),
    min_importance: float = Query(default=0.5, ge=0.0, le=1.0, description="æœ€ä½é‡è¦æ€§é˜ˆå€¼")
) -> NewsAnalysisResponse:
    """è·å–æœ‰å¸‚åœºå½±å“çš„æ–°é—»åˆ†æ"""
    try:
        async with NewsAnalysisService() as news_service:
            # è·å–å¸‚åœºå½±å“è¾ƒå¤§çš„æ–°é—»
            market_news = await news_service.get_market_moving_news(hours_back=hours_back)
            
            # æŒ‰é‡è¦æ€§è¿‡æ»¤
            filtered_news = [
                result for result in market_news
                if (result.news_item.importance_score or 0) >= min_importance
            ]
            
            # ç”Ÿæˆæ‘˜è¦
            summary = _generate_analysis_summary(filtered_news)
            summary['filter_criteria'] = {
                'hours_back': hours_back,
                'min_importance': min_importance
            }
            
            return NewsAnalysisResponse(
                status="success",
                message=f"å‘ç° {len(filtered_news)} æ¡æœ‰å¸‚åœºå½±å“çš„æ–°é—»",
                data=filtered_news,
                summary=summary,
                timestamp=datetime.now()
            )
            
    except Exception as e:
        logger.error(f"è·å–å¸‚åœºå½±å“æ–°é—»å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–å¤±è´¥: {str(e)}")


@router.get("/symbols/{symbol}/news", response_model=NewsAnalysisResponse)
async def get_symbol_related_news(
    symbol: str,
    hours_back: int = Query(default=48, ge=1, le=168, description="å›çœ‹æ—¶é—´ï¼ˆå°æ—¶ï¼‰"),
    enable_kronos: bool = Query(default=True, description="æ˜¯å¦å¯ç”¨Kronosåˆ†æ")
) -> NewsAnalysisResponse:
    """è·å–ç‰¹å®šå¸ç§ç›¸å…³çš„æ–°é—»åˆ†æ"""
    try:
        async with NewsAnalysisService() as news_service:
            # è·å–æœ€æ–°æ–°é—»
            all_news = await news_service.fetch_latest_news(limit=100)
            
            # è¿‡æ»¤æ—¶é—´å’Œå¸ç§ç›¸å…³çš„æ–°é—»
            cutoff_time = datetime.now() - timedelta(hours=hours_back)
            symbol_news = []
            
            for item in all_news:
                if item.publish_time >= cutoff_time:
                    # æ£€æŸ¥æ˜¯å¦æåŠè¯¥å¸ç§
                    if (symbol in item.mentioned_symbols or 
                        any(symbol.split('-')[0].lower() in item.title.lower() or 
                            symbol.split('-')[0].lower() in item.content.lower())):
                        symbol_news.append(item)
            
            # åˆ†ææ–°é—»
            if enable_kronos and symbol_news:
                analysis_results = await news_service.analyze_news_with_kronos(symbol_news)
            else:
                analysis_results = []
                for item in symbol_news:
                    basic_analysis = await news_service._analyze_single_news(item)
                    analysis_results.append(basic_analysis)
            
            # ç”Ÿæˆæ‘˜è¦
            summary = _generate_analysis_summary(analysis_results)
            summary['target_symbol'] = symbol
            
            return NewsAnalysisResponse(
                status="success",
                message=f"æ‰¾åˆ° {len(analysis_results)} æ¡ä¸ {symbol} ç›¸å…³çš„æ–°é—»",
                data=analysis_results,
                summary=summary,
                timestamp=datetime.now()
            )
            
    except Exception as e:
        logger.error(f"è·å–{symbol}ç›¸å…³æ–°é—»å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–å¤±è´¥: {str(e)}")


@router.post("/monitor/start")
async def start_news_monitoring(
    background_tasks: BackgroundTasks,
    interval_minutes: int = Query(default=30, ge=5, le=180, description="ç›‘æ§é—´éš”ï¼ˆåˆ†é’Ÿï¼‰")
) -> JSONResponse:
    """å¯åŠ¨æ–°é—»ç›‘æ§"""
    try:
        # æ·»åŠ åå°ç›‘æ§ä»»åŠ¡
        background_tasks.add_task(
            _start_continuous_news_monitoring,
            interval_minutes
        )
        
        return JSONResponse(
            status_code=200,
            content={
                "status": "success",
                "message": f"æ–°é—»ç›‘æ§å·²å¯åŠ¨ï¼Œé—´éš” {interval_minutes} åˆ†é’Ÿ",
                "timestamp": datetime.now().isoformat()
            }
        )
        
    except Exception as e:
        logger.error(f"å¯åŠ¨æ–°é—»ç›‘æ§å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å¯åŠ¨å¤±è´¥: {str(e)}")


def _generate_analysis_summary(analysis_results: List[NewsAnalysisResult]) -> dict:
    """ç”Ÿæˆåˆ†ææ‘˜è¦"""
    if not analysis_results:
        return {
            "total_analyzed": 0,
            "positive_sentiment": 0,
            "negative_sentiment": 0,
            "neutral_sentiment": 0,
            "trading_signals_generated": 0,
            "kronos_analyses": 0
        }
    
    positive_count = 0
    negative_count = 0
    neutral_count = 0
    total_signals = 0
    kronos_count = 0
    
    for result in analysis_results:
        # ç»Ÿè®¡æƒ…æ„Ÿåˆ†å¸ƒ
        sentiment = result.sentiment_analysis.get('overall_sentiment', 'neutral')
        if sentiment == 'positive':
            positive_count += 1
        elif sentiment == 'negative':
            negative_count += 1
        else:
            neutral_count += 1
        
        # ç»Ÿè®¡äº¤æ˜“ä¿¡å·
        total_signals += len(result.trading_signals)
        
        # ç»Ÿè®¡Kronosåˆ†æ
        if result.kronos_analysis:
            kronos_count += 1
    
    return {
        "total_analyzed": len(analysis_results),
        "positive_sentiment": positive_count,
        "negative_sentiment": negative_count,
        "neutral_sentiment": neutral_count,
        "trading_signals_generated": total_signals,
        "kronos_analyses": kronos_count,
        "sentiment_distribution": {
            "positive_pct": round(positive_count / len(analysis_results) * 100, 1),
            "negative_pct": round(negative_count / len(analysis_results) * 100, 1),
            "neutral_pct": round(neutral_count / len(analysis_results) * 100, 1)
        }
    }


async def _send_important_signals_notification(analysis_results: List[NewsAnalysisResult]):
    """å‘é€é‡è¦ä¿¡å·é€šçŸ¥"""
    try:
        # ç­›é€‰é‡è¦ä¿¡å·
        important_signals = []
        
        for result in analysis_results:
            # é«˜é‡è¦æ€§æˆ–å¼ºæƒ…æ„Ÿçš„æ–°é—»
            if ((result.news_item.importance_score or 0) > 0.7 or 
                abs(result.news_item.sentiment_score or 0) > 0.6):
                
                for signal in result.trading_signals:
                    if signal.get('confidence', 0) > 0.6:
                        important_signals.append({
                            'news_title': result.news_item.title,
                            'symbol': signal['symbol'],
                            'signal': signal['signal'],
                            'confidence': signal['confidence'],
                            'reason': signal['reason']
                        })
        
        if important_signals:
            # å‘é€é€šçŸ¥
            async with NotificationService() as notification_service:
                message = "ğŸ“° é‡è¦æ–°é—»äº¤æ˜“ä¿¡å·\n\n"
                
                for i, signal in enumerate(important_signals[:5], 1):  # æœ€å¤š5ä¸ªä¿¡å·
                    message += f"{i}. {signal['news_title'][:50]}...\n"
                    message += f"   å¸ç§: {signal['symbol']}\n"
                    message += f"   ä¿¡å·: {signal['signal']} (ç½®ä¿¡åº¦: {signal['confidence']:.2f})\n"
                    message += f"   åŸå› : {signal['reason']}\n\n"
                
                await notification_service.send_notification(
                    message=message,
                    title="æ–°é—»åˆ†æäº¤æ˜“ä¿¡å·",
                    priority="high"
                )
                
                logger.info(f"å·²å‘é€ {len(important_signals)} ä¸ªé‡è¦æ–°é—»äº¤æ˜“ä¿¡å·é€šçŸ¥")
        
    except Exception as e:
        logger.error(f"å‘é€æ–°é—»ä¿¡å·é€šçŸ¥å¤±è´¥: {e}")


async def _start_continuous_news_monitoring(interval_minutes: int):
    """å¯åŠ¨æŒç»­æ–°é—»ç›‘æ§"""
    import asyncio
    
    logger.info(f"å¼€å§‹æŒç»­æ–°é—»ç›‘æ§ï¼Œé—´éš” {interval_minutes} åˆ†é’Ÿ")
    
    while True:
        try:
            async with NewsAnalysisService() as news_service:
                # è·å–æœ€æ–°æ–°é—»å¹¶åˆ†æ
                market_news = await news_service.get_market_moving_news(hours_back=2)
                
                if market_news:
                    # å‘é€é€šçŸ¥
                    await _send_important_signals_notification(market_news)
                
                logger.info(f"æ–°é—»ç›‘æ§å®Œæˆï¼Œå‘ç° {len(market_news)} æ¡é‡è¦æ–°é—»")
            
            # ç­‰å¾…ä¸‹æ¬¡ç›‘æ§
            await asyncio.sleep(interval_minutes * 60)
            
        except Exception as e:
            logger.error(f"æ–°é—»ç›‘æ§å¼‚å¸¸: {e}")
            # å‡ºé”™åç­‰å¾…è¾ƒçŸ­æ—¶é—´å†é‡è¯•
            await asyncio.sleep(300)  # 5åˆ†é’Ÿåé‡è¯•