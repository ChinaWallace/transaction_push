# -*- coding: utf-8 -*-
"""
HTTPå®¢æˆ·ç«¯å·¥å…·
HTTP client utility for making API requests
"""

import asyncio
import aiohttp
from typing import Dict, Any, Optional
import json
from datetime import datetime, timedelta

from app.core.logging import get_logger
from app.core.config import get_settings
from app.utils.exceptions import RateLimitError, BinanceAPIError

logger = get_logger(__name__)


class HTTPClient:
    """HTTPå®¢æˆ·ç«¯ç±» - ä½¿ç”¨è¿æ¥æ± """
    
    # ç±»çº§åˆ«çš„å…±äº«sessionï¼Œå®ç°è¿æ¥æ± å¤ç”¨
    _shared_session = None
    _session_lock = asyncio.Lock()
    
    def __init__(self, timeout: int = 30, max_retries: int = 3, use_proxy: bool = None):
        self.timeout = timeout
        self.max_retries = max_retries
        self.session = None
        self._rate_limit_reset = {}
        
        # ä»£ç†é…ç½®
        settings = get_settings()
        if use_proxy is None:
            self.use_proxy = settings.proxy_enabled
        else:
            self.use_proxy = use_proxy
        self.proxy_url = settings.proxy_url if self.use_proxy else None
        
    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        await self.start_session()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        await self.close_session()
    
    async def start_session(self):
        """å¯åŠ¨ä¼šè¯ - ä½¿ç”¨å…±äº«è¿æ¥æ± """
        if self.session is None:
            # ä½¿ç”¨å…±äº«sessionå®ç°è¿æ¥æ± å¤ç”¨
            async with HTTPClient._session_lock:
                if HTTPClient._shared_session is None or HTTPClient._shared_session.closed:
                    await self._create_shared_session()
                self.session = HTTPClient._shared_session
    
    async def _create_shared_session(self):
        """åˆ›å»ºå…±äº«session"""
        settings = get_settings()
        http_config = settings.http_pool_config
        
        # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è¿æ¥æ± é…ç½®
        connector = aiohttp.TCPConnector(
            limit=http_config["pool_limit"],                    # æ€»è¿æ¥æ± å¤§å°
            limit_per_host=http_config["pool_limit_per_host"],  # æ¯ä¸ªä¸»æœºçš„è¿æ¥æ•°
            keepalive_timeout=http_config["keepalive_timeout"], # ä¿æŒè¿æ¥æ—¶é—´
            enable_cleanup_closed=True,                         # è‡ªåŠ¨æ¸…ç†å…³é—­çš„è¿æ¥
            ttl_dns_cache=http_config["dns_cache_ttl"],        # DNSç¼“å­˜æ—¶é—´
            use_dns_cache=True,                                # å¯ç”¨DNSç¼“å­˜
            ssl=False,                                         # å¯¹äºHTTP APIï¼Œç¦ç”¨SSLéªŒè¯ä»¥æé«˜æ€§èƒ½
            force_close=False                                  # ä¸å¼ºåˆ¶å…³é—­è¿æ¥ï¼Œå¤ç”¨è¿æ¥
        )
        
        timeout = aiohttp.ClientTimeout(
            total=http_config["total_timeout"],
            connect=http_config["connect_timeout"],      # è¿æ¥è¶…æ—¶
            sock_read=http_config["read_timeout"],       # è¯»å–è¶…æ—¶
            sock_connect=http_config["connect_timeout"]  # socketè¿æ¥è¶…æ—¶
        )
        
        # è®¾ç½®ä»£ç†
        session_kwargs = {
            'connector': connector,
            'timeout': timeout,
            'headers': {
                'User-Agent': 'Python-Trading-Tool/1.0.0',
                'Accept': 'application/json',
                'Accept-Encoding': 'gzip, deflate',
                'Connection': 'keep-alive'  # ä¿æŒè¿æ¥
            },
            'cookie_jar': aiohttp.CookieJar(),  # å¯ç”¨cookieæ”¯æŒ
            'raise_for_status': False,  # ä¸è‡ªåŠ¨æŠ›å‡ºHTTPé”™è¯¯
            'trust_env': True  # ä¿¡ä»»ç¯å¢ƒå˜é‡ä¸­çš„ä»£ç†è®¾ç½®
        }
        
        # å¦‚æœå¯ç”¨äº†ä»£ç†ï¼Œä½¿ç”¨ä»£ç†è¿æ¥å™¨
        if http_config["proxy_enabled"] and http_config["proxy_url"]:
            logger.info(f"Using proxy: {http_config['proxy_url']}")
            # ä»£ç†æƒ…å†µä¸‹ä½¿ç”¨ä¸åŒçš„è¿æ¥å™¨é…ç½®
            proxy_connector = aiohttp.TCPConnector(
                limit=http_config["pool_limit"] // 2,  # ä»£ç†æ—¶å‡å°‘è¿æ¥æ•°
                limit_per_host=http_config["pool_limit_per_host"] // 2,
                keepalive_timeout=http_config["keepalive_timeout"],
                enable_cleanup_closed=True
            )
            session_kwargs['connector'] = proxy_connector
        
        HTTPClient._shared_session = aiohttp.ClientSession(**session_kwargs)
        logger.info("âœ… HTTPè¿æ¥æ± å·²åˆ›å»º")
    
    async def close_session(self):
        """å…³é—­ä¼šè¯ - ä¸å…³é—­å…±äº«sessionï¼Œåªæ¸…ç†å¼•ç”¨"""
        self.session = None
    
    @classmethod
    async def close_shared_session(cls):
        """å…³é—­å…±äº«session - åº”ç”¨å…³é—­æ—¶è°ƒç”¨"""
        async with cls._session_lock:
            if cls._shared_session and not cls._shared_session.closed:
                await cls._shared_session.close()
                cls._shared_session = None
                logger.info("ğŸ”’ HTTPè¿æ¥æ± å·²å…³é—­")
    
    def _check_rate_limit(self, url: str):
        """æ£€æŸ¥é™æµçŠ¶æ€"""
        domain = url.split('/')[2] if '/' in url else url
        reset_time = self._rate_limit_reset.get(domain)
        
        if reset_time and datetime.now() < reset_time:
            raise RateLimitError(f"Rate limit exceeded for {domain}")
    
    def _handle_rate_limit(self, url: str, retry_after: int = None):
        """å¤„ç†é™æµå“åº”"""
        domain = url.split('/')[2] if '/' in url else url
        reset_time = datetime.now() + timedelta(seconds=retry_after or 60)
        self._rate_limit_reset[domain] = reset_time
        
        logger.warning(f"Rate limit hit for {domain}, reset at {reset_time}")
    
    async def _make_request(self, method: str, url: str, **kwargs) -> Dict[str, Any]:
        """å‘èµ·HTTPè¯·æ±‚"""
        if not self.session:
            await self.start_session()
        
        # æ£€æŸ¥é™æµçŠ¶æ€
        self._check_rate_limit(url)
        
        for attempt in range(self.max_retries + 1):
            try:
                # å¦‚æœä½¿ç”¨ä»£ç†ï¼Œæ·»åŠ ä»£ç†å‚æ•°
                if self.use_proxy and self.proxy_url:
                    kwargs['proxy'] = self.proxy_url
                
                async with self.session.request(method, url, **kwargs) as response:
                    # å¤„ç†é™æµ
                    if response.status == 429:
                        retry_after = int(response.headers.get('Retry-After', 60))
                        self._handle_rate_limit(url, retry_after)
                        
                        if attempt < self.max_retries:
                            await asyncio.sleep(retry_after)
                            continue
                        else:
                            raise RateLimitError("Max retries exceeded for rate limiting")
                    
                    # å¤„ç†å…¶ä»–é”™è¯¯çŠ¶æ€
                    if response.status >= 400:
                        error_text = await response.text()
                        try:
                            error_data = json.loads(error_text)
                            error_msg = error_data.get('msg', error_text)
                            error_code = error_data.get('code')
                        except json.JSONDecodeError:
                            error_msg = error_text
                            error_code = None
                        
                        raise BinanceAPIError(
                            f"API request failed: {error_msg}",
                            error_code=str(error_code) if error_code else None,
                            status_code=response.status
                        )
                    
                    # æˆåŠŸå“åº”
                    response_text = await response.text()
                    try:
                        return json.loads(response_text)
                    except json.JSONDecodeError:
                        return {"raw_data": response_text}
                        
            except (aiohttp.ClientError, asyncio.TimeoutError) as e:
                if attempt < self.max_retries:
                    wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿
                    logger.warning(f"Request failed (attempt {attempt + 1}), retrying in {wait_time}s: {e}")
                    await asyncio.sleep(wait_time)
                    continue
                else:
                    logger.error(f"Request failed after {self.max_retries} retries: {e}")
                    raise BinanceAPIError(f"Network error after {self.max_retries} retries: {e}")
    
    async def get(self, url: str, params: Dict[str, Any] = None, 
                  headers: Dict[str, str] = None) -> Dict[str, Any]:
        """GETè¯·æ±‚"""
        kwargs = {}
        if params:
            kwargs['params'] = params
        if headers:
            kwargs['headers'] = headers
            
        return await self._make_request('GET', url, **kwargs)
    
    async def post(self, url: str, data: Dict[str, Any] = None, 
                   json_data: Dict[str, Any] = None,
                   headers: Dict[str, str] = None) -> Dict[str, Any]:
        """POSTè¯·æ±‚"""
        kwargs = {}
        if data:
            kwargs['data'] = data
        if json_data:
            kwargs['json'] = json_data
        if headers:
            kwargs['headers'] = headers
            
        return await self._make_request('POST', url, **kwargs)
    
    async def put(self, url: str, data: Dict[str, Any] = None,
                  json_data: Dict[str, Any] = None,
                  headers: Dict[str, str] = None) -> Dict[str, Any]:
        """PUTè¯·æ±‚"""
        kwargs = {}
        if data:
            kwargs['data'] = data
        if json_data:
            kwargs['json'] = json_data
        if headers:
            kwargs['headers'] = headers
            
        return await self._make_request('PUT', url, **kwargs)
    
    async def delete(self, url: str, headers: Dict[str, str] = None) -> Dict[str, Any]:
        """DELETEè¯·æ±‚"""
        kwargs = {}
        if headers:
            kwargs['headers'] = headers
            
        return await self._make_request('DELETE', url, **kwargs)


class HTTPConnectionPool:
    """HTTPè¿æ¥æ± ç®¡ç†å™¨"""
    
    def __init__(self):
        self.clients = {}
        self._lock = asyncio.Lock()
    
    async def get_client(self, name: str = "default", **kwargs) -> HTTPClient:
        """è·å–HTTPå®¢æˆ·ç«¯å®ä¾‹"""
        async with self._lock:
            if name not in self.clients:
                self.clients[name] = HTTPClient(**kwargs)
            return self.clients[name]
    
    async def close_all(self):
        """å…³é—­æ‰€æœ‰å®¢æˆ·ç«¯"""
        async with self._lock:
            for client in self.clients.values():
                await client.close_session()
            self.clients.clear()
            
            # å…³é—­å…±äº«session
            await HTTPClient.close_shared_session()
    
    def get_pool_stats(self) -> Dict[str, Any]:
        """è·å–è¿æ¥æ± ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "total_clients": len(self.clients),
            "client_names": list(self.clients.keys()),
            "shared_session_active": HTTPClient._shared_session is not None and not HTTPClient._shared_session.closed
        }
        
        # å¦‚æœæœ‰å…±äº«sessionï¼Œè·å–è¿æ¥å™¨ç»Ÿè®¡
        if HTTPClient._shared_session and not HTTPClient._shared_session.closed:
            connector = HTTPClient._shared_session.connector
            try:
                if hasattr(connector, '_conns'):
                    stats["total_connections"] = len(connector._conns)
                if hasattr(connector, 'limit'):
                    stats["connection_limit"] = connector.limit
                if hasattr(connector, 'limit_per_host'):
                    stats["per_host_limit"] = connector.limit_per_host
                if hasattr(connector, '_keepalive_timeout'):
                    stats["keepalive_timeout"] = connector._keepalive_timeout
                elif hasattr(connector, 'keepalive_timeout'):
                    stats["keepalive_timeout"] = connector.keepalive_timeout
            except Exception:
                # å¿½ç•¥è·å–ç»Ÿè®¡ä¿¡æ¯çš„é”™è¯¯
                pass
        
        return stats


# å…¨å±€HTTPè¿æ¥æ± å®ä¾‹
http_pool = HTTPConnectionPool()


async def get_http_client(name: str = "default", **kwargs) -> HTTPClient:
    """è·å–HTTPå®¢æˆ·ç«¯å®ä¾‹"""
    return await http_pool.get_client(name, **kwargs)


async def close_http_pool():
    """å…³é—­HTTPè¿æ¥æ± """
    await http_pool.close_all()


def get_http_pool_stats() -> Dict[str, Any]:
    """è·å–HTTPè¿æ¥æ± ç»Ÿè®¡ä¿¡æ¯"""
    return http_pool.get_pool_stats()